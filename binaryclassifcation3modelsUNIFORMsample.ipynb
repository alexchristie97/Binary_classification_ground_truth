{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=random.rand(1000, 10)\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(10, 10) \n",
    "        self.layer_2 = nn.Linear(10, 10) \n",
    "        self.layer_3 = nn.Linear(10, 10)\n",
    "        self.layer_4 = nn.Linear(10, 10)\n",
    "        self.layer_5 = nn.Linear(10, 10) \n",
    "        self.layer_out = nn.Linear(10, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0f695b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#6 layers then an output layer. first 5 and output are copied\n",
    "class extra_inner_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(extra_inner_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = nn.Linear(10, 10)\n",
    "        self.layer_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(10)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8be94e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer at end\n",
    "class append_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_out = nn.Linear(1,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f67b50",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer and output\n",
    "class append_layer_and_ouput(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer_and_ouput, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_7 = nn.Linear(1,10)\n",
    "        self.layer_out = nn.Linear(10,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        self.batchnorm7 = nn.BatchNorm1d(10)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.relu(self.layer_7(x))\n",
    "        x = self.batchnorm7(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 50 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "GroundTruth.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in Truthloadertrain:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        truthoptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = GroundTruth(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        truthoptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#DELETeee\n",
    "\n",
    "Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "        \n",
    "\n",
    "truth_list = []\n",
    "GroundTruth.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truthloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = GroundTruth(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = torch.round(y_truth)\n",
    "        truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "#print(y)\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "#print(y_train)\n",
    "#rescale data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "#ssplit data\n",
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=.5, random_state=69)\n",
    "X_train=scaler.fit_transform(X_train)                                                        \n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_train2=scaler.fit_transform(X_train2)\n",
    "X_test = scaler.transform(X_test)\n",
    "                                                          \n",
    "                                                      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "train_data1= trainData(torch.FloatTensor(X_train1), \n",
    "                       torch.FloatTensor(y_train1))\n",
    "                                         \n",
    "train_data2= trainData(torch.FloatTensor(X_train2), \n",
    "                       torch.FloatTensor(y_train2))\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader1= DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader2= DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)                         \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  214  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.35      0.44       127\n",
      "         1.0       0.67      0.83      0.74       203\n",
      "\n",
      "    accuracy                           0.65       330\n",
      "   macro avg       0.62      0.59      0.59       330\n",
      "weighted avg       0.63      0.65      0.63       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define models with extra layers\n",
    "trained_append_layer=append_layer(trained)\n",
    "trained_append_layeroutput=append_layer_and_ouput(trained)\n",
    "trained_extra_inner_layer=extra_inner_layer(trained)\n",
    "\n",
    "optimizerappend = optim.Adam(trained_append_layer.parameters(), lr=LEARNING_RATE)\n",
    "optimizermiddle = optim.Adam(trained_append_layeroutput.parameters(), lr=LEARNING_RATE)\n",
    "optimizerappendoutput = optim.Adam(trained_extra_inner_layer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        \n",
    "\n",
    "      \n",
    "firstlayers_model1=binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07c8dcb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  204  out of  330\n",
      "half data partial model correct:  207  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.39      0.44       127\n",
      "         1.0       0.67      0.76      0.71       203\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.59      0.57      0.57       330\n",
      "weighted avg       0.60      0.62      0.61       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.38      0.44       127\n",
      "         1.0       0.67      0.78      0.72       203\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.59      0.58      0.58       330\n",
      "weighted avg       0.61      0.63      0.61       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  219  out of  330\n",
      "full data partial model correct:  211  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.48      0.52       127\n",
      "         1.0       0.71      0.78      0.74       203\n",
      "\n",
      "    accuracy                           0.66       330\n",
      "   macro avg       0.64      0.63      0.63       330\n",
      "weighted avg       0.66      0.66      0.66       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.51      0.52       127\n",
      "         1.0       0.70      0.72      0.71       203\n",
      "\n",
      "    accuracy                           0.64       330\n",
      "   macro avg       0.62      0.62      0.62       330\n",
      "weighted avg       0.64      0.64      0.64       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "optimzer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d25561",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  176  out of  330\n",
      "half data partial model correct:  205  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.33      0.35       127\n",
      "         1.0       0.61      0.66      0.64       203\n",
      "\n",
      "    accuracy                           0.53       330\n",
      "   macro avg       0.50      0.50      0.49       330\n",
      "weighted avg       0.52      0.53      0.53       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.57      0.54       127\n",
      "         1.0       0.71      0.65      0.68       203\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.61      0.61      0.61       330\n",
      "weighted avg       0.63      0.62      0.62       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  170  out of  330\n",
      "full data partial model correct:  212  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.30      0.32       127\n",
      "         1.0       0.60      0.65      0.62       203\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.47      0.47      0.47       330\n",
      "weighted avg       0.50      0.52      0.51       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.24      0.34       127\n",
      "         1.0       0.65      0.89      0.75       203\n",
      "\n",
      "    accuracy                           0.64       330\n",
      "   macro avg       0.62      0.57      0.55       330\n",
      "weighted avg       0.63      0.64      0.60       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimzer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1d608e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  171  out of  330\n",
      "half data partial model correct:  214  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.37      0.35      0.36       127\n",
      "         1.0       0.60      0.63      0.62       203\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.49      0.49      0.49       330\n",
      "weighted avg       0.51      0.52      0.52       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.49      0.52       127\n",
      "         1.0       0.70      0.75      0.72       203\n",
      "\n",
      "    accuracy                           0.65       330\n",
      "   macro avg       0.62      0.62      0.62       330\n",
      "weighted avg       0.64      0.65      0.64       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  171  out of  330\n",
      "full data partial model correct:  208  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.41      0.40       127\n",
      "         1.0       0.61      0.59      0.60       203\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.50      0.50      0.50       330\n",
      "weighted avg       0.52      0.52      0.52       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.10      0.18       127\n",
      "         1.0       0.63      0.96      0.76       203\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.63      0.53      0.47       330\n",
      "weighted avg       0.63      0.63      0.54       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add middle layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train partial model using first half data\n",
    "optimzer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0931f717",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained append model:\n",
      "Number correct full model:  210  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.41      0.46       127\n",
      "         1.0       0.68      0.78      0.72       203\n",
      "\n",
      "    accuracy                           0.64       330\n",
      "   macro avg       0.61      0.59      0.59       330\n",
      "weighted avg       0.62      0.64      0.62       330\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  207  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.43      0.47       127\n",
      "         1.0       0.68      0.75      0.71       203\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.60      0.59      0.59       330\n",
      "weighted avg       0.62      0.63      0.62       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer, train regularly\n",
    "\n",
    "normalappend=extra_inner_layer(trained)\n",
    "normaloptimappend = optim.Adam(normalappend.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalappend.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimappend.zero_grad()\n",
    "        \n",
    "        y_pred = normalappend(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalappend.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalappend(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Trained append model:\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77499cee",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained append layer and output\n",
      "Number correct:  199  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.40      0.44       127\n",
      "         1.0       0.66      0.73      0.69       203\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.57      0.57      0.57       330\n",
      "weighted avg       0.59      0.60      0.59       330\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  204  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.41      0.45       127\n",
      "         1.0       0.67      0.75      0.71       203\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.59      0.58      0.58       330\n",
      "weighted avg       0.61      0.62      0.61       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output, and train regularly\n",
    "\n",
    "\n",
    "normalextralayeroutput=append_layer_and_ouput(trained)\n",
    "normaloptimextraoutput = optim.Adam(normalextralayeroutput.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextraoutput.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextraoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "print(\"Trained append layer and output\")        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef2f03a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained add middle layer\n",
      "Number correct:  203  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.39      0.44       127\n",
      "         1.0       0.66      0.76      0.71       203\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.58      0.57      0.57       330\n",
      "weighted avg       0.60      0.62      0.60       330\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  205  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.39      0.44       127\n",
      "         1.0       0.67      0.76      0.71       203\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.59      0.58      0.58       330\n",
      "weighted avg       0.61      0.62      0.61       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#just add middle layer, and train regularly\n",
    "\n",
    "\n",
    "normalextralayer=extra_inner_layer(trained)\n",
    "normaloptimextra = optim.Adam(normalextralayer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextra.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextra.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "print(\"trained add middle layer\")        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed861e4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n"
     ]
    }
   ],
   "source": [
    "#Find and fix weights\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "\n",
    "\n",
    "#get weighs for seconds layer\n",
    "#print(repr(GroundTruth.layer_2.weight.detach().numpy()))\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "#print(GroundTruth.layer_3.weight)\n",
    "#print(GroundTruth.layer_4.weight)\n",
    "#print(GroundTruth.layer_5.weight)\n",
    "#print(GroundTruth.layer_out.weight)\n",
    "\n",
    "\n",
    "\n",
    "#bais1\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais2\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais3\n",
    "#print(\"BIASES\")\n",
    "#print(GroundTruth.layer_1.bias)\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "#print(GroundTruth.layer_3.bias)\n",
    "#print(GroundTruth.layer_4.bias)\n",
    "#print(GroundTruth.layer_5.bias)\n",
    "#print(GroundTruth.layer_out.bias)\n",
    "\n",
    "#Counts number of ground truths\n",
    "truthcount=0\n",
    "for i in y:\n",
    "    if i==1:\n",
    "        truthcount=truthcount+1\n",
    "        \n",
    "print(truthcount)\n",
    "#print(len(y))\n",
    "#print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdac33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
