{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=random.rand(1000, 10)\n",
    "y=[]\n",
    "for i in range(1000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(10, 10) \n",
    "        self.layer_2 = nn.Linear(10, 10) \n",
    "        self.layer_3 = nn.Linear(10, 10)\n",
    "        self.layer_4 = nn.Linear(10, 10)\n",
    "        self.layer_5 = nn.Linear(10, 10) \n",
    "        self.layer_out = nn.Linear(10, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(10)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0f695b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#6 layers then an output layer. first 5 and output are copied\n",
    "class extra_inner_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(extra_inner_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = nn.Linear(10, 10)\n",
    "        self.layer_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(10)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8be94e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer at end\n",
    "class append_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_out = nn.Linear(1,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f67b50",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer and output\n",
    "class append_layer_and_ouput(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer_and_ouput, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_7 = nn.Linear(1,10)\n",
    "        self.layer_out = nn.Linear(10,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        self.batchnorm7 = nn.BatchNorm1d(10)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.relu(self.layer_7(x))\n",
    "        x = self.batchnorm7(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 50 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "GroundTruth.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in Truthloadertrain:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        truthoptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = GroundTruth(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        truthoptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#DELETeee\n",
    "\n",
    "Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "        \n",
    "\n",
    "truth_list = []\n",
    "GroundTruth.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truthloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = GroundTruth(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = torch.round(y_truth)\n",
    "        truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "#print(y)\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "#print(y_train)\n",
    "#rescale data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "#ssplit data\n",
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=.5, random_state=69)\n",
    "X_train=scaler.fit_transform(X_train)                                                        \n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_train2=scaler.fit_transform(X_train2)\n",
    "X_test = scaler.transform(X_test)\n",
    "                                                          \n",
    "                                                      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "train_data1= trainData(torch.FloatTensor(X_train1), \n",
    "                       torch.FloatTensor(y_train1))\n",
    "                                         \n",
    "train_data2= trainData(torch.FloatTensor(X_train2), \n",
    "                       torch.FloatTensor(y_train2))\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader1= DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader2= DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)                         \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  172  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.58      0.54       159\n",
      "         1.0       0.54      0.46      0.50       171\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.52      0.52      0.52       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define models with extra layers\n",
    "trained_append_layer=append_layer(trained)\n",
    "trained_append_layeroutput=append_layer_and_ouput(trained)\n",
    "trained_extra_inner_layer=extra_inner_layer(trained)\n",
    "\n",
    "optimizerappend = optim.Adam(trained_append_layer.parameters(), lr=LEARNING_RATE)\n",
    "optimizermiddle = optim.Adam(trained_append_layeroutput.parameters(), lr=LEARNING_RATE)\n",
    "optimizerappendoutput = optim.Adam(trained_extra_inner_layer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        \n",
    "\n",
    "      \n",
    "firstlayers_model1=binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a07c8dcb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  181  out of  330\n",
      "half data partial model correct:  171  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.58      0.56       159\n",
      "         1.0       0.57      0.51      0.54       171\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.55      0.55      0.55       330\n",
      "weighted avg       0.55      0.55      0.55       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       159\n",
      "         1.0       0.52      1.00      0.68       171\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.26      0.50      0.34       330\n",
      "weighted avg       0.27      0.52      0.35       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  184  out of  330\n",
      "full data partial model correct:  171  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.64      0.58       159\n",
      "         1.0       0.59      0.48      0.53       171\n",
      "\n",
      "    accuracy                           0.56       330\n",
      "   macro avg       0.56      0.56      0.56       330\n",
      "weighted avg       0.56      0.56      0.55       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       159\n",
      "         1.0       0.52      1.00      0.68       171\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.26      0.50      0.34       330\n",
      "weighted avg       0.27      0.52      0.35       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d25561",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  172  out of  330\n",
      "half data partial model correct:  159  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.78      0.61       159\n",
      "         1.0       0.58      0.28      0.38       171\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.54      0.53      0.49       330\n",
      "weighted avg       0.54      0.52      0.49       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65       159\n",
      "         1.0       0.00      0.00      0.00       171\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.24      0.50      0.33       330\n",
      "weighted avg       0.23      0.48      0.31       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  170  out of  330\n",
      "full data partial model correct:  159  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.74      0.60       159\n",
      "         1.0       0.56      0.30      0.39       171\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.53      0.52      0.49       330\n",
      "weighted avg       0.53      0.52      0.49       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65       159\n",
      "         1.0       0.00      0.00      0.00       171\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.24      0.50      0.33       330\n",
      "weighted avg       0.23      0.48      0.31       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c1d608e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  151  out of  330\n",
      "half data partial model correct:  159  out of  330\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.50      0.47       159\n",
      "         1.0       0.47      0.42      0.45       171\n",
      "\n",
      "    accuracy                           0.46       330\n",
      "   macro avg       0.46      0.46      0.46       330\n",
      "weighted avg       0.46      0.46      0.46       330\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65       159\n",
      "         1.0       0.00      0.00      0.00       171\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.24      0.50      0.33       330\n",
      "weighted avg       0.23      0.48      0.31       330\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  150  out of  330\n",
      "full data partial model correct:  159  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.48      0.46       159\n",
      "         1.0       0.47      0.43      0.45       171\n",
      "\n",
      "    accuracy                           0.45       330\n",
      "   macro avg       0.46      0.46      0.45       330\n",
      "weighted avg       0.46      0.45      0.45       330\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65       159\n",
      "         1.0       0.00      0.00      0.00       171\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.24      0.50      0.33       330\n",
      "weighted avg       0.23      0.48      0.31       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add middle layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0931f717",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct:  178  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.55      0.53       159\n",
      "         1.0       0.56      0.53      0.54       171\n",
      "\n",
      "    accuracy                           0.54       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.54      0.54      0.54       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer, train regularly\n",
    "\n",
    "normalappend=extra_inner_layer(trained)\n",
    "normaloptimappend = optim.Adam(normalappend.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalappend.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimappend.zero_grad()\n",
    "        \n",
    "        y_pred = normalappend(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalappend.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalappend(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "\n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77499cee",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct:  183  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.62      0.57       159\n",
      "         1.0       0.58      0.50      0.54       171\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.56      0.56      0.55       330\n",
      "weighted avg       0.56      0.55      0.55       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output, and train regularly\n",
    "\n",
    "\n",
    "normalextralayeroutput=append_layer_and_ouput(trained)\n",
    "normaloptimextraoutput = optim.Adam(normalextralayeroutput.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextraoutput.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextraoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ef2f03a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number correct:  192  out of  330\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.64      0.59       159\n",
      "         1.0       0.61      0.53      0.57       171\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.58      0.58      0.58       330\n",
      "weighted avg       0.59      0.58      0.58       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#just add middle layer, and train regularly\n",
    "\n",
    "\n",
    "normalextralayer=extra_inner_layer(trained)\n",
    "normaloptimextra = optim.Adam(normalextralayer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextra.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextra.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ed861e4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n"
     ]
    }
   ],
   "source": [
    "#Find and fix weights\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "\n",
    "\n",
    "#get weighs for seconds layer\n",
    "#print(repr(GroundTruth.layer_2.weight.detach().numpy()))\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "#print(GroundTruth.layer_3.weight)\n",
    "#print(GroundTruth.layer_4.weight)\n",
    "#print(GroundTruth.layer_5.weight)\n",
    "#print(GroundTruth.layer_out.weight)\n",
    "\n",
    "\n",
    "\n",
    "#bais1\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais2\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais3\n",
    "#print(\"BIASES\")\n",
    "#print(GroundTruth.layer_1.bias)\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "#print(GroundTruth.layer_3.bias)\n",
    "#print(GroundTruth.layer_4.bias)\n",
    "#print(GroundTruth.layer_5.bias)\n",
    "#print(GroundTruth.layer_out.bias)\n",
    "\n",
    "#Counts number of ground truths\n",
    "truthcount=0\n",
    "for i in y:\n",
    "    if i==1:\n",
    "        truthcount=truthcount+1\n",
    "        \n",
    "print(truthcount)\n",
    "#print(len(y))\n",
    "#print(len(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
