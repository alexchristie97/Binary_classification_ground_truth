{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=random.rand(10000, 5)\n",
    "\n",
    "np.random.normal(0, 1, size=(10000, 10))\n",
    "\n",
    "\n",
    "y=[]\n",
    "for i in range(10000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, 5) \n",
    "        self.layer_2 = nn.Linear(5, 5) \n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4 = nn.Linear(5, 5)\n",
    "        self.layer_5 = nn.Linear(5, 5) \n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196afae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#parallel model (two 5 layer models, with output going into new output layer)\n",
    "class parallelmodel(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(parallelmodel, self).__init__()\n",
    "        self.layer1_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer1_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer1_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer1_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer1_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer1_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu1 = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout1 = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1_1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm1_2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm1_3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm1_4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm1_5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        #self.batchnorm1_out=nn.BatchNorm1d(1)\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        #self.batchnorm2_out=nn.BatchNorm1d()\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu1(self.layer1_1(inputs))\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu1(self.layer1_2(x))\n",
    "        x = self.batchnorm1_2(x)\n",
    "        x = self.relu1(self.layer1_3(x))\n",
    "        x = self.batchnorm1_3(x)\n",
    "        x = self.relu1(self.layer1_4(x))\n",
    "        x = self.batchnorm1_4(x)\n",
    "        x = self.relu1(self.layer1_5(x))\n",
    "        x = self.batchnorm1_5(x) \n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer1_out(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(inputs))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 100 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "\n",
    "\n",
    "baddata=True\n",
    "while(baddata):\n",
    "\n",
    "    \n",
    "\n",
    "    GroundTruth.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in Truthloadertrain:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            truthoptimizer.zero_grad()\n",
    "\n",
    "            y_pred = GroundTruth(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            truthoptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "    Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "    #print(y_train)\n",
    "    #rescale data \n",
    "    scaler = StandardScaler()\n",
    "    truthcounter=0\n",
    "    for i in y:\n",
    "        if i==1:\n",
    "            truthcounter=truthcounter+1\n",
    "    \n",
    "    \n",
    "    #print(truthcounter)\n",
    "    if truthcounter/len(y)<.8 and truthcounter/len(y)>.2:\n",
    "        baddata=False\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  2973  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.90      0.91      1963\n",
      "         1.0       0.86      0.91      0.88      1337\n",
      "\n",
      "    accuracy                           0.90      3300\n",
      "   macro avg       0.90      0.90      0.90      3300\n",
      "weighted avg       0.90      0.90      0.90      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#w1=(trained.layer_1.weight)\n",
    "#w2=(trained.layer_2.weight)\n",
    "#w3=(trained.layer_3.weight)\n",
    "#w4=(trained.layer_4.weight)\n",
    "#w5=(trained.layer_5.weight)\n",
    "#print(w1)\n",
    "#print(w2)\n",
    "#print(w3)\n",
    "#print(w4)\n",
    "#print(w5)\n",
    "#print(trained.layer_out.weight)\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10501\n",
      "# correct:  3156  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96      1963\n",
      "         1.0       0.94      0.96      0.95      1337\n",
      "\n",
      "    accuracy                           0.96      3300\n",
      "   macro avg       0.95      0.96      0.95      3300\n",
      "weighted avg       0.96      0.96      0.96      3300\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[ 8.3781, -4.6677]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#train parralel model\n",
    "parralel = parallelmodel(trained)\n",
    "parralel.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "parralel.outputlayer.weight=torch.nn.Parameter(data=torch.tensor([[.7,0.3]]), requires_grad=True)\n",
    "parralel.alpha.append(.7)\n",
    "parralel.beta.append(.3)\n",
    "epochlist=[]\n",
    "losslist=[]\n",
    "\n",
    "paroptimizer = optim.Adam(parralel.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "#EPOCHS = 300 #number of passes of whole data\n",
    "#BATCH_SIZE = 16 #size of data going through at once\n",
    "\n",
    "\n",
    "\n",
    "#train trained model\n",
    "parralel.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        paroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = parralel(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        paroptimizer.step()\n",
    "        \n",
    "        parralel.alpha.append(parralel.outputlayer.weight[0][0].detach().numpy().item())\n",
    "        parralel.beta.append(parralel.outputlayer.weight[0][1].detach().numpy().item())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    epochlist.append(e)   \n",
    "    losslist.append(epoch_loss/len(train_loader))\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "    \n",
    "passlist=list(range(0,len(parralel.alpha)))\n",
    "    \n",
    "#losslist.insert(0, losslist[0])\n",
    "\n",
    "  \n",
    "print(len(parralel.alpha))\n",
    "    \n",
    "y_parmodelpred_list =[]\n",
    "parralel.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = parralel(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "#print(y_parmodelpred_list)\n",
    "    \n",
    "parmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_parmodelpred_list[i]==y_test[i]:\n",
    "        parmodelcounter=parmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    \n",
    "    \n",
    "print(\"output weight: \", parralel.outputlayer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6504ca20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphs\n",
    "\n",
    "fig, (weights, lossgraph) = plt.subplots(2)\n",
    "weights.plot(passlist,parralel.alpha, label=\"Alpha\")\n",
    "weights.plot(passlist,parralel.beta, label=\"Beta\")\n",
    "weights.legend()\n",
    "\n",
    "weights.set_xlabel('Epochs')\n",
    "weights.set_ylabel('Weights')\n",
    "weights.set_title('Alpa and Beta')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(epochlist,losslist, label=\"loss\")\n",
    "\n",
    "lossgraph.set_xlabel('Epochs')\n",
    "lossgraph.set_label('Loss')\n",
    "lossgraph.set_title('Loss')\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('e2fullparalelgraph3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a880e22f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained stats:\n",
      "Tained half model;\n",
      "Number correct full model:  1963  out of  3300\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      1.00      0.75      1963\n",
      "         1.0       0.00      0.00      0.00      1337\n",
      "\n",
      "    accuracy                           0.59      3300\n",
      "   macro avg       0.30      0.50      0.37      3300\n",
      "weighted avg       0.35      0.59      0.44      3300\n",
      "\n",
      "untrained half stats:\n",
      "untained half model;\n",
      "Number correct full model:  1337  out of  3300\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1963\n",
      "         1.0       0.41      1.00      0.58      1337\n",
      "\n",
      "    accuracy                           0.41      3300\n",
      "   macro avg       0.20      0.50      0.29      3300\n",
      "weighted avg       0.16      0.41      0.23      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#half model stats\n",
    "\n",
    "halfmodeltrained=binaryClassification()\n",
    "halfmodellow=binaryClassification()\n",
    "\n",
    "halfmodeltrained.layer_1 = copy.deepcopy(parralel.layer1_1)\n",
    "halfmodeltrained.layer_2 = copy.deepcopy(parralel.layer1_2)\n",
    "halfmodeltrained.layer_3 = copy.deepcopy(parralel.layer1_3)\n",
    "halfmodeltrained.layer_4 = copy.deepcopy(parralel.layer1_4)\n",
    "halfmodeltrained.layer_5 = copy.deepcopy(parralel.layer1_5)\n",
    "halfmodeltrained.layer_out = copy.deepcopy(parralel.layer1_out)\n",
    "\n",
    "\n",
    "halfmodellow.layer_1 = copy.deepcopy(parralel.layer2_1)\n",
    "halfmodellow.layer_2 = copy.deepcopy(parralel.layer2_2)\n",
    "halfmodellow.layer_3 = copy.deepcopy(parralel.layer2_3)\n",
    "halfmodellow.layer_4 = copy.deepcopy(parralel.layer2_4)\n",
    "halfmodellow.layer_5 = copy.deepcopy(parralel.layer2_5)\n",
    "halfmodellow.layer_out = copy.deepcopy(parralel.layer2_out)\n",
    "\n",
    "\n",
    "print(\"pretrained stats:\")\n",
    "\n",
    "\n",
    "\n",
    "y_pretrianedlist =[]\n",
    "halfmodeltrained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = halfmodeltrained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pretrianedlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_pretrianedlist = [a.squeeze().tolist() for a in y_pretrianedlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_pretrianedlist)):\n",
    "    if y_pretrianedlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained half model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_pretrianedlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"untrained half stats:\")\n",
    "y_untrianedlist =[]\n",
    "halfmodellow.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = halfmodellow(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrianedlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_untrianedlist = [a.squeeze().tolist() for a in y_untrianedlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_untrianedlist)):\n",
    "    if y_untrianedlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"untained half model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_untrianedlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137a5bc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#multiple routines\n",
    "val = input(\"Enter number of training routines:\")\n",
    "for k in range(int(val)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X=random.rand(1000, 5)\n",
    "\n",
    "    np.random.normal(0, 1, size=(1000, 10))\n",
    "\n",
    "\n",
    "    y=[]\n",
    "    for i in range(1000):\n",
    "        y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "    \n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data= trainData(torch.FloatTensor(X_train), \n",
    "                           torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "    #data loader initiation\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #train trained model\n",
    "    parralel.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            paroptimizer.zero_grad()\n",
    "\n",
    "            y_pred = parralel(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            paroptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_parmodelpred_list =[]\n",
    "    parralel.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = parralel(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    #print(y_parmodelpred_list)\n",
    "\n",
    "    parmodelcounter=0\n",
    "    for i in range(len(y_fullmodelpred_list)):\n",
    "        if y_parmodelpred_list[i]==y_test[i]:\n",
    "            parmodelcounter=parmodelcounter+1       \n",
    "    print(\"training routine #: \", k+1)\n",
    "    print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Full model statistics\")\n",
    "    print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    print(\"output weight: \", parralel.outputlayer.weight)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "parralel.outputlayer.weight[0].detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
