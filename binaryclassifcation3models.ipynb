{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "weight1=[[ 0.1642,  0.2455, -0.3093, -0.4260, -0.1927],\n",
    "        [ 0.1405,  0.2877,  0.1791,  0.2886,  0.0281],\n",
    "        [-0.4129,  0.2434, -0.3342,  0.0638,  0.0898],\n",
    "        [ 0.3933,  0.3019,  0.0625,  0.2342, -0.4222],\n",
    "        [-0.3019,  0.1200, -0.1640, -0.1984, -0.1032]]\n",
    "\n",
    "weight2=[[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0]]\n",
    "\n",
    "weight4=[[-0.0068,  0.1320, -0.4003,  0.0965, -0.4061],\n",
    "        [ 0.2241,  0.1185,  0.0251, -0.0104, -0.0224],\n",
    "        [ 0.4361, -0.0875,  0.0647,  0.3484,  0.4034],\n",
    "        [ 0.1191, -0.3272,  0.2531,  0.2740, -0.3526],\n",
    "        [ 0.3558, -0.0614, -0.2608, -0.1395, -0.0635]]\n",
    "\n",
    "\n",
    "weight5=[[-0.0115,  0.1046,  0.2259,  0.1117, -0.0206],\n",
    "        [-0.4093, -0.2933, -0.3829, -0.2851,  0.1360],\n",
    "        [ 0.1195,  0.3427,  0.4183,  0.1673,  0.1913],\n",
    "        [-0.2937, -0.2824,  0.1436, -0.2029,  0.1594],\n",
    "        [ 0.0140,  0.1943, -0.2809,  0.2599,  0.0647]]\n",
    "\n",
    "weightout=[[.50,.50,.50,.50,.50]]\n",
    "bias1=[ 0.1889, -0.4299,  0.0239,  0.3833, -0.2821]\n",
    "bias2=[0.0,.0,0.0,0.0,0.0]\n",
    "#weight2\n",
    "#bias3=\n",
    "#bias4=\n",
    "#bias5=\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, 5) \n",
    "        self.layer_2 = nn.Linear(5, 5) \n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4 = nn.Linear(5, 5)\n",
    "        self.layer_5 = nn.Linear(5, 5) \n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0f695b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#6 layers then an output layer. first 5 and output are copied\n",
    "class extra_inner_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(extra_inner_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = nn.Linear(5, 5)\n",
    "        self.layer_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8be94e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer at end\n",
    "class append_layer(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_out = nn.Linear(1,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f67b50",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#append layer and output\n",
    "class append_layer_and_ouput(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(append_layer_and_ouput, self).__init__()\n",
    "        self.layer_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer_6 = copy.deepcopy(originalmodel.layer_out)\n",
    "        self.layer_7 = nn.Linear(1,5)\n",
    "        self.layer_out = nn.Linear(5,1)\n",
    "        \n",
    "        self.relu = copy.deepcopy(originalmodel.relu)\n",
    "        self.dropout = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batchnorm1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(1)\n",
    "        self.batchnorm7 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x) \n",
    "        x = self.relu(self.layer_6(x))\n",
    "        x = self.batchnorm6(x)\n",
    "        x = self.relu(self.layer_7(x))\n",
    "        x = self.batchnorm7(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "#df = pd.read_csv(\"Dataset_spine.csv\")\n",
    "df= pd.read_csv(\"Breast_cancer_data.csv\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.iloc[:, 0:-1] #input columns\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled)) #format data for input\n",
    "Truth_loader = DataLoader(dataset=X_formatted, batch_size=1) #format data for input\n",
    "\n",
    "\n",
    "\n",
    "GroundTruth = binaryClassification()\n",
    "#set weights to \"evenly distributed\" 0, 1\n",
    "GroundTruth.layer_1.weight=torch.nn.Parameter(data=torch.tensor(weight1), requires_grad=True)\n",
    "GroundTruth.layer_2.weight=torch.nn.Parameter(data=torch.tensor(weight2), requires_grad=True)\n",
    "GroundTruth.layer_3.weight=torch.nn.Parameter(data=torch.tensor(weight2), requires_grad=True)\n",
    "GroundTruth.layer_4.weight=torch.nn.Parameter(data=torch.tensor(weight4), requires_grad=True)\n",
    "GroundTruth.layer_5.weight=torch.nn.Parameter(data=torch.tensor(weight5), requires_grad=True)\n",
    "GroundTruth.layer_out.weight=torch.nn.Parameter(data=torch.tensor(weightout), requires_grad=True)\n",
    "\n",
    "GroundTruth.layer_1.bias=torch.nn.Parameter(data=torch.tensor(bias1), requires_grad=True)\n",
    "GroundTruth.layer_2.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_3.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_4.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_5.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_out.bias=torch.nn.Parameter(data=torch.tensor([-3.0]),requires_grad=True)\n",
    "\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "\n",
    "truth_list = []\n",
    "GroundTruth.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truth_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = GroundTruth(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = torch.round(y_truth)\n",
    "        truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "#rescale data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "#ssplit data\n",
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train, y_train, test_size=.5, random_state=69)\n",
    "X_train=scaler.fit_transform(X_train)                                                        \n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "X_train2=scaler.fit_transform(X_train2)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "                                                          \n",
    "                                                      \n",
    "\n",
    "EPOCHS = 50 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "train_data1= trainData(torch.FloatTensor(X_train1), \n",
    "                       torch.FloatTensor(y_train1))\n",
    "                                         \n",
    "train_data2= trainData(torch.FloatTensor(X_train2), \n",
    "                       torch.FloatTensor(y_train2))\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader1= DataLoader(dataset=train_data1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader2= DataLoader(dataset=train_data2, batch_size=BATCH_SIZE, shuffle=True)                         \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  178  out of  188\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        88\n",
      "         1.0       0.95      0.95      0.95       100\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.95      0.95      0.95       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "    \n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define models with extra layers\n",
    "trained_append_layer=append_layer(trained)\n",
    "trained_append_layeroutput=append_layer_and_ouput(trained)\n",
    "trained_extra_inner_layer=extra_inner_layer(trained)\n",
    "\n",
    "optimizerappend = optim.Adam(trained_append_layer.parameters(), lr=LEARNING_RATE)\n",
    "optimizermiddle = optim.Adam(trained_append_layeroutput.parameters(), lr=LEARNING_RATE)\n",
    "optimizerappendoutput = optim.Adam(trained_extra_inner_layer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        \n",
    "\n",
    "      \n",
    "firstlayers_model1=binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07c8dcb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  100  out of  188\n",
      "half data partial model correct:  89  out of  188\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        88\n",
      "         1.0       0.53      1.00      0.69       100\n",
      "\n",
      "    accuracy                           0.53       188\n",
      "   macro avg       0.27      0.50      0.35       188\n",
      "weighted avg       0.28      0.53      0.37       188\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      1.00      0.64        88\n",
      "         1.0       1.00      0.01      0.02       100\n",
      "\n",
      "    accuracy                           0.47       188\n",
      "   macro avg       0.74      0.51      0.33       188\n",
      "weighted avg       0.75      0.47      0.31       188\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  172  out of  188\n",
      "full data partial model correct:  104  out of  188\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91        88\n",
      "         1.0       0.90      0.94      0.92       100\n",
      "\n",
      "    accuracy                           0.91       188\n",
      "   macro avg       0.92      0.91      0.91       188\n",
      "weighted avg       0.92      0.91      0.91       188\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.92      0.66        88\n",
      "         1.0       0.77      0.23      0.35       100\n",
      "\n",
      "    accuracy                           0.55       188\n",
      "   macro avg       0.64      0.58      0.51       188\n",
      "weighted avg       0.65      0.55      0.50       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader1):.5f} | Acc: {epoch_acc/len(train_loader1):.3f}')\n",
    "\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappend.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d25561",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  92  out of  188\n",
      "half data partial model correct:  100  out of  188\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65        88\n",
      "         1.0       1.00      0.04      0.08       100\n",
      "\n",
      "    accuracy                           0.49       188\n",
      "   macro avg       0.74      0.52      0.36       188\n",
      "weighted avg       0.76      0.49      0.34       188\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        88\n",
      "         1.0       0.53      1.00      0.69       100\n",
      "\n",
      "    accuracy                           0.53       188\n",
      "   macro avg       0.27      0.50      0.35       188\n",
      "weighted avg       0.28      0.53      0.37       188\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  104  out of  188\n",
      "full data partial model correct:  100  out of  188\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      1.00      0.68        88\n",
      "         1.0       1.00      0.16      0.28       100\n",
      "\n",
      "    accuracy                           0.55       188\n",
      "   macro avg       0.76      0.58      0.48       188\n",
      "weighted avg       0.77      0.55      0.46       188\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        88\n",
      "         1.0       0.53      1.00      0.69       100\n",
      "\n",
      "    accuracy                           0.53       188\n",
      "   macro avg       0.27      0.50      0.35       188\n",
      "weighted avg       0.28      0.53      0.37       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_append_layeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizerappendoutput.zero_grad()\n",
    "        \n",
    "        y_pred = trained_append_layeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizerappendoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_append_layeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_append_layeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1d608e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "Results using half training data:\n",
      "half data full model correct:  172  out of  188\n",
      "half data partial model correct:  100  out of  188\n",
      "Full model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90        88\n",
      "         1.0       0.89      0.96      0.92       100\n",
      "\n",
      "    accuracy                           0.91       188\n",
      "   macro avg       0.92      0.91      0.91       188\n",
      "weighted avg       0.92      0.91      0.91       188\n",
      "\n",
      "Partial model statistics, half data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        88\n",
      "         1.0       0.53      1.00      0.69       100\n",
      "\n",
      "    accuracy                           0.53       188\n",
      "   macro avg       0.27      0.50      0.35       188\n",
      "weighted avg       0.28      0.53      0.37       188\n",
      "\n",
      "Results using full training data:\n",
      "full data full model correct:  172  out of  188\n",
      "full data partial model correct:  100  out of  188\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.90        88\n",
      "         1.0       0.89      0.96      0.92       100\n",
      "\n",
      "    accuracy                           0.91       188\n",
      "   macro avg       0.92      0.91      0.91       188\n",
      "weighted avg       0.92      0.91      0.91       188\n",
      "\n",
      "Partial model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        88\n",
      "         1.0       0.53      1.00      0.69       100\n",
      "\n",
      "    accuracy                           0.53       188\n",
      "   macro avg       0.27      0.50      0.35       188\n",
      "weighted avg       0.28      0.53      0.37       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add middle layer train with first half then second\n",
    "\n",
    "#train using first half\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader1:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "\n",
    "print(\"Results using half training data:\")\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "#results full model, half data\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#results partial model\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#counts correct values\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "\n",
    "print(\"half data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"half data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics, half data\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics, half data\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "\n",
    "\n",
    "\n",
    "#train with second half of data set\n",
    "trained_extra_inner_layer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader2:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizermiddle.zero_grad()\n",
    "        \n",
    "        y_pred = trained_extra_inner_layer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizermiddle.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Results using full training data:\")\n",
    "\n",
    "\n",
    "\n",
    "#full model predictions\n",
    "y_fullmodelpred_list =[]\n",
    "trained_extra_inner_layer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained_extra_inner_layer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "#partial model predictions\n",
    "y_partialmodelpred_list =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_partialmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_partialmodelpred_list = [a.squeeze().tolist() for a in y_partialmodelpred_list]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prints correct results\n",
    "fullmodelcounter=0\n",
    "partialmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "    if y_partialmodelpred_list[i]==y_test[i]:\n",
    "        partialmodelcounter=partialmodelcounter+1\n",
    "        \n",
    "print(\"full data full model correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "print(\"full data partial model correct: \",partialmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))\n",
    "\n",
    "\n",
    "print(\"Partial model statistics\")\n",
    "print(classification_report(y_test, y_partialmodelpred_list))\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0931f717",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained append model:\n",
      "Number correct full model:  179  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.94      0.95        88\n",
      "         1.0       0.95      0.96      0.96       100\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.95      0.95      0.95       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  176  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93        88\n",
      "         1.0       0.95      0.93      0.94       100\n",
      "\n",
      "    accuracy                           0.94       188\n",
      "   macro avg       0.94      0.94      0.94       188\n",
      "weighted avg       0.94      0.94      0.94       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer, train regularly\n",
    "\n",
    "normalappend=extra_inner_layer(trained)\n",
    "normaloptimappend = optim.Adam(normalappend.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalappend.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimappend.zero_grad()\n",
    "        \n",
    "        y_pred = normalappend(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimappend.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalappend.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalappend(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Trained append model:\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "#copy over first part of model\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layer.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77499cee",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained append layer and output\n",
      "Number correct:  163  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.95      0.87        88\n",
      "         1.0       0.95      0.79      0.86       100\n",
      "\n",
      "    accuracy                           0.87       188\n",
      "   macro avg       0.88      0.87      0.87       188\n",
      "weighted avg       0.88      0.87      0.87       188\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  179  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95        88\n",
      "         1.0       0.96      0.95      0.95       100\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.95      0.95      0.95       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#append layer and output, and train regularly\n",
    "\n",
    "\n",
    "normalextralayeroutput=append_layer_and_ouput(trained)\n",
    "normaloptimextraoutput = optim.Adam(normalextralayeroutput.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayeroutput.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextraoutput.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayeroutput(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextraoutput.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayeroutput.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayeroutput(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "print(\"Trained append layer and output\")        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_append_layeroutput.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_append_layeroutput.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_append_layeroutput.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_append_layeroutput.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_append_layeroutput.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_append_layeroutput.layer_6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef2f03a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained add middle layer\n",
      "Number correct:  180  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95        88\n",
      "         1.0       0.94      0.98      0.96       100\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.96      0.96      0.96       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Tained parial model;\n",
      "Number correct full model:  179  out of  188\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95        88\n",
      "         1.0       0.99      0.92      0.95       100\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.95      0.95      0.95       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#just add middle layer, and train regularly\n",
    "\n",
    "\n",
    "normalextralayer=extra_inner_layer(trained)\n",
    "normaloptimextra = optim.Adam(normalextralayer.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "normalextralayer.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        normaloptimextra.zero_grad()\n",
    "        \n",
    "        y_pred = normalextralayer(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        normaloptimextra.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "y_predlist =[]\n",
    "normalextralayer.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = normalextralayer(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "print(\"trained add middle layer\")        \n",
    "print(\"Number correct: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "firstlayers_model1.layer_1 = copy.deepcopy(trained_extra_inner_layer.layer_1)\n",
    "firstlayers_model1.layer_2 = copy.deepcopy(trained_extra_inner_layer.layer_2)\n",
    "firstlayers_model1.layer_3 = copy.deepcopy(trained_extra_inner_layer.layer_3)\n",
    "firstlayers_model1.layer_4 = copy.deepcopy(trained_extra_inner_layer.layer_4)\n",
    "firstlayers_model1.layer_5 = copy.deepcopy(trained_extra_inner_layer.layer_5)\n",
    "firstlayers_model1.layer_out = copy.deepcopy(trained_extra_inner_layer.layer_out)\n",
    "\n",
    "\n",
    "\n",
    "firstlayeroptimizer=optim.Adam(firstlayers_model1.parameters(), lr=LEARNING_RATE)\n",
    "firstlayers_model1.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        firstlayeroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = firstlayers_model1(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        firstlayeroptimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "y_predlist =[]\n",
    "firstlayers_model1.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = firstlayers_model1(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_predlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_predlist = [a.squeeze().tolist() for a in y_predlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_predlist)):\n",
    "    if y_predlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"Tained parial model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_predlist))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed861e4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Find and fix weights\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "\n",
    "\n",
    "#get weighs for seconds layer\n",
    "#print(repr(GroundTruth.layer_2.weight.detach().numpy()))\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "#print(GroundTruth.layer_2.weight)\n",
    "#print(GroundTruth.layer_3.weight)\n",
    "#print(GroundTruth.layer_4.weight)\n",
    "#print(GroundTruth.layer_5.weight)\n",
    "#print(GroundTruth.layer_out.weight)\n",
    "\n",
    "\n",
    "\n",
    "#bais1\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais2\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais3\n",
    "#print(\"BIASES\")\n",
    "#print(GroundTruth.layer_1.bias)\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "#print(GroundTruth.layer_3.bias)\n",
    "#print(GroundTruth.layer_4.bias)\n",
    "#print(GroundTruth.layer_5.bias)\n",
    "#print(GroundTruth.layer_out.bias)\n",
    "\n",
    "#Counts number of ground truths\n",
    "truthcount=0\n",
    "for i in y:\n",
    "    if i==1:\n",
    "        truthcount=truthcount+1\n",
    "        \n",
    "#print(truthcount)\n",
    "#print(len(y))\n",
    "#print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b38a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec8771",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
