{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ea6f4543",
   "metadata": {
    "code_folding": [
     17,
     82,
     442
    ]
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "weight1=[[ 0.1755, -0.2570,  0.0385,  0.1462,  0.2883,  0.2781, -0.1379,  0.1158,\n",
    "         -0.1919, -0.0646, -0.0471, -0.0156],\n",
    "        [-0.2780, -0.0346, -0.0423, -0.0192,  0.0237, -0.2446, -0.1018, -0.0863,\n",
    "         -0.1780, -0.0322,  0.0395, -0.0686],\n",
    "        [ 0.0131,  0.1255, -0.1127, -0.1981, -0.1835,  0.0722,  0.1823,  0.2723,\n",
    "          0.0513, -0.2855,  0.1316, -0.1696],\n",
    "        [-0.0497, -0.0984,  0.1085,  0.1532, -0.2375,  0.1417, -0.2586, -0.1358,\n",
    "          0.0341, -0.0997, -0.0787,  0.0409],\n",
    "        [ 0.1201, -0.0037, -0.2884, -0.2402,  0.0501, -0.1614,  0.2223, -0.2378,\n",
    "          0.1817, -0.0024, -0.1836, -0.1188],\n",
    "        [-0.1727, -0.2240, -0.1011, -0.2685,  0.0570,  0.0618, -0.2850,  0.0350,\n",
    "          0.0016,  0.1328,  0.1745,  0.0801],\n",
    "        [-0.1104,  0.0356, -0.0283,  0.2606,  0.0042, -0.0646,  0.1877,  0.1364,\n",
    "          0.2780, -0.2541,  0.1563,  0.1029],\n",
    "        [-0.1928,  0.0880, -0.1213, -0.0273, -0.1915, -0.2529, -0.2446,  0.2198,\n",
    "          0.1026,  0.2274,  0.0045,  0.1604],\n",
    "        [ 0.1652,  0.1710,  0.2616, -0.0825,  0.1951,  0.1821,  0.2456,  0.1081,\n",
    "          0.0301, -0.2318,  0.2580, -0.0573],\n",
    "        [ 0.1364, -0.0292, -0.0744, -0.0907,  0.1058,  0.1157,  0.2388,  0.0796,\n",
    "          0.1158,  0.0084,  0.2128,  0.0210],\n",
    "        [ 0.1604,  0.2220,  0.0842,  0.2679, -0.0843,  0.0605, -0.0670, -0.2639,\n",
    "         -0.0150,  0.0150, -0.2037, -0.2514],\n",
    "        [-0.0089,  0.0491,  0.1226, -0.0860, -0.1121, -0.1910, -0.2357,  0.0699,\n",
    "         -0.1888, -0.1078,  0.0412,  0.2289],\n",
    "        [-0.0206, -0.0538, -0.1791,  0.2310, -0.1596,  0.1924,  0.1579, -0.1252,\n",
    "          0.1196,  0.1946, -0.2477,  0.1508],\n",
    "        [-0.0030,  0.2120,  0.1650, -0.2089, -0.0828,  0.2771, -0.0191,  0.2882,\n",
    "         -0.0408,  0.0696,  0.1415,  0.1211],\n",
    "        [ 0.1383, -0.2456,  0.2203, -0.0988, -0.0480, -0.1860, -0.0910, -0.0173,\n",
    "          0.1389,  0.1787, -0.1565, -0.0454],\n",
    "        [ 0.0825, -0.2495,  0.0199, -0.1516, -0.0546, -0.1612,  0.0958,  0.1169,\n",
    "          0.2805, -0.1929, -0.2382, -0.0576],\n",
    "        [ 0.1657,  0.2029,  0.1196,  0.1923,  0.2699, -0.2536,  0.2233, -0.0572,\n",
    "          0.1496, -0.2070,  0.1400, -0.1925],\n",
    "        [ 0.0424, -0.2662,  0.0623,  0.0010,  0.2293, -0.0068,  0.2591,  0.1105,\n",
    "         -0.1155, -0.2614, -0.0868,  0.0706],\n",
    "        [-0.2461, -0.0747,  0.1883, -0.1401,  0.0099, -0.1938,  0.0972, -0.1003,\n",
    "          0.1023,  0.0880, -0.0653,  0.1812],\n",
    "        [-0.1996, -0.1321,  0.2133, -0.0652,  0.0106, -0.0003,  0.1960,  0.0935,\n",
    "          0.1206,  0.1486, -0.2597,  0.1292],\n",
    "        [ 0.1117,  0.0603, -0.0549,  0.0453, -0.2671, -0.2432,  0.1045, -0.2328,\n",
    "         -0.2563, -0.2162,  0.2178, -0.2527],\n",
    "        [-0.2194, -0.2653, -0.1610, -0.1484,  0.1053,  0.1584,  0.0756, -0.0072,\n",
    "         -0.0368,  0.0892, -0.0600, -0.0927],\n",
    "        [ 0.2175,  0.0518, -0.1016, -0.1835, -0.2244,  0.1488, -0.1371, -0.2737,\n",
    "         -0.1614,  0.1574, -0.2825,  0.0911],\n",
    "        [-0.2131,  0.0164,  0.2192, -0.2280, -0.2184,  0.2453,  0.1650, -0.2159,\n",
    "         -0.1101,  0.1906,  0.0813,  0.1277],\n",
    "        [-0.0464,  0.1360, -0.2583,  0.1041,  0.1836,  0.2348,  0.1200, -0.1623,\n",
    "          0.2172,  0.0367, -0.2090,  0.2012],\n",
    "        [ 0.2564, -0.0753, -0.1457,  0.0151, -0.1872,  0.1968,  0.2761, -0.2823,\n",
    "         -0.2437, -0.2031, -0.0219,  0.1329],\n",
    "        [ 0.0448, -0.2577, -0.0770,  0.0702, -0.1634, -0.2311,  0.2431,  0.0575,\n",
    "         -0.0601, -0.2515,  0.0626, -0.0047],\n",
    "        [-0.0257, -0.2529, -0.0004,  0.2239, -0.0466, -0.1740,  0.2376, -0.2353,\n",
    "         -0.1580,  0.1873,  0.1379,  0.2540],\n",
    "        [-0.2056, -0.0145, -0.0396, -0.1977,  0.0364,  0.1459, -0.0215,  0.2796,\n",
    "          0.1512, -0.2103, -0.2683, -0.2449],\n",
    "        [-0.1346, -0.1335, -0.2284, -0.1206,  0.0922,  0.0736, -0.1713, -0.0304,\n",
    "         -0.2532,  0.0417,  0.0963,  0.1357],\n",
    "        [ 0.1626, -0.1369, -0.1967,  0.1761,  0.1143,  0.1663, -0.0937,  0.1316,\n",
    "         -0.1512,  0.0046, -0.2807,  0.0974],\n",
    "        [-0.0426, -0.0162,  0.1179,  0.2693, -0.1982, -0.1447, -0.1375,  0.0577,\n",
    "          0.1636,  0.1197, -0.1751, -0.1339]]\n",
    "\n",
    "weight2=[[ 1.27629474e-01, -1.31778330e-01,  1.71449050e-01,\n",
    "         2.22478807e-03, -4.87338752e-02, -1.20451644e-01,\n",
    "         1.35281757e-01,  1.23455361e-01, -6.79472312e-02,\n",
    "         5.66107631e-02, -2.86271572e-02,  1.62933394e-01,\n",
    "        -1.71178475e-01,  1.36282101e-01, -1.58862978e-01,\n",
    "         1.09996453e-01, -1.32724911e-01,  1.01717755e-01,\n",
    "        -1.60561115e-01,  1.62114337e-01,  8.30418020e-02,\n",
    "         2.21399963e-02,  1.55852541e-01, -1.64892122e-01,\n",
    "         1.17871508e-01, -1.34546399e-01,  2.80110836e-02,\n",
    "         6.57359064e-02,  1.76134065e-01, -5.59099838e-02,\n",
    "        -8.06050003e-03, -1.32411331e-01],\n",
    "       [ 3.29570025e-02,  9.75792557e-02, -6.84635341e-03,\n",
    "        -1.17063165e-01, -6.36889860e-02,  2.66269296e-02,\n",
    "         1.19289830e-01, -1.65745914e-01, -1.66307390e-01,\n",
    "        -2.84630656e-02, -1.33916080e-01,  5.97212762e-02,\n",
    "        -8.25153962e-02, -1.49467647e-01,  1.18083701e-01,\n",
    "         8.99730176e-02,  1.26408651e-01,  9.04732496e-02,\n",
    "         5.76600134e-02, -1.55703515e-01, -6.20554984e-02,\n",
    "         7.23479688e-02, -2.44924873e-02,  1.26500145e-01,\n",
    "        -4.35967594e-02,  3.82994711e-02,  7.69918412e-02,\n",
    "        -1.70744389e-01, -4.23454195e-02, -1.68977529e-01,\n",
    "         7.19969124e-02, -4.14404720e-02],\n",
    "       [ 5.72970957e-02,  1.28512070e-01, -1.40462160e-01,\n",
    "        -1.39181957e-01,  7.63479918e-02,  5.27379066e-02,\n",
    "        -1.21493310e-01, -1.33433208e-01, -9.53319520e-02,\n",
    "         1.50765076e-01, -8.46173167e-02, -1.36514887e-01,\n",
    "         1.31110147e-01,  5.11740446e-02, -1.43955514e-01,\n",
    "         7.59825259e-02, -1.69412419e-01,  5.81420660e-02,\n",
    "         1.72124490e-01, -7.65271038e-02,  1.00781485e-01,\n",
    "        -7.86401182e-02, -1.12472422e-01, -1.37506634e-01,\n",
    "        -4.33554500e-02, -1.16912320e-01,  2.99481601e-02,\n",
    "         1.28245756e-01, -8.16366300e-02, -8.13894421e-02,\n",
    "         1.26093820e-01, -9.30750370e-03],\n",
    "       [ 7.29451925e-02,  1.55267432e-01,  1.43710241e-01,\n",
    "         1.76747575e-01,  3.46298367e-02,  1.39673248e-01,\n",
    "        -1.56485662e-01, -1.07996263e-01, -1.62375495e-01,\n",
    "        -8.54987800e-02,  1.36799589e-01,  1.61151811e-01,\n",
    "        -5.28158173e-02, -3.87751609e-02, -1.48643553e-03,\n",
    "        -1.37997895e-01,  5.03557473e-02,  3.63451242e-02,\n",
    "         1.71704590e-03,  5.90322465e-02, -1.38039589e-01,\n",
    "         5.58169484e-02, -1.65638268e-01,  2.54635811e-02,\n",
    "        -1.44617796e-01, -9.24392045e-02, -8.69494975e-02,\n",
    "         1.45661876e-01, -2.13428885e-02, -1.60664380e-01,\n",
    "        -4.50867563e-02, -6.81380481e-02],\n",
    "       [-1.37551457e-01, -1.00883096e-01, -1.73114240e-03,\n",
    "        -1.01298727e-01,  1.08535960e-01,  2.32054591e-02,\n",
    "         1.23837367e-01,  3.84520441e-02,  1.37854353e-01,\n",
    "         1.75179169e-01,  2.56374776e-02,  9.06508118e-02,\n",
    "        -3.38034630e-02, -7.04229325e-02,  1.30050853e-01,\n",
    "         4.31238711e-02,  8.48200470e-02,  1.07944921e-01,\n",
    "        -1.58502370e-01,  1.61808282e-02,  9.97866690e-03,\n",
    "        -1.77372843e-02, -1.56664178e-01, -1.95061564e-02,\n",
    "         4.62260097e-02, -1.37114659e-01,  1.47393718e-01,\n",
    "        -7.59116560e-02,  7.97533542e-02,  6.98903054e-02,\n",
    "        -1.33032396e-01,  7.01780021e-02],\n",
    "       [-6.78360015e-02,  3.87940705e-02, -8.11832771e-02,\n",
    "        -6.25082850e-02,  5.64767718e-02, -6.55565783e-02,\n",
    "        -1.62260532e-02, -1.65050611e-01,  5.10483831e-02,\n",
    "         1.31194815e-01, -6.33212999e-02, -5.94327003e-02,\n",
    "        -2.34071165e-02, -1.61033034e-01, -1.52289212e-01,\n",
    "        -7.73398429e-02, -1.12710342e-01,  1.05483577e-01,\n",
    "        -9.59148854e-02, -1.42431587e-01,  3.15563381e-02,\n",
    "        -3.07142586e-02, -1.27851486e-01, -1.63027197e-01,\n",
    "         1.30248353e-01,  1.32951275e-01, -1.28177881e-01,\n",
    "        -1.34356454e-01, -1.45125672e-01,  1.49312779e-01,\n",
    "         4.49740142e-02,  9.22075063e-02],\n",
    "       [-9.53312814e-02, -7.32915103e-03,  9.20717269e-02,\n",
    "        -2.70896703e-02,  1.74156681e-01, -2.48178989e-02,\n",
    "        -1.58585668e-01,  1.31829426e-01,  6.35453910e-02,\n",
    "         1.46818265e-01,  1.41249463e-01,  1.36781618e-01,\n",
    "        -3.56146544e-02,  7.06616938e-02, -1.35382533e-01,\n",
    "        -1.27738461e-01,  1.60587206e-01, -1.54897273e-01,\n",
    "         4.11511213e-02, -1.63946435e-01,  8.72904509e-02,\n",
    "        -5.21513820e-03, -3.01708579e-02,  1.09768406e-01,\n",
    "         1.40245706e-02,  1.29384920e-01, -4.05239761e-02,\n",
    "         1.76754639e-01,  1.44885331e-02,  6.63439035e-02,\n",
    "         9.99796242e-02, -7.79973343e-02],\n",
    "       [-3.81741971e-02, -1.11111738e-01, -6.48848414e-02,\n",
    "        -4.80047911e-02,  4.77659106e-02,  1.74313977e-01,\n",
    "        -1.73301995e-02,  9.52472538e-02,  1.00905880e-01,\n",
    "         5.74662536e-02, -3.27526033e-02, -3.15214396e-02,\n",
    "        -1.51412517e-01,  1.35939524e-01,  1.42856792e-01,\n",
    "         1.31871149e-01, -5.41912392e-02, -1.49409980e-01,\n",
    "        -7.27157220e-02,  7.01260567e-02, -1.90860033e-02,\n",
    "         1.06136039e-01, -1.36847869e-01,  9.89020020e-02,\n",
    "         7.95844644e-02,  1.58682689e-01,  4.21108305e-02,\n",
    "         1.54920369e-02,  1.75959811e-01,  1.46949440e-02,\n",
    "         1.34204432e-01, -1.66092724e-01],\n",
    "       [-5.71823120e-02,  1.53170958e-01, -8.00386369e-02,\n",
    "         1.22631267e-01,  5.01564145e-02, -8.97539034e-02,\n",
    "         7.45111704e-03, -1.54234886e-01,  7.97696561e-02,\n",
    "        -1.60794586e-01,  5.95291406e-02,  8.66737217e-02,\n",
    "        -1.07510142e-01, -1.07546069e-01, -1.16365656e-01,\n",
    "        -1.67479470e-01,  5.76500148e-02,  3.93328518e-02,\n",
    "        -1.51760980e-01, -4.57207263e-02,  9.30467397e-02,\n",
    "         6.32177144e-02, -1.33004263e-01,  4.51229364e-02,\n",
    "        -1.50223911e-01,  1.53514490e-01,  1.36355922e-01,\n",
    "        -1.65590912e-01,  2.80359387e-02,  1.07620016e-01,\n",
    "        -4.58864272e-02, -8.05888399e-02],\n",
    "       [ 2.84080654e-02,  1.65752903e-01, -1.78737789e-02,\n",
    "        -1.41755164e-01, -1.21222131e-01,  7.36540705e-02,\n",
    "        -1.18057787e-01,  3.62168550e-02, -1.42279714e-01,\n",
    "        -5.52533343e-02, -1.17457405e-01,  7.92297274e-02,\n",
    "        -1.39212593e-01,  1.10007837e-01,  9.56069678e-02,\n",
    "        -1.28516942e-01, -1.53153643e-01, -1.45395204e-01,\n",
    "        -1.54274181e-01, -7.87356868e-02, -1.85639560e-02,\n",
    "        -5.63965067e-02,  1.63845316e-01, -1.05672725e-01,\n",
    "        -1.02580182e-01,  5.82999289e-02, -4.26220745e-02,\n",
    "        -3.32562625e-02, -1.07623808e-01,  1.71803877e-01,\n",
    "        -1.67472497e-01,  5.55110276e-02],\n",
    "       [-1.71954751e-01,  3.10517102e-02, -4.70666438e-02,\n",
    "        -7.25035369e-03,  1.38118908e-01,  8.81171376e-02,\n",
    "        -6.99512661e-03,  9.79436487e-02, -1.63558170e-01,\n",
    "         7.59750158e-02, -1.48438022e-01,  4.19776142e-02,\n",
    "        -2.95872390e-02, -1.71351016e-01, -1.75833762e-01,\n",
    "         1.47757530e-02, -7.27425516e-03, -8.24442506e-02,\n",
    "        -1.18864328e-01, -1.41692668e-01,  1.28933832e-01,\n",
    "         1.53988764e-01,  1.91507041e-02,  5.00681102e-02,\n",
    "        -6.45779669e-02,  3.78124267e-02,  5.13678044e-02,\n",
    "        -1.41880214e-01,  1.18434802e-01,  1.03029907e-02,\n",
    "        -8.88237208e-02, -6.99049085e-02],\n",
    "       [ 1.14965886e-02, -2.42143869e-05,  7.84585327e-02,\n",
    "         7.89236873e-02,  1.44890085e-01, -1.74121231e-01,\n",
    "        -1.70519620e-01, -1.64695442e-01,  1.46179035e-01,\n",
    "        -1.76332906e-01, -1.20713815e-01, -1.04847826e-01,\n",
    "        -1.29557908e-01,  5.62533736e-02, -6.80477470e-02,\n",
    "         2.58508325e-02, -3.03201228e-02, -1.67707115e-01,\n",
    "        -8.39924067e-02,  1.52842894e-01,  1.51233748e-01,\n",
    "        -1.00887716e-02,  8.24704319e-02, -1.61362454e-01,\n",
    "         4.84096557e-02, -4.47705984e-02,  1.40126050e-03,\n",
    "        -1.37365744e-01,  7.88855702e-02, -9.39641222e-02,\n",
    "         1.42921999e-01, -1.50275379e-02],\n",
    "       [-6.77206293e-02, -6.53964430e-02,  1.31143048e-01,\n",
    "        -1.58728227e-01,  1.49895623e-01, -6.42335862e-02,\n",
    "        -1.17532447e-01,  1.68982282e-01,  7.78727680e-02,\n",
    "         1.06029674e-01, -1.57243520e-01, -1.74520060e-01,\n",
    "        -1.66893825e-01, -1.58807725e-01, -5.41851446e-02,\n",
    "        -1.56610668e-01, -1.16609305e-01,  6.98036104e-02,\n",
    "         3.03091705e-02,  1.63833931e-01, -1.47831604e-01,\n",
    "         1.18442282e-01, -1.31773740e-01,  1.46529868e-01,\n",
    "        -1.63009241e-01, -6.61279410e-02, -4.55395877e-02,\n",
    "        -1.38222232e-01, -1.73254326e-01,  6.75302744e-02,\n",
    "        -2.13995129e-02,  9.68673676e-02],\n",
    "       [-6.85989857e-03,  6.60400689e-02, -1.56355977e-01,\n",
    "        -1.02575712e-01,  6.60860687e-02,  2.28707790e-02,\n",
    "        -9.92798060e-02,  1.17531717e-02, -7.57347643e-02,\n",
    "        -2.41249204e-02, -5.78573346e-03,  1.74763903e-01,\n",
    "        -1.35469079e-01, -3.19746584e-02, -1.10154368e-01,\n",
    "         4.84129190e-02, -6.56707734e-02,  1.72686502e-01,\n",
    "         1.39927283e-01,  2.77900696e-02,  7.85932392e-02,\n",
    "        -2.35753804e-02, -1.33264393e-01,  1.55313835e-01,\n",
    "         1.26104519e-01,  1.49755850e-01, -7.01297224e-02,\n",
    "        -3.79087925e-02,  1.21726885e-01,  9.89482552e-02,\n",
    "         1.08525380e-01, -1.15129977e-01],\n",
    "       [-9.42576751e-02, -7.77093247e-02, -1.19175248e-01,\n",
    "        -1.45431459e-02, -6.02163374e-02,  3.79766524e-02,\n",
    "        -6.99921325e-02,  1.39973834e-01,  7.69166797e-02,\n",
    "         1.26222208e-01,  1.57789335e-01, -8.06198791e-02,\n",
    "         1.84617043e-02,  1.76324412e-01,  1.23838916e-01,\n",
    "        -5.82080036e-02, -7.05026090e-03,  1.64217129e-01,\n",
    "         1.86187476e-02,  7.30152577e-02, -7.21213669e-02,\n",
    "         2.97158957e-04, -1.21858843e-01, -3.53467762e-02,\n",
    "        -1.72216177e-01,  1.13735273e-01, -4.72023189e-02,\n",
    "        -9.72992852e-02,  1.61127314e-01,  5.30098379e-03,\n",
    "        -2.08841413e-02,  7.34210014e-03],\n",
    "       [ 1.51687115e-02, -2.18164921e-03,  1.70322254e-01,\n",
    "         5.99795133e-02,  9.69067961e-02,  4.15856391e-02,\n",
    "        -2.29961574e-02, -9.07074362e-02, -9.81525704e-02,\n",
    "         1.41958937e-01,  2.33927369e-03, -3.55740041e-02,\n",
    "        -1.02805875e-01, -1.31886035e-01, -1.09649025e-01,\n",
    "         1.47663638e-01, -1.18179992e-01,  1.53284073e-02,\n",
    "        -8.66443068e-02, -2.10960805e-02, -6.74357787e-02,\n",
    "         9.27140266e-02,  6.08879328e-03, -1.52147934e-01,\n",
    "        -4.25840914e-03, -1.75178528e-01,  1.12022594e-01,\n",
    "         3.35869640e-02, -8.72173384e-02, -1.67520627e-01,\n",
    "        -9.80542824e-02, -5.43836802e-02],\n",
    "       [-1.31426111e-01,  4.59180772e-02, -8.27657878e-02,\n",
    "         5.68144321e-02, -6.04465231e-02, -2.60045230e-02,\n",
    "        -1.56005144e-01, -1.32210359e-01,  1.25033543e-01,\n",
    "         2.02106386e-02, -1.14174381e-01, -1.29699633e-01,\n",
    "         2.97961831e-02,  1.20683149e-01, -1.61878884e-01,\n",
    "         5.79898953e-02, -1.72632471e-01, -1.46200731e-01,\n",
    "        -7.63071179e-02,  2.88335830e-02, -1.75289094e-01,\n",
    "        -9.61982384e-02,  4.57965136e-02, -2.86608636e-02,\n",
    "        -1.74851447e-01, -1.25703797e-01, -1.25498354e-01,\n",
    "        -3.22374105e-02,  5.07847965e-02,  8.32723081e-03,\n",
    "        -3.31037939e-02,  7.12889433e-02],\n",
    "       [-1.23270303e-01,  1.24513879e-01, -6.53075501e-02,\n",
    "         7.67080039e-02, -1.20259203e-01, -1.76342055e-01,\n",
    "        -1.66895971e-01, -5.08264452e-02,  1.19447693e-01,\n",
    "         1.22478232e-01,  1.03427246e-01, -4.39866781e-02,\n",
    "         1.74833015e-01, -7.03478307e-02, -1.63065761e-01,\n",
    "        -5.19542694e-02,  1.16469964e-01, -7.03503191e-03,\n",
    "         8.19690973e-02, -2.16715336e-02,  1.08137503e-01,\n",
    "         1.31440237e-01,  1.66336343e-01,  3.56864929e-02,\n",
    "        -1.21756785e-01, -7.11120665e-03,  9.27199423e-03,\n",
    "        -9.42975283e-04, -3.79077345e-02,  9.06833559e-02,\n",
    "        -1.74242124e-01, -1.05191834e-01],\n",
    "       [-1.39868200e-01,  9.97426361e-02, -1.28741980e-01,\n",
    "        -4.76077497e-02,  1.24750867e-01,  1.73248306e-01,\n",
    "         1.23738900e-01, -1.00728817e-01,  6.19019568e-02,\n",
    "        -1.73519641e-01, -6.36675730e-02, -1.48388192e-01,\n",
    "        -9.92986709e-02, -1.15152106e-01, -4.15238589e-02,\n",
    "         1.67336121e-01,  2.48195827e-02,  1.20971039e-01,\n",
    "         7.48842508e-02, -8.40895399e-02, -3.35667580e-02,\n",
    "        -1.37346044e-01,  1.16224423e-01,  1.25028715e-01,\n",
    "        -1.02307782e-01,  7.53673166e-02,  1.64821282e-01,\n",
    "        -2.34042257e-02,  1.15765288e-01,  7.40840286e-02,\n",
    "         1.03367701e-01, -1.20420203e-01],\n",
    "       [-2.87759304e-03,  1.48193672e-01,  2.98358202e-02,\n",
    "        -9.37118903e-02, -9.37090814e-03,  1.01241902e-01,\n",
    "         1.33033857e-01, -1.39054194e-01,  6.50592446e-02,\n",
    "         7.00934678e-02,  8.73153359e-02,  1.06705800e-01,\n",
    "        -1.21679947e-01, -1.58845380e-01,  1.09515294e-01,\n",
    "         1.63551912e-01,  1.73653662e-02, -1.29459769e-01,\n",
    "         1.25217661e-01,  9.58109647e-02, -3.75245214e-02,\n",
    "         1.67456120e-02,  1.36129633e-01, -1.69060975e-01,\n",
    "         5.68274856e-02, -3.19590122e-02, -1.61956325e-01,\n",
    "         7.31596798e-02, -9.42637250e-02,  1.43242583e-01,\n",
    "        -1.33465663e-01,  3.16010416e-03],\n",
    "       [-3.32054198e-02,  2.92927772e-02, -2.69370675e-02,\n",
    "        -1.76429480e-01, -8.27188566e-02,  1.58558205e-01,\n",
    "        -7.68804550e-03,  1.11775234e-01, -7.85116330e-02,\n",
    "         1.97091699e-02,  1.37582734e-01, -5.30521125e-02,\n",
    "         9.72483903e-02, -9.42739397e-02, -1.73257247e-01,\n",
    "        -2.31633633e-02, -1.73681065e-01,  2.44373679e-02,\n",
    "         7.02887475e-02,  6.21768683e-02,  1.65673897e-01,\n",
    "        -1.62939906e-01,  2.32852250e-02, -1.67442322e-01,\n",
    "        -3.48530561e-02,  4.37138230e-02, -1.33162901e-01,\n",
    "         3.69332582e-02, -1.37657672e-02, -2.68305540e-02,\n",
    "        -1.06697299e-01, -9.91751775e-02],\n",
    "       [ 1.04622051e-01,  1.69293210e-01, -8.34785104e-02,\n",
    "        -9.56396908e-02, -7.85784349e-02,  8.69245976e-02,\n",
    "         1.37094811e-01, -8.44289884e-02,  8.93820077e-02,\n",
    "        -1.73753202e-01,  9.39012319e-02,  7.36067444e-02,\n",
    "         3.20756435e-02,  1.57033727e-01,  1.33783743e-01,\n",
    "         1.14454791e-01, -3.49953771e-02,  1.37239382e-01,\n",
    "        -1.63650498e-01,  9.26706344e-02,  1.46069571e-01,\n",
    "         6.22469187e-03, -7.98297524e-02,  8.01405758e-02,\n",
    "        -7.34735280e-02, -2.31485218e-02,  1.52660459e-02,\n",
    "        -1.52131766e-01,  5.95473498e-02,  1.40747830e-01,\n",
    "         1.12309620e-01,  7.77307004e-02],\n",
    "       [-6.97436556e-02, -1.39679372e-01, -2.44318694e-02,\n",
    "        -3.38232219e-02, -1.11979991e-02, -6.55277893e-02,\n",
    "        -1.61129847e-01,  1.27724275e-01, -4.46563512e-02,\n",
    "        -8.54222402e-02, -6.94687739e-02,  9.63134021e-02,\n",
    "         1.27610698e-01,  1.03368416e-01, -6.03493750e-02,\n",
    "         7.95280933e-03,  4.30280715e-02, -1.59946799e-01,\n",
    "        -1.29964888e-01,  1.47566423e-01, -1.31595701e-01,\n",
    "         7.69326091e-03,  3.28045785e-02, -7.33831599e-02,\n",
    "        -1.12090260e-01,  1.40584871e-01, -1.37991324e-01,\n",
    "        -1.57583594e-01, -1.41217351e-01,  9.90435481e-03,\n",
    "         6.11100197e-02,  1.36166617e-01],\n",
    "       [ 1.39473662e-01,  4.79353815e-02, -6.04231656e-03,\n",
    "        -4.00660932e-02,  1.85126066e-03, -1.02690794e-01,\n",
    "        -1.54667974e-01,  1.22779027e-01,  1.66401491e-01,\n",
    "        -5.67205921e-02, -1.74904868e-01,  1.56710610e-01,\n",
    "        -1.17116421e-02, -6.81578368e-02, -5.55035025e-02,\n",
    "        -7.57259354e-02,  1.15881249e-01,  1.46519050e-01,\n",
    "         1.01794198e-01, -2.50525475e-02, -8.02612528e-02,\n",
    "         1.34058446e-02, -8.42480958e-02, -5.31573147e-02,\n",
    "        -1.76118091e-01,  5.68251759e-02, -1.18361816e-01,\n",
    "         6.25707209e-02,  4.94912118e-02, -1.63942263e-01,\n",
    "         7.67118484e-02,  5.44359684e-02],\n",
    "       [-1.68831274e-01, -7.79145136e-02,  1.00922480e-01,\n",
    "         6.12485409e-02,  1.44721717e-02,  9.16725248e-02,\n",
    "         6.77953511e-02,  1.18400916e-01,  1.25181392e-01,\n",
    "         1.06332675e-01, -2.91447341e-03,  7.98145384e-02,\n",
    "         1.25224993e-01,  8.18841308e-02, -2.94242352e-02,\n",
    "         3.03771049e-02, -1.30029619e-02, -8.33309144e-02,\n",
    "         7.72523433e-02, -3.62840295e-02,  1.27620250e-02,\n",
    "        -8.42599571e-02,  1.70098826e-01,  1.75932989e-01,\n",
    "         1.15735576e-01,  4.29428518e-02, -9.33934525e-02,\n",
    "         6.13673478e-02, -3.56159806e-02,  2.37410218e-02,\n",
    "         7.39205033e-02, -1.63908213e-01],\n",
    "       [ 6.42278194e-02,  4.98356819e-02, -1.51995063e-01,\n",
    "         1.97108388e-02,  5.71796149e-02, -8.62842053e-02,\n",
    "        -1.75012663e-01, -6.76420033e-02, -4.51730341e-02,\n",
    "         8.71377736e-02,  1.07556149e-01, -1.23861477e-01,\n",
    "         1.69953153e-01,  1.44737229e-01, -1.42851532e-01,\n",
    "        -7.46449158e-02, -1.49203241e-02,  2.99882442e-02,\n",
    "        -4.43404019e-02, -1.18210375e-01,  5.38144857e-02,\n",
    "        -5.21805808e-02, -5.11862338e-03, -8.26124176e-02,\n",
    "         1.40761063e-01, -3.94320637e-02,  5.54019064e-02,\n",
    "         7.96602666e-03, -1.14705324e-01,  1.37024894e-01,\n",
    "         3.15297842e-02,  1.40467808e-01],\n",
    "       [-1.26129672e-01,  3.93068939e-02, -3.19402665e-02,\n",
    "        -7.47411102e-02, -1.19698249e-01,  8.15828294e-02,\n",
    "        -2.29657739e-02,  5.62307686e-02, -4.03504074e-03,\n",
    "        -1.48346961e-01,  9.10789818e-02,  1.42225549e-01,\n",
    "        -1.60098135e-01, -7.56818503e-02,  2.97103822e-03,\n",
    "         9.38685387e-02, -3.12474817e-02, -8.99305195e-02,\n",
    "        -7.09399506e-02,  1.64154619e-02, -1.22148663e-01,\n",
    "        -2.65351683e-02, -1.18086301e-01, -4.32823002e-02,\n",
    "         1.39772341e-01,  1.75359979e-01, -5.08249402e-02,\n",
    "         1.61948964e-01, -9.47375596e-02, -1.26267701e-01,\n",
    "        -3.91015261e-02, -6.23729900e-02],\n",
    "       [ 1.67908117e-01,  6.39253855e-03, -6.24089465e-02,\n",
    "         1.50737271e-01, -1.32769346e-02, -1.01942033e-01,\n",
    "        -1.38617635e-01, -3.15942019e-02, -1.90685838e-02,\n",
    "        -1.40191033e-01, -1.36646777e-01,  1.76004454e-01,\n",
    "         7.93943256e-02, -1.19298317e-01,  1.08494535e-01,\n",
    "         1.71200588e-01, -7.28519410e-02,  3.93329561e-03,\n",
    "        -1.03180118e-01,  2.85829455e-02, -1.82565004e-02,\n",
    "        -1.32218450e-01,  1.17517456e-01,  1.24964252e-01,\n",
    "         1.62314102e-01,  3.53110731e-02,  7.16303587e-02,\n",
    "        -1.08745061e-01, -2.71909535e-02, -7.26120844e-02,\n",
    "        -1.78828388e-02,  2.05475390e-02],\n",
    "       [-1.05219372e-01, -5.87871820e-02,  1.43023178e-01,\n",
    "        -1.65066123e-03, -1.47593707e-01,  1.72386482e-01,\n",
    "        -6.99467212e-02,  9.03296918e-02, -9.58817825e-02,\n",
    "        -1.72109082e-01,  1.47940218e-02,  1.38347000e-02,\n",
    "         1.67123750e-01,  3.27003300e-02, -7.93855041e-02,\n",
    "         1.48451582e-01, -9.62084234e-02,  1.18502364e-01,\n",
    "        -1.27764881e-01, -1.68383569e-02, -1.68069676e-01,\n",
    "        -4.65090424e-02,  6.97893500e-02, -7.12470785e-02,\n",
    "         6.32639378e-02,  1.46723822e-01, -6.08719140e-02,\n",
    "         1.25373170e-01, -6.49152473e-02, -1.08080178e-01,\n",
    "         2.20777392e-02, -1.11142226e-01],\n",
    "       [ 3.41399312e-02,  4.56179082e-02, -9.84693840e-02,\n",
    "         3.81763428e-02,  7.49320537e-02,  1.55415162e-01,\n",
    "        -1.52769506e-01,  1.29208192e-01,  2.82798856e-02,\n",
    "         8.01424235e-02, -1.56163469e-01, -6.35774881e-02,\n",
    "        -3.40181291e-02, -4.87193763e-02,  1.01302907e-01,\n",
    "        -8.56658295e-02,  5.46399355e-02, -1.08963676e-01,\n",
    "        -4.64700162e-03, -9.44225490e-02,  1.70358077e-01,\n",
    "         4.43687439e-02,  2.90573239e-02, -1.76280290e-02,\n",
    "         1.12996802e-01,  1.04883745e-01,  1.52630940e-01,\n",
    "        -8.24765787e-02, -3.64928246e-02, -1.12814322e-01,\n",
    "        -1.04616888e-01,  5.68405688e-02],\n",
    "       [-4.49690372e-02,  4.23947126e-02, -8.34124908e-02,\n",
    "         4.51013595e-02,  1.53857812e-01,  1.53192833e-01,\n",
    "         1.58026516e-02, -1.15583301e-01, -3.23639810e-03,\n",
    "         2.64104009e-02, -7.38365352e-02,  1.06338277e-01,\n",
    "        -1.52044922e-01,  1.30661592e-01,  2.80750096e-02,\n",
    "        -9.69575346e-03,  1.08021006e-01,  6.69555217e-02,\n",
    "        -5.40371463e-02,  1.04573295e-01, -1.45686015e-01,\n",
    "        -1.04120903e-01, -1.39567435e-01,  8.29765946e-02,\n",
    "         1.49609253e-01, -1.07864588e-02,  3.44516784e-02,\n",
    "        -2.19865292e-02,  1.65960118e-01, -5.35379574e-02,\n",
    "        -1.15648001e-01,  4.42007929e-02],\n",
    "       [-9.80035588e-02, -1.49314523e-01,  1.19439796e-01,\n",
    "         1.17699012e-01,  8.20991248e-02, -5.85412160e-02,\n",
    "        -1.26304343e-01,  7.33705610e-02,  1.56773821e-01,\n",
    "         2.06111223e-02,  5.82780689e-02, -1.74617723e-01,\n",
    "        -1.25601709e-01,  6.36755228e-02, -1.21034786e-01,\n",
    "        -1.17746234e-01,  1.50086001e-01, -5.61209023e-03,\n",
    "         1.01187572e-01,  1.36203721e-01,  8.26239735e-02,\n",
    "        -8.01171735e-02, -1.60180524e-01, -1.99170262e-02,\n",
    "        -4.60562408e-02, -1.30015016e-02, -4.57886308e-02,\n",
    "         1.36866882e-01,  1.55913338e-01,  9.80716199e-02,\n",
    "         1.54807582e-01,  1.76288977e-01]]\n",
    "\n",
    "weight3=[[-0.0085,  0.1221,  0.0064, -0.1152, -0.0524, -0.0324, -0.1192, -0.0219,\n",
    "         -0.1684, -0.1212,  0.0453, -0.0631,  0.0411,  0.0217,  0.0725, -0.0133,\n",
    "          0.1247, -0.1404,  0.0053,  0.1541, -0.1276,  0.0561,  0.0085, -0.1356,\n",
    "          0.1281,  0.0357, -0.0203, -0.1021, -0.1089, -0.1207,  0.1108,  0.0786]]\n",
    "\n",
    "\n",
    "\n",
    "bias1=[-0.1882, -0.0524,  0.2718, -0.1533, -0.2459,  0.1016,  0.0690,  0.1408,\n",
    "        -0.0126, -0.1954, -0.0471,  0.1142, -0.0410, -0.0766,  0.1389,  0.0104,\n",
    "        -0.1107, -0.1808, -0.2448, -0.1975, -0.2694, -0.1557, -0.1829, -0.1509,\n",
    "         0.1714,  0.1606, -0.1026,  0.1599,  0.2751, -0.1825, -0.1093, -0.2679]\n",
    "\n",
    "bias2=[-0.0916,  0.0866, -0.0381, -0.0028,  0.1009,  0.0988,  0.1590, -0.0264,\n",
    "         0.1566, -0.1291,  0.0514,  0.0069, -0.0260,  0.0311,  0.1604, -0.0198,\n",
    "         0.0731, -0.1475, -0.0842,  0.0811,  0.0716,  0.0086, -0.0653, -0.0314,\n",
    "        -0.0280,  0.1131,  0.1015,  0.1643, -0.0151, -0.0142,  0.1359,  0.0166]\n",
    "\n",
    "bias3=[0.0135]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f554690d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#model class\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(12, 32) #layer 1\n",
    "        self.layer_2 = nn.Linear(32, 32) #layer 2 input matches output of prev layer\n",
    "        #self.layer_3 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(32, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        #self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        #x = self.relu(self.layer_3(x))\n",
    "        #x = self.batchnorm3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "70c00927",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a6cfc5ef",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#accuracy calculatory rounds output to 0 or 1\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fd55f044",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "df = pd.read_csv(\"Dataset_spine.csv\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.iloc[:, 0:-1] #input columns\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled)) #format data for input\n",
    "Truth_loader = DataLoader(dataset=X_formatted, batch_size=1) #format data for input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GroundTruth = binaryClassification()\n",
    "#set weights to \"evenly distributed\" 0, 1\n",
    "GroundTruth.layer_1.weight=torch.nn.Parameter(data=torch.tensor(weight1), requires_grad=True)\n",
    "GroundTruth.layer_2.weight=torch.nn.Parameter(data=torch.tensor(weight2), requires_grad=True)\n",
    "GroundTruth.layer_out.weight=torch.nn.Parameter(data=torch.tensor(weight3), requires_grad=True)\n",
    "\n",
    "GroundTruth.layer_1.bias=torch.nn.Parameter(data=torch.tensor(bias1), requires_grad=True)\n",
    "GroundTruth.layer_2.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_out.bias=torch.nn.Parameter(data=torch.tensor(bias3), requires_grad=True)\n",
    "\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "\n",
    "\n",
    "truth_list = []\n",
    "GroundTruth.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truth_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = GroundTruth(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = torch.round(y_truth)\n",
    "        truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "#print(y)\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "#print(y_train)\n",
    "#rescale data \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "EPOCHS = 50 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    ()\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0e9f2376",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#train trained model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "#print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcffbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset untrained model\n",
    "untrained=binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0ba2e261",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.90      0.80        42\n",
      "         1.0       0.92      0.75      0.83        61\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.82      0.83      0.81       103\n",
      "weighted avg       0.84      0.82      0.82       103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.31      0.30        42\n",
      "         1.0       0.49      0.46      0.47        61\n",
      "\n",
      "    accuracy                           0.40       103\n",
      "   macro avg       0.39      0.38      0.39       103\n",
      "weighted avg       0.41      0.40      0.40       103\n",
      "\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]\n",
      "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
      "trained correct:  84\n",
      "untrained correct:  41\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n"
     ]
    }
   ],
   "source": [
    "#prints results\n",
    "y_trainedpred_list = []\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_trainedpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_trainedpred_list = [a.squeeze().tolist() for a in y_trainedpred_list]\n",
    "confusion_matrix(y_test, y_trainedpred_list)\n",
    "print(classification_report(y_test, y_trainedpred_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#untrained results\n",
    "y_untrainedpred_list = []\n",
    "untrained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = untrained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrainedpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_untrainedpred_list = [a.squeeze().tolist() for a in y_untrainedpred_list]\n",
    "confusion_matrix(y_test, y_untrainedpred_list)\n",
    "print(classification_report(y_test, y_untrainedpred_list))\n",
    "\n",
    "\n",
    "print(y_untrainedpred_list)\n",
    "print(y_trainedpred_list)\n",
    "\n",
    "trainedcounter=0\n",
    "untrainedcounter=0\n",
    "for i in range(len(y_trainedpred_list)):\n",
    "    if y_trainedpred_list[i]==y_test[i]:\n",
    "        trainedcounter=trainedcounter+1       \n",
    "    if y_untrainedpred_list[i]==y_test[i]:\n",
    "        untrainedcounter=untrainedcounter+1\n",
    "        \n",
    "print(\"trained correct: \",trainedcounter)\n",
    "print(\"untrained correct: \",untrainedcounter)\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4e1ccd86",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0135], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Find and fix weights\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "\n",
    "\n",
    "#get weighs for seconds layer\n",
    "#print(repr(GroundTruth.layer_2.weight.detach().numpy()))\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_out.weight)\n",
    "\n",
    "\n",
    "#bais1\n",
    "#print(GroundTruth.layer_1.bias)\n",
    "\n",
    "\n",
    "#bais2\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais3\n",
    "#print(GroundTruth.layer_out.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7ecb3998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "#Counts number of ground truths\n",
    "truthcount=0\n",
    "for i in y:\n",
    "    if i==1:\n",
    "        truthcount=truthcount+1\n",
    "        \n",
    "print(truthcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51853dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
