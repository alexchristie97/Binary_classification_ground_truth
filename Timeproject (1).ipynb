{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     38,
     44,
     63,
     82,
     108,
     151,
     208,
     238,
     256,
     338,
     359,
     516,
     571,
     583
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "    \n",
    "THRESH_HOLD=5e-8            #MSE value when we consider the second model to have \"cracked\" the first\n",
    "EPOCHS = 25                 #number of passes of whole data\n",
    "BATCH_SIZE =  64            #size of data going through at once\n",
    "LEARNING_RATE = 0.01        #how much we shift parameters during back prop\n",
    "NEURONS=5                    #number of nodes in each layer\n",
    "XSIZE=  577                 #size of each data set generated\n",
    "BADLOSSPASSES=1000          #number of times we have small loss until we stop code\n",
    "TESTMODULE_LAYERS=10        #number of layers in cracking module\n",
    "#GROUND_TRUTH_LAYERS=5       #number of layers in ground thruth models\n",
    "\n",
    "    \n",
    "def get_Xvals():\n",
    "    return (np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getdata_XY():\n",
    "    X=(np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "#trains a network, returns time spent training \n",
    "def trainnetwork(network, train_loader, optimizer, Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #X_batch = X_batch.astype(np.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = network(X_batch)\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')\n",
    "        #rint(\"Ave Loss: \", epoch_loss)\n",
    "        #rint(\"size \", len(train_loader))\n",
    "        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "\n",
    "#returns next ground truth model\n",
    "#model obtained by taking average of models with better times than previous model \n",
    "def get_new_GroundTruth(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    \n",
    "    layer1_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer1_weight=layer1_weight+i.layer_1.weight/(len(better_model_list))\n",
    "        \n",
    "    layer1_weight.requires_grad_()\n",
    "    newGroundTruth.layer_1.weight=torch.nn.Parameter(layer1_weight)\n",
    "\n",
    "    layer2_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer2_weight=layer2_weight+i.layer_2.weight/(len(better_model_list))\n",
    "        \n",
    "    layer2_weight.requires_grad_()\n",
    "    newGroundTruth.layer_2.weight=torch.nn.Parameter(layer2_weight)\n",
    "    \n",
    "    \n",
    "    layer3_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer3_weight=layer3_weight+i.layer_3.weight/(len(better_model_list))\n",
    "        \n",
    "    layer3_weight.requires_grad_()\n",
    "    newGroundTruth.layer_3.weight=torch.nn.Parameter(layer3_weight)\n",
    "    \n",
    "    layer4_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer4_weight=layer4_weight+i.layer_4.weight/(len(better_model_list))\n",
    "        \n",
    "    layer4_weight.requires_grad_()\n",
    "    newGroundTruth.layer_4.weight=torch.nn.Parameter(layer4_weight)\n",
    "    \n",
    "    layer5_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer5_weight=layer5_weight+i.layer_5.weight/(len(better_model_list))\n",
    "        \n",
    "    layer5_weight.requires_grad_()\n",
    "    newGroundTruth.layer_5.weight=torch.nn.Parameter(layer5_weight)\n",
    "    \n",
    "                \n",
    "    layeroutput_weight=torch.tensor([[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layeroutput_weight=layeroutput_weight+i.layer_out.weight/(len(better_model_list))\n",
    "        \n",
    "    layeroutput_weight.requires_grad_()\n",
    "    newGroundTruth.layer_out.weight=torch.nn.Parameter(layeroutput_weight)\n",
    "    \n",
    "    return newGroundTruth\n",
    "\n",
    "#checks accuracy of model\n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    total_lossconfirm=0\n",
    "    #criterion = nn.MSELoss()\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            #loss = criterion(y_pred_tag, torch.tensor([y]))\n",
    "\n",
    "            \n",
    "            #print(\"y \", y)\n",
    "            #print(\"pred \", y_pred_tag.cpu().numpy())\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "            #total_lossconfirm=total_lossconfirm+loss.item()\n",
    "    \n",
    "    #total_loss=np.sqrt(total_loss)/len(truth)\n",
    "    total_loss=total_loss/len(truth)\n",
    "    total_lossconfirm=total_lossconfirm/len(truth)\n",
    "    #print(\"current loss: \", total_loss)\n",
    "    #print(\"current confirm loss: \", total_lossconfirm)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True, total_loss[0][0]\n",
    "    else:\n",
    "        return False, total_loss[0][0]\n",
    "        \n",
    "        \n",
    "def evalnetwork(network, test_loader, stats=True):\n",
    "    y_pred_list =[]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            y_test_pred = network(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            #y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    if(stats):\n",
    "        statistics(y_pred_list)\n",
    "    return y_pred_list\n",
    "\n",
    "def statistics(y_pred_list):\n",
    "    correctcounter=0\n",
    "    for i in range(len(y_pred_list)):\n",
    "        if y_pred_list[i]==y_test[i]:\n",
    "            correctcounter=correctcounter+1       \n",
    "\n",
    "    print(\"# correct: \",correctcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Model statistics\")\n",
    "    print(classification_report(y_test, y_pred_list))    \n",
    "    \n",
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, NEURONS) \n",
    "        self.layer_2 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_3 = nn.Linear(NEURONS, NEURONS)\n",
    "        self.layer_4 = nn.Linear(NEURONS,NEURONS)\n",
    "        self.layer_5 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_out = nn.Linear(NEURONS, 1) #output layer\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #elf.layer_input=nn.Linear(5, OUTPUT)\n",
    "        #elf.layer_1=nn.ModuleList([nn.Linear(OUTPUT, 1) for i in range(TESTMODULE_LAYERS)])\n",
    "        #elf.layer_2=nn.ModuleList([nn.Linear(OUTPUT, 1) for i in range(TESTMODULE_LAYERS)])\n",
    "        #elf.layer_3=nn.ModuleList([nn.Linear(OUTPUT, 1) for i in range(TESTMODULE_LAYERS)])\n",
    "        #elf.layer_4=nn.ModuleList([nn.Linear(OUTPUT, 1) for i in range(TESTMODULE_LAYERS)])\n",
    "        #elf.layer_5=nn.ModuleList([nn.Linear(OUTPUT, 1) for i in range(TESTMODULE_LAYERS)])\n",
    "        \n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #activitation function.\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "        #dropout randomly zeros coordinates with probability p during training\n",
    "        #standard practice. meant to prevent dependence of neurons.\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        #batchnorm centers data the input into each layer will be ~gaussian\n",
    "        #keeps running mean and standard deviation from training.\n",
    "        self.batchnorm1 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        #standard forward feed network.\n",
    "        #x-->layer-->activation-->normalize and dropout-->next layer\n",
    "        x = torch.sigmoid(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = torch.sigmoid(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = torch.sigmoid(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = torch.sigmoid(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = torch.sigmoid(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "     \n",
    "    #returns deep copy of model\n",
    "    def get_copy(self):\n",
    "        copied_model=binaryClassification()\n",
    "        copied_model.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        copied_model.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        copied_model.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        copied_model.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        copied_model.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        copied_model.layer_out = copy.deepcopy(self.layer_out)\n",
    "        copied_model.batchnorm1=copy.deepcopy(self.batchnorm1)\n",
    "        copied_model.batchnorm2=copy.deepcopy(self.batchnorm2)\n",
    "        copied_model.batchnorm3=copy.deepcopy(self.batchnorm3)\n",
    "        copied_model.batchnorm4=copy.deepcopy(self.batchnorm4)\n",
    "        copied_model.batchnorm5=copy.deepcopy(self.batchnorm5)\n",
    "\n",
    "        \n",
    "          \n",
    "        return copied_model\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    def change_node_modellinear(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=[1.0]*5\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #changes a random weight from a random layer.\n",
    "    #all layers linear so represeented as matrices. adds a guassian weight to random component\n",
    "    def change_node_model(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        perturb=np.random.normal(0, 1)\n",
    "        weightchange=[[0.0]*5]*5\n",
    "        if node[0]!=5:\n",
    "            weightchange[node[1][0]][node[1][1]]=perturb\n",
    "            \n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            newweight=self.layer_1.weight+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            newweight=self.layer_2.weight+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            \n",
    "        elif node[0]==4:\n",
    "            newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "           \n",
    "        else:\n",
    "            weightchange=[[0.0]*5]\n",
    "            weightchange[0][node[1]]=perturb\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "def select_node():\n",
    "    layer=randrange(6)\n",
    "    if layer!=5:\n",
    "        node=[randrange(5), randrange(5)]\n",
    "    else:\n",
    "        node=randrange(5)\n",
    "    return [layer, node]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class arbitraryLayerModel(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(arbitraryLayerModel, self).__init__()\n",
    "        self.layer_input=nn.Linear(5, NEURONS)\n",
    "        self.layers=nn.ModuleList([nn.Linear(NEURONS, NEURONS) for i in range(num_layers)])\n",
    "        self.batchnorms=nn.ModuleList([nn.BatchNorm1d(NEURONS) for i in range(num_layers)])\n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def get_copy(self):\n",
    "        copied_model=arbitraryLayerModel()\n",
    "        copied_model.layers=nn.ModuleList()\n",
    "        for i in self.layers:\n",
    "            copied_model.layers.append(copy.deepcopy(i))\n",
    "            \n",
    "        copied_model.batchnorms=nn.ModuleList()\n",
    "        for i in self.batchnorms:\n",
    "            copied_model.batchnorms.append(copy.deepcopy(i))\n",
    "        copied_model.layer_input=copy.deepcopy(self.layer_input)\n",
    "        copied_model.layer_output=copy.deepcopy(self.layer_output)\n",
    "\n",
    "        return copied_model\n",
    "            \n",
    "     \n",
    "    def forward(self, inputs):\n",
    "        x=self.relu(self.layer_input(inputs))\n",
    "        for (layer, batchnorm) in zip(self.layers, self.batchnorms):\n",
    "            x=batchnorm(x)\n",
    "            x=self.relu(layer(x))\n",
    "            x=self.dropout(x)\n",
    "        x=self.layer_output(x)\n",
    "        return(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=self.get_copy()\n",
    "        \n",
    "        weightchange=np.random.normal(0,1)\n",
    "        weightchange=[weightchange.item()]\n",
    "        zeros=[[0]]*(NEURONS-1)\n",
    "        if node[0]==0:\n",
    "            zeros.insert(weightchange, node[1])\n",
    "            newweight=self.layer_input.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_input.weight=torch.nn.Parameter(newweight)    \n",
    "            return changed_node\n",
    "            \n",
    "            \n",
    "        weightchange=np.random.normal(0, 1, size=NEURONS)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "        zeros = [[0.0]*NEURONS]*(NEURONS-1)\n",
    "        \n",
    "        if node[0]==TESTMODULE_LAYERS+1:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight) \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            for layer, i in enumerate(changed_node.layers):\n",
    "                if i==node[0]+1:\n",
    "                    zeros.insert(weightchange,node[1])\n",
    "                    newweight=layer.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "                    newweight.requires_grad_()\n",
    "                    layer.weight=torch.nn.Parameter(newweight)\n",
    "                    \n",
    "        \n",
    "\n",
    "        return changed_node\n",
    "\n",
    "    \n",
    "    \n",
    "             \n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b1a1f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Linear combo 5d guassian weight (cracking model has double layers)\n",
    "       \n",
    "#groundtruth model  \n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=arbitraryLayerModel()\n",
    "possible_infinite_time=arbitraryLayerModel()\n",
    "\n",
    "\n",
    "\n",
    "test_model=arbitraryLayerModel()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(1e-6):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==10:\n",
    "        print(\"No increase for 10 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983e056",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#linear combo 1 weight guassian weight\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "firstmodeltrained=binaryClassification()\n",
    "test_model_optimizer = optim.Adam(firstmodeltrained.parameters(), lr=LEARNING_RATE)\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader,test_model_optimizer)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    \n",
    "    test_model_list=[binaryClassification() for i in range(10)]\n",
    "    for i in range(0, 10):\n",
    "        total_time=0\n",
    "        infinite_time_counter=0\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "\n",
    "        for j, test_model in enumerate(test_model_list):\n",
    "            current_loss=0\n",
    "            previous_loss=0\n",
    "            train_testmodel=test_model.get_copy()\n",
    "            test_model_optimizer = optim.Adam(train_testmodel.parameters(), lr=LEARNING_RATE)\n",
    "            data_counter=0\n",
    "            test_time=0\n",
    "            inital_data_length=len(data_list)\n",
    "            accepted=False\n",
    "            loss_difference_counter=0\n",
    "            Model_beaten=False\n",
    "\n",
    "            while(not accepted): \n",
    "                #use previously generated data\n",
    "                if data_counter<inital_data_length:\n",
    "                    X=data_list[data_counter]\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    previous_loss=current_loss\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "                    data_counter=data_counter+1\n",
    "                #generate new data if needed\n",
    "                else:                          \n",
    "                    X=get_Xvals()\n",
    "                    data_list.append(X)\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                    previous_loss=current_loss\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "\n",
    "\n",
    "                #print(current_loss)\n",
    "\n",
    "                #checks if loss difference is small\n",
    "                if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                    loss_difference_counter=loss_difference_counter+1\n",
    "                    if loss_difference_counter>25:\n",
    "                        infinite_time_counter=infinite_time_counter+1\n",
    "                        print(\"Test model beaten. Total beaten by prospective ground truth: \", infinite_time_counter)\n",
    "                        Model_beaten=True\n",
    "                    elif loss_difference_counter>5:\n",
    "                        print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    " \n",
    "\n",
    "                \n",
    "                if Model_beaten:\n",
    "                    break\n",
    "\n",
    "\n",
    "            total_time=total_time+test_time\n",
    "            #print(\"Iteration: \", interationcounter, \" | Ground truth number: \", i+1,\" | Test model number: \", j+1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        print(\"Iteration: \", interationcounter, \" | Ground truth number: \", i+1)\n",
    "\n",
    "        if infinite_time_counter==10:\n",
    "            print(\"Potential unbreakable found\")\n",
    "            possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "            break\n",
    "        time_list.append(total_time/(10))\n",
    "\n",
    "        \n",
    "           \n",
    "    \n",
    "    if infinite_time_counter==10:\n",
    "        break\n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    time_increase=max_new_time-current_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==10:\n",
    "        print(\"No increase for 10 iterations\")\n",
    "    #    time_increase=False\n",
    " \n",
    "      \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef9797",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define specific groundtruth\n",
    "GroundTruth = binaryClassification()\n",
    "weightchange=np.random.normal(0, 1, size=(5,5))\n",
    "weightchange=[[j.item()*10 for j in i] for i in weightchange]\n",
    "ones=[1.0]*5\n",
    "zeros=[[0.0]*5]\n",
    "\n",
    "newweight=GroundTruth.layer_1.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "newweight.requires_grad_()\n",
    "GroundTruth.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "GroundTruth.layer_2.weight=torch.nn.Parameter(torch.diag(torch.tensor(ones)))\n",
    "GroundTruth.layer_3.weight=torch.nn.Parameter(torch.diag(torch.tensor(ones)))\n",
    "GroundTruth.layer_4.weight=torch.nn.Parameter(torch.diag(torch.tensor(ones)))\n",
    "GroundTruth.layer_5.weight=torch.nn.Parameter(torch.diag(torch.tensor(ones)))\n",
    "GroundTruth.layer_out.weight=torch.nn.Parameter(torch.tensor([[1.0]*5]))\n",
    "\n",
    "\n",
    "GroundTruth.layer_1.bias=torch.nn.Parameter(torch.tensor(zeros))\n",
    "GroundTruth.layer_2.bias=torch.nn.Parameter(torch.tensor(zeros))\n",
    "GroundTruth.layer_3.bias=torch.nn.Parameter(torch.tensor(zeros))\n",
    "GroundTruth.layer_4.bias=torch.nn.Parameter(torch.tensor(zeros))\n",
    "GroundTruth.layer_5.bias=torch.nn.Parameter(torch.tensor(zeros))\n",
    "GroundTruth.layer_out.bias=torch.nn.Parameter(torch.tensor([[0.0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124815e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Check specific groundtruth model\n",
    "beaten_model_counter=0\n",
    "for i in range(10):\n",
    "    test_model=arbitraryLayerModel()\n",
    "    test_model_optimizer = optim.Adam(test_model.parameters(), lr=LEARNING_RATE)\n",
    "    accepted=False\n",
    "    current_time=0\n",
    "    data_list=[]\n",
    "\n",
    "    loss_difference_counter=0\n",
    "    current_loss=0\n",
    "    previous_loss=0\n",
    "    Model_beaten=False \n",
    "    thresh_hold_check_counter=0\n",
    "    while((not accepted)):\n",
    "        X, y=getdata_XY()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "        train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "        test_data = testData(torch.FloatTensor(X_test))\n",
    "        train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "        test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "        data_list.append(X)\n",
    "        current_time=current_time+trainnetwork(test_model, train_loader,test_model_optimizer)\n",
    "        previous_loss=current_loss\n",
    "        accepted, current_loss=check_threshhold(test_model, test_loader, y_test)\n",
    "        loss_diff=previous_loss-current_loss\n",
    "        thresh_hold_check_counter=thresh_hold_check_counter+1\n",
    "        if abs(loss_diff)<(1e-5) or thresh_hold_check_counter>30:\n",
    "            loss_difference_counter=loss_difference_counter+1\n",
    "            if loss_difference_counter>25:\n",
    "                print(\"Test model beaten\")\n",
    "                Model_beaten=True\n",
    "            elif loss_difference_counter>5:\n",
    "                print(f'Number no loss change {loss_difference_counter}: | Current time: {current_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "        if Model_beaten:\n",
    "            beaten_model_counter=beaten_model_counter+1\n",
    "            print(\"Number of beaten models: \",beaten_model_counter, \"Current Model number: \", i+1)\n",
    "            break\n",
    "    if not Model_beaten:\n",
    "        print(\"Test model not beaten\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[0]*5]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43500d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e288f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
