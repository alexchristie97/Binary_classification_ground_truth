{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6f4543",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "weight1=[[ 0.1642,  0.2455, -0.3093, -0.4260, -0.1927],\n",
    "        [ 0.1405,  0.2877,  0.1791,  0.2886,  0.0281],\n",
    "        [-0.4129,  0.2434, -0.3342,  0.0638,  0.0898],\n",
    "        [ 0.3933,  0.3019,  0.0625,  0.2342, -0.4222],\n",
    "        [-0.3019,  0.1200, -0.1640, -0.1984, -0.1032]]\n",
    "\n",
    "weight2=[[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0],[1.0,1.0,1.0,1.0,1.0]]\n",
    "\n",
    "weight4=[[-0.0068,  0.1320, -0.4003,  0.0965, -0.4061],\n",
    "        [ 0.2241,  0.1185,  0.0251, -0.0104, -0.0224],\n",
    "        [ 0.4361, -0.0875,  0.0647,  0.3484,  0.4034],\n",
    "        [ 0.1191, -0.3272,  0.2531,  0.2740, -0.3526],\n",
    "        [ 0.3558, -0.0614, -0.2608, -0.1395, -0.0635]]\n",
    "\n",
    "\n",
    "weight5=[[-0.0115,  0.1046,  0.2259,  0.1117, -0.0206],\n",
    "        [-0.4093, -0.2933, -0.3829, -0.2851,  0.1360],\n",
    "        [ 0.1195,  0.3427,  0.4183,  0.1673,  0.1913],\n",
    "        [-0.2937, -0.2824,  0.1436, -0.2029,  0.1594],\n",
    "        [ 0.0140,  0.1943, -0.2809,  0.2599,  0.0647]]\n",
    "\n",
    "weightout=[[.50,.50,.50,.50,.50]]\n",
    "bias1=[ 0.1889, -0.4299,  0.0239,  0.3833, -0.2821]\n",
    "bias2=[0.0,.0,0.0,0.0,0.0]\n",
    "#weight2\n",
    "#bias3=\n",
    "#bias4=\n",
    "#bias5=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(5, 5) #layer 1\n",
    "        self.layer_2 = nn.Linear(5, 5) #layer 2 input matches output of prev layer\n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4= nn.Linear(5,5)\n",
    "        self.layer_5=nn.Linear(5,5)\n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4= nn.BatchNorm1d(5)\n",
    "        self.batchnorm5= nn.BatchNorm1d(5)\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c00927",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cfc5ef",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#accuracy calculatory rounds output to 0 or 1\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "df = pd.read_csv(\"Breast_cancer_data.csv\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df.iloc[:, 0:-1] #input columns\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled)) #format data for input\n",
    "Truth_loader = DataLoader(dataset=X_formatted, batch_size=1) #format data for input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GroundTruth = binaryClassification()\n",
    "#set weights to \"evenly distributed\" 0, 1\n",
    "GroundTruth.layer_1.weight=torch.nn.Parameter(data=torch.tensor(weight1), requires_grad=True)\n",
    "GroundTruth.layer_2.weight=torch.nn.Parameter(data=torch.tensor(weight2), requires_grad=True)\n",
    "GroundTruth.layer_3.weight=torch.nn.Parameter(data=torch.tensor(weight2), requires_grad=True)\n",
    "GroundTruth.layer_4.weight=torch.nn.Parameter(data=torch.tensor(weight4), requires_grad=True)\n",
    "GroundTruth.layer_5.weight=torch.nn.Parameter(data=torch.tensor(weight5), requires_grad=True)\n",
    "GroundTruth.layer_out.weight=torch.nn.Parameter(data=torch.tensor(weightout), requires_grad=True)\n",
    "\n",
    "GroundTruth.layer_1.bias=torch.nn.Parameter(data=torch.tensor(bias1), requires_grad=True)\n",
    "GroundTruth.layer_2.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_3.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_4.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_5.bias=torch.nn.Parameter(data=torch.tensor(bias2), requires_grad=True)\n",
    "GroundTruth.layer_out.bias=torch.nn.Parameter(data=torch.tensor([-3.0]),requires_grad=True)\n",
    "\n",
    "\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "\n",
    "\n",
    "truth_list = []\n",
    "GroundTruth.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truth_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = GroundTruth(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = torch.round(y_truth)\n",
    "        truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "#print(y)\n",
    "\n",
    "#split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "#print(y_train)\n",
    "#rescale data \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "EPOCHS = 50 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    ()\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9f2376",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#train trained model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "#print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "#train trained model\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset untrained model\n",
    "untrained=binaryClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba2e261",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.93      0.72        88\n",
      "         1.0       0.88      0.43      0.58       100\n",
      "\n",
      "    accuracy                           0.66       188\n",
      "   macro avg       0.73      0.68      0.65       188\n",
      "weighted avg       0.74      0.66      0.65       188\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      1.00      0.64        88\n",
      "         1.0       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.47       188\n",
      "   macro avg       0.23      0.50      0.32       188\n",
      "weighted avg       0.22      0.47      0.30       188\n",
      "\n",
      "trained correct:  125\n",
      "untrained correct:  88\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n"
     ]
    }
   ],
   "source": [
    "#prints results\n",
    "y_trainedpred_list = []\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_trainedpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_trainedpred_list = [a.squeeze().tolist() for a in y_trainedpred_list]\n",
    "confusion_matrix(y_test, y_trainedpred_list)\n",
    "print(classification_report(y_test, y_trainedpred_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#untrained results\n",
    "y_untrainedpred_list = []\n",
    "untrained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = untrained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrainedpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_untrainedpred_list = [a.squeeze().tolist() for a in y_untrainedpred_list]\n",
    "confusion_matrix(y_test, y_untrainedpred_list)\n",
    "print(classification_report(y_test, y_untrainedpred_list))\n",
    "\n",
    "\n",
    "#print(y_untrainedpred_list)\n",
    "#print(y_trainedpred_list)\n",
    "\n",
    "trainedcounter=0\n",
    "untrainedcounter=0\n",
    "for i in range(len(y_trainedpred_list)):\n",
    "    if y_trainedpred_list[i]==y_test[i]:\n",
    "        trainedcounter=trainedcounter+1       \n",
    "    if y_untrainedpred_list[i]==y_test[i]:\n",
    "        untrainedcounter=untrainedcounter+1\n",
    "        \n",
    "print(\"trained correct: \",trainedcounter)\n",
    "print(\"untrained correct: \",untrainedcounter)\n",
    "\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e1ccd86",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Find and fix weights\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_1.weight)\n",
    "\n",
    "\n",
    "#get weighs for seconds layer\n",
    "#print(repr(GroundTruth.layer_2.weight.detach().numpy()))\n",
    "\n",
    "#layer 1 weights\n",
    "#print(GroundTruth.layer_out.weight)\n",
    "\n",
    "\n",
    "#bais1\n",
    "#print(GroundTruth.layer_1.bias)\n",
    "\n",
    "\n",
    "#bais2\n",
    "#print(GroundTruth.layer_2.bias)\n",
    "\n",
    "\n",
    "#bais3\n",
    "#print(GroundTruth.layer_out.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ecb3998",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#counts number of groundtruth values\n",
    "truthcount=0\n",
    "for i in y:\n",
    "    if i==1:\n",
    "        truthcount=truthcount+1\n",
    "        \n",
    "#print(truthcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51853dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4c151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
