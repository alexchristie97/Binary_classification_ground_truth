{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     45,
     64,
     83,
     95,
     107,
     116,
     231,
     261,
     283,
     295,
     314,
     379,
     406,
     432,
     458,
     492,
     505
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "\n",
    "THRESH_HOLD=.05\n",
    "EPOCHS = 25 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.001\n",
    "NEURONS=5\n",
    "XSIZE=3168\n",
    "#NUMBER_ITERATIONS=10\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def get_Xvals():\n",
    "    return np.normal.random(0, 1, size=(10000, 5))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getdata_XY():\n",
    "    X=np.random.normal(0, 1, size=(10000, 5))\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def trainnetwork(network, train_loader,Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #X_batch = X_batch.astype(np.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = network(X_batch)\n",
    "            #y_pred = network(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')\n",
    "        #rint(\"Ave Loss: \", epoch_loss)\n",
    "        #rint(\"size \", len(train_loader))\n",
    "        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "\n",
    "\n",
    "def get_new_GroundTruth(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    \n",
    "    layer1_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer1_weight=layer1_weight+i.layer_1.weight/(len(better_model_list))\n",
    "        \n",
    "    layer1_weight.requires_grad_()\n",
    "    newGroundTruth.layer_1.weight=torch.nn.Parameter(layer1_weight)\n",
    "\n",
    "    layer2_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer2_weight=layer2_weight+i.layer_2.weight/(len(better_model_list))\n",
    "        \n",
    "    layer2_weight.requires_grad_()\n",
    "    newGroundTruth.layer_2.weight=torch.nn.Parameter(layer2_weight)\n",
    "    \n",
    "    \n",
    "    layer3_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer3_weight=layer3_weight+i.layer_3.weight/(len(better_model_list))\n",
    "        \n",
    "    layer3_weight.requires_grad_()\n",
    "    newGroundTruth.layer_3.weight=torch.nn.Parameter(layer3_weight)\n",
    "    \n",
    "    layer4_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer4_weight=layer4_weight+i.layer_4.weight/(len(better_model_list))\n",
    "        \n",
    "    layer4_weight.requires_grad_()\n",
    "    newGroundTruth.layer_4.weight=torch.nn.Parameter(layer4_weight)\n",
    "    \n",
    "    layer5_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer5_weight=layer5_weight+i.layer_5.weight/(len(better_model_list))\n",
    "        \n",
    "    layer5_weight.requires_grad_()\n",
    "    newGroundTruth.layer_5.weight=torch.nn.Parameter(layer5_weight)\n",
    "    \n",
    "                \n",
    "    layeroutput_weight=torch.tensor([[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layeroutput_weight=layeroutput_weight+i.layer_out.weight/(len(better_model_list))\n",
    "        \n",
    "    layeroutput_weight.requires_grad_()\n",
    "    newGroundTruth.layer_out.weight=torch.nn.Parameter(layeroutput_weight)\n",
    "    \n",
    "    return newGroundTruth\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    total_lossconfirm=0\n",
    "    criterion = nn.MSELoss()\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            loss = criterion(y_pred_tag, torch.tensor([y]))\n",
    "\n",
    "            \n",
    "            #print(\"y \", y)\n",
    "            #print(\"pred \", y_pred_tag.cpu().numpy())\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "            total_lossconfirm=total_lossconfirm+loss.item()\n",
    "    \n",
    "    #total_loss=np.sqrt(total_loss)/len(truth)\n",
    "    total_loss=total_loss/len(truth)\n",
    "    total_lossconfirm=total_lossconfirm/len(truth)\n",
    "    print(\"current loss: \", total_loss)\n",
    "    print(\"current confirm loss: \", total_lossconfirm)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "        \n",
    "def evalnetwork(network, test_loader, stats=True):\n",
    "    y_pred_list =[]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            y_test_pred = network(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    if(stats):\n",
    "        statistics(y_pred_list)\n",
    "    #return y_fullmodelpred_list\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def statistics(y_pred_list):\n",
    "    correctcounter=0\n",
    "    for i in range(len(y_pred_list)):\n",
    "        if y_pred_list[i]==y_test[i]:\n",
    "            correctcounter=correctcounter+1       \n",
    "\n",
    "    print(\"# correct: \",correctcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Model statistics\")\n",
    "    print(classification_report(y_test, y_pred_list))    \n",
    "    \n",
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, NEURONS) \n",
    "        self.layer_2 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_3 = nn.Linear(NEURONS, NEURONS)\n",
    "        self.layer_4 = nn.Linear(NEURONS,NEURONS)\n",
    "        self.layer_5 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_out = nn.Linear(NEURONS, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        #self.batchnorm1 = nn.BatchNorm1d(NEURONS)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(NEURONS)\n",
    "        #self.batchnorm3 = nn.BatchNorm1d(NEURONS)\n",
    "        #self.batchnorm4 = nn.BatchNorm1d(NEURONS)\n",
    "        #self.batchnorm5 = nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        #x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        #x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        #x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        #x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        #x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "     \n",
    "    def get_copy(self):\n",
    "        copied_model=binaryClassification()\n",
    "        copied_model.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        copied_model.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        copied_model.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        copied_model.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        copied_model.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        copied_model.layer_out = copy.deepcopy(self.layer_out)\n",
    "        return copied_model\n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=np.random.normal(0, 1, size=5)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "def select_node():\n",
    "    layer=randrange(5)\n",
    "    if layer!=6:\n",
    "        node=randrange(5)\n",
    "    else:\n",
    "        node=randrange(2)\n",
    "    return [layer, node]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def change_node_modellinear(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=[1.0]*5\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e304a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss:  [[0.04032014]]\n",
      "current confirm loss:  0.0403201908979452\n",
      "loss at 0 : 0.003270771209429313\n",
      "10.486868143081665\n"
     ]
    }
   ],
   "source": [
    "#add Guassian weight, take lincombo\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "    MSE_at_0=torch.sigmoid(GroundTruth(torch.tensor([0.0]*5)))-torch.sigmoid(test_model(torch.tensor([0.0]*5)))\n",
    "    MSE_at_0=MSE_at_0.item()**2\n",
    "    \n",
    "    print(\"loss at 0 :\", MSE_at_0)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(current_time)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a0143",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss:  [[0.04032303]]\n",
      "current confirm loss:  0.0403230316316088\n",
      "current loss:  [[0.04032259]]\n",
      "current confirm loss:  0.040322578947878246\n",
      "current loss:  [[0.04019855]]\n",
      "current confirm loss:  0.040198499322163336\n",
      "current loss:  [[0.04069774]]\n",
      "current confirm loss:  0.04069779558841026\n",
      "current loss:  [[0.04027421]]\n",
      "current confirm loss:  0.04027423541541352\n",
      "current loss:  [[0.0476684]]\n",
      "current confirm loss:  0.0476684344322844\n",
      "current loss:  [[0.03663478]]\n",
      "current confirm loss:  0.03663474045693874\n",
      "current loss:  [[0.04040384]]\n",
      "current confirm loss:  0.04040383984419432\n",
      "current loss:  [[0.04041904]]\n",
      "current confirm loss:  0.04041906097508741\n",
      "current loss:  [[0.04033352]]\n",
      "current confirm loss:  0.040333542719934924\n",
      "[10.624905824661255, 10.404668807983398, 10.395946979522705, 10.382790327072144, 10.390247106552124, 10.531948804855347, 10.45015549659729, 10.443061590194702, 10.851318597793579, 10.530945539474487]\n",
      "current loss:  [[0.04183781]]\n",
      "current confirm loss:  0.04183779868777051\n",
      "current loss:  [[0.04213979]]\n",
      "current confirm loss:  0.0421398209577257\n",
      "current loss:  [[0.04231172]]\n",
      "current confirm loss:  0.04231162147991585\n",
      "current loss:  [[0.04210805]]\n",
      "current confirm loss:  0.04210801937250477\n",
      "current loss:  [[0.04224165]]\n",
      "current confirm loss:  0.04224162951789119\n",
      "current loss:  [[0.04225414]]\n",
      "current confirm loss:  0.042254114660123986\n",
      "current loss:  [[0.0422209]]\n",
      "current confirm loss:  0.04222091336367708\n",
      "current loss:  [[0.04274186]]\n",
      "current confirm loss:  0.04274184433574026\n"
     ]
    }
   ],
   "source": [
    "#iterates\n",
    "\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                data_counter=data_counter+1\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "\n",
    "            #print(test_time)\n",
    "        time_list.append(test_time)\n",
    "    \n",
    "    \n",
    "    print(time_list)\n",
    "    max_new_time=max(time_list)\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "                      \n",
    "    if no_increasecounter==3:\n",
    "        time_increase=False\n",
    " \n",
    "                                 \n",
    "        \n",
    "                          \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf9c0e8",
   "metadata": {
    "code_folding": [
     0,
     12,
     27,
     42
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.73229\n",
      "Epoch 002: | Loss: 0.44874\n",
      "Epoch 003: | Loss: 0.24310\n",
      "Epoch 004: | Loss: 0.11759\n",
      "Epoch 005: | Loss: 0.05941\n",
      "Epoch 006: | Loss: 0.03801\n",
      "Epoch 007: | Loss: 0.03335\n",
      "Epoch 008: | Loss: 0.03083\n",
      "Epoch 009: | Loss: 0.03013\n",
      "Epoch 010: | Loss: 0.02765\n",
      "Epoch 011: | Loss: 0.02733\n",
      "Epoch 012: | Loss: 0.02600\n",
      "Epoch 013: | Loss: 0.02434\n",
      "Epoch 014: | Loss: 0.02493\n",
      "Epoch 015: | Loss: 0.02086\n",
      "Epoch 016: | Loss: 0.01907\n",
      "Epoch 017: | Loss: 0.01865\n",
      "Epoch 018: | Loss: 0.01611\n",
      "Epoch 019: | Loss: 0.01474\n",
      "Epoch 020: | Loss: 0.01551\n",
      "Epoch 021: | Loss: 0.01362\n",
      "Epoch 022: | Loss: 0.01217\n",
      "Epoch 023: | Loss: 0.01143\n",
      "Epoch 024: | Loss: 0.00987\n",
      "Epoch 025: | Loss: 0.00856\n",
      "Epoch 026: | Loss: 0.00800\n",
      "Epoch 027: | Loss: 0.00782\n",
      "Epoch 028: | Loss: 0.00680\n",
      "Epoch 029: | Loss: 0.00578\n",
      "Epoch 030: | Loss: 0.00497\n",
      "Epoch 031: | Loss: 0.00440\n",
      "Epoch 032: | Loss: 0.00400\n",
      "Epoch 033: | Loss: 0.00356\n",
      "Epoch 034: | Loss: 0.00319\n",
      "Epoch 035: | Loss: 0.00258\n",
      "Epoch 036: | Loss: 0.00239\n",
      "Epoch 037: | Loss: 0.00213\n",
      "Epoch 038: | Loss: 0.00188\n",
      "Epoch 039: | Loss: 0.00151\n",
      "Epoch 040: | Loss: 0.00128\n",
      "Epoch 041: | Loss: 0.00116\n",
      "Epoch 042: | Loss: 0.00093\n",
      "Epoch 043: | Loss: 0.00082\n",
      "Epoch 044: | Loss: 0.00065\n",
      "Epoch 045: | Loss: 0.00062\n",
      "Epoch 046: | Loss: 0.00048\n",
      "Epoch 047: | Loss: 0.00047\n",
      "Epoch 048: | Loss: 0.00037\n",
      "Epoch 049: | Loss: 0.00031\n",
      "Epoch 050: | Loss: 0.00028\n",
      "current loss:  [[0.00667181]]\n",
      "1\n",
      "Epoch 001: | Loss: 0.00011\n",
      "Epoch 002: | Loss: 0.00002\n",
      "Epoch 003: | Loss: 0.00001\n",
      "Epoch 004: | Loss: 0.00000\n",
      "Epoch 005: | Loss: 0.00000\n",
      "Epoch 006: | Loss: 0.00000\n",
      "Epoch 007: | Loss: 0.00000\n",
      "Epoch 008: | Loss: 0.00000\n",
      "Epoch 009: | Loss: 0.00000\n",
      "Epoch 010: | Loss: 0.00000\n",
      "Epoch 011: | Loss: 0.00000\n",
      "Epoch 012: | Loss: 0.00000\n",
      "Epoch 013: | Loss: 0.00000\n",
      "Epoch 014: | Loss: 0.00000\n",
      "Epoch 015: | Loss: 0.00000\n",
      "Epoch 016: | Loss: 0.00000\n",
      "Epoch 017: | Loss: 0.00000\n",
      "Epoch 018: | Loss: 0.00000\n",
      "Epoch 019: | Loss: 0.00000\n",
      "Epoch 020: | Loss: 0.00000\n",
      "Epoch 021: | Loss: 0.00000\n",
      "Epoch 022: | Loss: 0.00000\n",
      "Epoch 023: | Loss: 0.00000\n",
      "Epoch 024: | Loss: 0.00000\n",
      "Epoch 025: | Loss: 0.00000\n",
      "Epoch 026: | Loss: 0.00000\n",
      "Epoch 027: | Loss: 0.00000\n",
      "Epoch 028: | Loss: 0.00000\n",
      "Epoch 029: | Loss: 0.00000\n",
      "Epoch 030: | Loss: 0.00000\n",
      "Epoch 031: | Loss: 0.00000\n",
      "Epoch 032: | Loss: 0.00000\n",
      "Epoch 033: | Loss: 0.00000\n",
      "Epoch 034: | Loss: 0.00000\n",
      "Epoch 035: | Loss: 0.00000\n",
      "Epoch 036: | Loss: 0.00000\n",
      "Epoch 037: | Loss: 0.00000\n",
      "Epoch 038: | Loss: 0.00000\n",
      "Epoch 039: | Loss: 0.00000\n",
      "Epoch 040: | Loss: 0.00000\n",
      "Epoch 041: | Loss: 0.00000\n",
      "Epoch 042: | Loss: 0.00000\n",
      "Epoch 043: | Loss: 0.00000\n",
      "Epoch 044: | Loss: 0.00000\n",
      "Epoch 045: | Loss: 0.00000\n",
      "Epoch 046: | Loss: 0.00000\n",
      "Epoch 047: | Loss: 0.00000\n",
      "Epoch 048: | Loss: 0.00000\n",
      "Epoch 049: | Loss: 0.00000\n",
      "Epoch 050: | Loss: 0.00000\n",
      "current loss:  [[0.00670763]]\n",
      "2\n",
      "Epoch 001: | Loss: 0.00000\n",
      "Epoch 002: | Loss: 0.00000\n",
      "Epoch 003: | Loss: 0.00000\n",
      "Epoch 004: | Loss: 0.00000\n",
      "Epoch 005: | Loss: 0.00000\n",
      "Epoch 006: | Loss: 0.00000\n",
      "Epoch 007: | Loss: 0.00000\n",
      "Epoch 008: | Loss: 0.00000\n",
      "Epoch 009: | Loss: 0.00000\n",
      "Epoch 010: | Loss: 0.00000\n",
      "Epoch 011: | Loss: 0.00000\n",
      "Epoch 012: | Loss: 0.00000\n",
      "Epoch 013: | Loss: 0.00000\n",
      "Epoch 014: | Loss: 0.00000\n",
      "Epoch 015: | Loss: 0.00000\n",
      "Epoch 016: | Loss: 0.00000\n",
      "Epoch 017: | Loss: 0.00000\n",
      "Epoch 018: | Loss: 0.00000\n",
      "Epoch 019: | Loss: 0.00000\n",
      "Epoch 020: | Loss: 0.00000\n",
      "Epoch 021: | Loss: 0.00000\n",
      "Epoch 022: | Loss: 0.00000\n",
      "Epoch 023: | Loss: 0.00000\n",
      "Epoch 024: | Loss: 0.00000\n",
      "Epoch 025: | Loss: 0.00000\n",
      "Epoch 026: | Loss: 0.00000\n",
      "Epoch 027: | Loss: 0.00000\n",
      "Epoch 028: | Loss: 0.00000\n",
      "Epoch 029: | Loss: 0.00000\n",
      "Epoch 030: | Loss: 0.00000\n",
      "Epoch 031: | Loss: 0.00000\n",
      "Epoch 032: | Loss: 0.00000\n",
      "Epoch 033: | Loss: 0.00000\n",
      "Epoch 034: | Loss: 0.00000\n",
      "Epoch 035: | Loss: 0.00000\n",
      "Epoch 036: | Loss: 0.00000\n",
      "Epoch 037: | Loss: 0.00000\n",
      "Epoch 038: | Loss: 0.00000\n",
      "Epoch 039: | Loss: 0.00000\n",
      "Epoch 040: | Loss: 0.00000\n",
      "Epoch 041: | Loss: 0.00000\n",
      "Epoch 042: | Loss: 0.00000\n",
      "Epoch 043: | Loss: 0.00000\n",
      "Epoch 044: | Loss: 0.00000\n",
      "Epoch 045: | Loss: 0.00000\n",
      "Epoch 046: | Loss: 0.00000\n",
      "Epoch 047: | Loss: 0.00000\n",
      "Epoch 048: | Loss: 0.00000\n",
      "Epoch 049: | Loss: 0.00000\n",
      "Epoch 050: | Loss: 0.00000\n",
      "current loss:  [[0.00671066]]\n",
      "3\n",
      "Epoch 001: | Loss: 0.00000\n",
      "Epoch 002: | Loss: 0.00000\n",
      "Epoch 003: | Loss: 0.00000\n",
      "Epoch 004: | Loss: 0.00000\n",
      "Epoch 005: | Loss: 0.00000\n",
      "Epoch 006: | Loss: 0.00000\n",
      "Epoch 007: | Loss: 0.00000\n",
      "Epoch 008: | Loss: 0.00000\n",
      "Epoch 009: | Loss: 0.00000\n",
      "Epoch 010: | Loss: 0.00000\n",
      "Epoch 011: | Loss: 0.00000\n",
      "Epoch 012: | Loss: 0.00000\n",
      "Epoch 013: | Loss: 0.00000\n",
      "Epoch 014: | Loss: 0.00000\n",
      "Epoch 015: | Loss: 0.00000\n",
      "Epoch 016: | Loss: 0.00000\n",
      "Epoch 017: | Loss: 0.00000\n",
      "Epoch 018: | Loss: 0.00000\n",
      "Epoch 019: | Loss: 0.00000\n",
      "Epoch 020: | Loss: 0.00000\n",
      "Epoch 021: | Loss: 0.00000\n",
      "Epoch 022: | Loss: 0.00000\n",
      "Epoch 023: | Loss: 0.00000\n",
      "Epoch 024: | Loss: 0.00000\n",
      "Epoch 025: | Loss: 0.00000\n",
      "Epoch 026: | Loss: 0.00000\n",
      "Epoch 027: | Loss: 0.00000\n",
      "Epoch 028: | Loss: 0.00000\n",
      "Epoch 029: | Loss: 0.00000\n",
      "Epoch 030: | Loss: 0.00000\n",
      "Epoch 031: | Loss: 0.00000\n",
      "Epoch 032: | Loss: 0.00000\n",
      "Epoch 033: | Loss: 0.00000\n",
      "Epoch 034: | Loss: 0.00000\n",
      "Epoch 035: | Loss: 0.00000\n",
      "Epoch 036: | Loss: 0.00000\n",
      "Epoch 037: | Loss: 0.00000\n",
      "Epoch 038: | Loss: 0.00000\n",
      "Epoch 039: | Loss: 0.00000\n",
      "Epoch 040: | Loss: 0.00000\n",
      "Epoch 041: | Loss: 0.00000\n",
      "Epoch 042: | Loss: 0.00000\n",
      "Epoch 043: | Loss: 0.00000\n",
      "Epoch 044: | Loss: 0.00000\n",
      "Epoch 045: | Loss: 0.00000\n",
      "Epoch 046: | Loss: 0.00000\n",
      "Epoch 047: | Loss: 0.00000\n",
      "Epoch 048: | Loss: 0.00000\n",
      "Epoch 049: | Loss: 0.00000\n",
      "Epoch 050: | Loss: 0.00000\n",
      "current loss:  [[0.00670657]]\n",
      "4\n",
      "Epoch 001: | Loss: 0.00000\n",
      "Epoch 002: | Loss: 0.00000\n",
      "Epoch 003: | Loss: 0.00000\n",
      "Epoch 004: | Loss: 0.00000\n",
      "Epoch 005: | Loss: 0.00000\n",
      "Epoch 006: | Loss: 0.00000\n",
      "Epoch 007: | Loss: 0.00000\n",
      "Epoch 008: | Loss: 0.00000\n",
      "Epoch 009: | Loss: 0.00000\n",
      "Epoch 010: | Loss: 0.00000\n",
      "Epoch 011: | Loss: 0.00000\n",
      "Epoch 012: | Loss: 0.00000\n",
      "Epoch 013: | Loss: 0.00000\n",
      "Epoch 014: | Loss: 0.00000\n",
      "Epoch 015: | Loss: 0.00000\n",
      "Epoch 016: | Loss: 0.00000\n",
      "Epoch 017: | Loss: 0.00000\n",
      "Epoch 018: | Loss: 0.00000\n",
      "Epoch 019: | Loss: 0.00000\n",
      "Epoch 020: | Loss: 0.00000\n",
      "Epoch 021: | Loss: 0.00000\n",
      "Epoch 022: | Loss: 0.00000\n",
      "Epoch 023: | Loss: 0.00000\n",
      "Epoch 024: | Loss: 0.00000\n",
      "Epoch 025: | Loss: 0.00000\n",
      "Epoch 026: | Loss: 0.00000\n",
      "Epoch 027: | Loss: 0.00000\n",
      "Epoch 028: | Loss: 0.00000\n",
      "Epoch 029: | Loss: 0.00000\n",
      "Epoch 030: | Loss: 0.00000\n",
      "Epoch 031: | Loss: 0.00000\n",
      "Epoch 032: | Loss: 0.00000\n",
      "Epoch 033: | Loss: 0.00000\n",
      "Epoch 034: | Loss: 0.00000\n",
      "Epoch 035: | Loss: 0.00000\n",
      "Epoch 036: | Loss: 0.00000\n",
      "Epoch 037: | Loss: 0.00000\n",
      "Epoch 038: | Loss: 0.00000\n",
      "Epoch 039: | Loss: 0.00000\n",
      "Epoch 040: | Loss: 0.00000\n",
      "Epoch 041: | Loss: 0.00000\n",
      "Epoch 042: | Loss: 0.00000\n",
      "Epoch 043: | Loss: 0.00000\n",
      "Epoch 044: | Loss: 0.00000\n",
      "Epoch 045: | Loss: 0.00000\n",
      "Epoch 046: | Loss: 0.00000\n",
      "Epoch 047: | Loss: 0.00000\n",
      "Epoch 048: | Loss: 0.00000\n",
      "Epoch 049: | Loss: 0.00000\n",
      "Epoch 050: | Loss: 0.00000\n",
      "current loss:  [[0.00671612]]\n",
      "5\n",
      "Epoch 001: | Loss: 0.00000\n",
      "Epoch 002: | Loss: 0.00000\n",
      "Epoch 003: | Loss: 0.00000\n",
      "Epoch 004: | Loss: 0.00000\n",
      "Epoch 005: | Loss: 0.00000\n",
      "Epoch 006: | Loss: 0.00000\n",
      "Epoch 007: | Loss: 0.00000\n",
      "Epoch 008: | Loss: 0.00000\n",
      "Epoch 009: | Loss: 0.00000\n",
      "Epoch 010: | Loss: 0.00000\n",
      "Epoch 011: | Loss: 0.00000\n",
      "Epoch 012: | Loss: 0.00000\n",
      "Epoch 013: | Loss: 0.00000\n",
      "Epoch 014: | Loss: 0.00000\n",
      "Epoch 015: | Loss: 0.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cc83469efdb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdata_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mcurrent_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_time\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtrainnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirstmodeltrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0maccepted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_threshhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirstmodeltrained\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-359d12d96ebb>\u001b[0m in \u001b[0;36mtrainnetwork\u001b[1;34m(network, train_loader, Time)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m#y_pred = network(X_batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-359d12d96ebb>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;31m#x = self.batchnorm2(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;31m#x = self.batchnorm3(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#add [1]*5, take lincombo\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "while(not accepted):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    print(len(data_list))\n",
    "       \n",
    "print(current_time)\n",
    "\n",
    "time_increase=1\n",
    "while(time_increase>.01):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_modellinear(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                data_counter=data_counter+1\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "\n",
    "            #print(test_time)\n",
    "        time_list.append(test_time)\n",
    "    \n",
    "    \n",
    "    print(time_list)\n",
    "    max_new_time=max(time_list)\n",
    "    GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "    time_increase=max_new_time-current_time\n",
    "    current_time=max_new_time\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "                      \n",
    "                          \n",
    " \n",
    "                                 \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c9a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
