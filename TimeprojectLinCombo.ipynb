{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0,
     38,
     44,
     63,
     82,
     94,
     106,
     157,
     213,
     243,
     261,
     329,
     485,
     524,
     551,
     577,
     603,
     649
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "    \n",
    "THRESH_HOLD=5e-7            #MSE value when we consider the second model to have \"cracked\" the first\n",
    "EPOCHS = 25                 #number of passes of whole data\n",
    "BATCH_SIZE = 64             #size of data going through at once\n",
    "LEARNING_RATE = 0.01       #how much we shift parameters during back prop\n",
    "NEURONS=5                   #number of nodes in each layer\n",
    "XSIZE=528                   #size of each data set generated\n",
    "BADLOSSPASSES=1000          #number of times we have small loss until we stop code\n",
    "TESTMODULE_LAYERS=10        #number of layers in cracking module\n",
    "GROUND_TRUTH_LAYERS=5       #number of layers in ground thruth models\n",
    "\n",
    "    \n",
    "def get_Xvals():\n",
    "    return (np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getdata_XY():\n",
    "    X=(np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def trainnetwork(network, train_loader, optimizer, Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #X_batch = X_batch.astype(np.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = torch.sigmoid(network(X_batch))\n",
    "            #y_pred = network(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')\n",
    "        #rint(\"Ave Loss: \", epoch_loss)\n",
    "        #rint(\"size \", len(train_loader))\n",
    "        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "\n",
    "\n",
    "def get_new_GroundTruth(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    \n",
    "    layer1_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer1_weight=layer1_weight+i.layer_1.weight/(len(better_model_list))\n",
    "        \n",
    "    layer1_weight.requires_grad_()\n",
    "    newGroundTruth.layer_1.weight=torch.nn.Parameter(layer1_weight)\n",
    "\n",
    "    layer2_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer2_weight=layer2_weight+i.layer_2.weight/(len(better_model_list))\n",
    "        \n",
    "    layer2_weight.requires_grad_()\n",
    "    newGroundTruth.layer_2.weight=torch.nn.Parameter(layer2_weight)\n",
    "    \n",
    "    \n",
    "    layer3_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer3_weight=layer3_weight+i.layer_3.weight/(len(better_model_list))\n",
    "        \n",
    "    layer3_weight.requires_grad_()\n",
    "    newGroundTruth.layer_3.weight=torch.nn.Parameter(layer3_weight)\n",
    "    \n",
    "    layer4_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer4_weight=layer4_weight+i.layer_4.weight/(len(better_model_list))\n",
    "        \n",
    "    layer4_weight.requires_grad_()\n",
    "    newGroundTruth.layer_4.weight=torch.nn.Parameter(layer4_weight)\n",
    "    \n",
    "    layer5_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer5_weight=layer5_weight+i.layer_5.weight/(len(better_model_list))\n",
    "        \n",
    "    layer5_weight.requires_grad_()\n",
    "    newGroundTruth.layer_5.weight=torch.nn.Parameter(layer5_weight)\n",
    "    \n",
    "                \n",
    "    layeroutput_weight=torch.tensor([[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layeroutput_weight=layeroutput_weight+i.layer_out.weight/(len(better_model_list))\n",
    "        \n",
    "    layeroutput_weight.requires_grad_()\n",
    "    newGroundTruth.layer_out.weight=torch.nn.Parameter(layeroutput_weight)\n",
    "    \n",
    "    return newGroundTruth\n",
    "        \n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    total_lossconfirm=0\n",
    "    #criterion = nn.MSELoss()\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            #loss = criterion(y_pred_tag, torch.tensor([y]))\n",
    "\n",
    "            \n",
    "            #print(\"y \", y)\n",
    "            #print(\"pred \", y_pred_tag.cpu().numpy())\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "            #total_lossconfirm=total_lossconfirm+loss.item()\n",
    "    \n",
    "    #total_loss=np.sqrt(total_loss)/len(truth)\n",
    "    total_loss=total_loss/len(truth)\n",
    "    total_lossconfirm=total_lossconfirm/len(truth)\n",
    "    #print(\"current loss: \", total_loss)\n",
    "    #print(\"current confirm loss: \", total_lossconfirm)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True, total_loss[0][0]\n",
    "    else:\n",
    "        return False, total_loss[0][0]\n",
    "        \n",
    "        \n",
    "def evalnetwork(network, test_loader, stats=True):\n",
    "    y_pred_list =[]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            y_test_pred = network(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            #y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    if(stats):\n",
    "        statistics(y_pred_list)\n",
    "    return y_pred_list\n",
    "\n",
    "def statistics(y_pred_list):\n",
    "    correctcounter=0\n",
    "    for i in range(len(y_pred_list)):\n",
    "        if y_pred_list[i]==y_test[i]:\n",
    "            correctcounter=correctcounter+1       \n",
    "\n",
    "    print(\"# correct: \",correctcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Model statistics\")\n",
    "    print(classification_report(y_test, y_pred_list))    \n",
    "    \n",
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, NEURONS) \n",
    "        self.layer_2 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_3 = nn.Linear(NEURONS, NEURONS)\n",
    "        self.layer_4 = nn.Linear(NEURONS,NEURONS)\n",
    "        self.layer_5 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_out = nn.Linear(NEURONS, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "     \n",
    "    def get_copy(self):\n",
    "        copied_model=binaryClassification()\n",
    "        copied_model.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        copied_model.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        copied_model.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        copied_model.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        copied_model.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        copied_model.layer_out = copy.deepcopy(self.layer_out)\n",
    "        copied_model.batchnorm1=copy.deepcopy(self.batchnorm1)\n",
    "        copied_model.batchnorm2=copy.deepcopy(self.batchnorm2)\n",
    "        copied_model.batchnorm3=copy.deepcopy(self.batchnorm3)\n",
    "        copied_model.batchnorm4=copy.deepcopy(self.batchnorm4)\n",
    "        copied_model.batchnorm5=copy.deepcopy(self.batchnorm5)\n",
    "\n",
    "        \n",
    "          \n",
    "        return copied_model\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    def change_node_modellinear(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=[1.0]*5\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=np.random.normal(0, 1, size=5)\n",
    "        weightchange=[i.item()*10 for i in weightchange]\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "def select_node():\n",
    "    layer=randrange(5)\n",
    "    if layer!=6:\n",
    "        node=randrange(5)\n",
    "    else:\n",
    "        node=randrange(2)\n",
    "    return [layer, node]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class arbitraryLayerModel(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(arbitraryLayerModel, self).__init__()\n",
    "        self.layer_input=nn.Linear(5, NEURONS)\n",
    "        self.layers=nn.ModuleList([nn.Linear(NEURONS, NEURONS) for i in range(num_layers)])\n",
    "        self.batchnorms=nn.ModuleList([nn.BatchNorm1d(NEURONS) for i in range(num_layers)])\n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def get_copy(self):\n",
    "        copied_model=arbitraryLayerModel()\n",
    "        copied_model.layers=nn.ModuleList()\n",
    "        for i in self.layers:\n",
    "            copied_model.layers.append(copy.deepcopy(i))\n",
    "            \n",
    "        copied_model.batchnorms=nn.ModuleList()\n",
    "        for i in self.batchnorms:\n",
    "            copied_model.batchnorms.append(copy.deepcopy(i))\n",
    "        copied_model.layer_input=copy.deepcopy(self.layer_input)\n",
    "        copied_model.layer_output=copy.deepcopy(self.layer_output)\n",
    "\n",
    "        return copied_model\n",
    "            \n",
    "     \n",
    "    def forward(self, inputs):\n",
    "        x=self.relu(self.layer_input(inputs))\n",
    "        for (layer, batchnorm) in zip(self.layers, self.batchnorms):\n",
    "            x=batchnorm(x)\n",
    "            x=self.relu(layer(x))\n",
    "            x=self.dropout(x)\n",
    "        x=self.layer_output(x)\n",
    "        return(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=self.get_copy()\n",
    "        \n",
    "        weightchange=np.random.normal(0,1)\n",
    "        weightchange=[weightchange.item()]\n",
    "        zeros=[[0]]*(NEURONS-1)\n",
    "        if node[0]==0:\n",
    "            zeros.insert(weightchange, node[1])\n",
    "            newweight=self.layer_input.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_input.weight=torch.nn.Parameter(newweight)    \n",
    "            return changed_node\n",
    "            \n",
    "            \n",
    "        weightchange=np.random.normal(0, 1, size=NEURONS)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "        zeros = [[0.0]*NEURONS]*(NEURONS-1)\n",
    "        \n",
    "        if node[0]==TESTMODULE_LAYERS+1:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight) \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            for layer, i in enumerate(changed_node.layers):\n",
    "                if i==node[0]+1:\n",
    "                    zeros.insert(weightchange,node[1])\n",
    "                    newweight=layer.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "                    newweight.requires_grad_()\n",
    "                    layer.weight=torch.nn.Parameter(newweight)\n",
    "                    \n",
    "        \n",
    "\n",
    "        return changed_node\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f79ec",
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "#Linear combo 5d guassian weight \n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "            if accepted:\n",
    "                #print(\"\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==25:\n",
    "        print(\"No increase for 25 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "        \n",
    "                          \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598e262a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time:  0.5339813232421875\n",
      "Number no loss change 6: | Current time: 13.974 | Loss difference: 7.371e-07 | Loss: 5.775e-06\n",
      "Number no loss change 7: | Current time: 18.814 | Loss difference: 2.789e-07 | Loss: 6.457e-06\n",
      "Number no loss change 8: | Current time: 19.773 | Loss difference: 1.388e-07 | Loss: 4.336e-06\n",
      "Number no loss change 9: | Current time: 20.249 | Loss difference: 1.229e-07 | Loss: 4.459e-06\n",
      "Number no loss change 10: | Current time: 21.191 | Loss difference: 3.232e-08 | Loss: 5.974e-06\n",
      "Number no loss change 11: | Current time: 23.100 | Loss difference: 8.088e-07 | Loss: 2.033e-06\n",
      "Number no loss change 12: | Current time: 24.085 | Loss difference: 1.968e-07 | Loss: 2.852e-06\n",
      "Number no loss change 13: | Current time: 24.574 | Loss difference: 3.873e-07 | Loss: 3.24e-06\n",
      "Number no loss change 14: | Current time: 26.155 | Loss difference: 8.056e-08 | Loss: 2.059e-06\n",
      "Number no loss change 15: | Current time: 26.764 | Loss difference: 6.911e-08 | Loss: 2.128e-06\n",
      "Number no loss change 16: | Current time: 27.267 | Loss difference: 8.054e-08 | Loss: 2.209e-06\n",
      "Number no loss change 17: | Current time: 29.456 | Loss difference: 1.57e-07 | Loss: 2.521e-06\n",
      "Number no loss change 18: | Current time: 29.973 | Loss difference: 8.88e-07 | Loss: 1.633e-06\n",
      "Number no loss change 19: | Current time: 30.471 | Loss difference: 5.217e-07 | Loss: 2.155e-06\n",
      "Number no loss change 20: | Current time: 31.005 | Loss difference: 2.755e-07 | Loss: 2.431e-06\n",
      "Number no loss change 21: | Current time: 31.526 | Loss difference: 3.509e-08 | Loss: 2.396e-06\n",
      "Number no loss change 22: | Current time: 32.487 | Loss difference: 4.798e-07 | Loss: 1.694e-06\n",
      "Number no loss change 23: | Current time: 32.974 | Loss difference: 4.728e-07 | Loss: 1.222e-06\n",
      "Number no loss change 24: | Current time: 33.568 | Loss difference: 8.318e-07 | Loss: 2.053e-06\n",
      "Number no loss change 25: | Current time: 37.043 | Loss difference: 3.665e-07 | Loss: 2.516e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  1\n",
      "Number no loss change 6: | Current time: 13.655 | Loss difference: 7.642e-07 | Loss: 8.703e-06\n",
      "Number no loss change 7: | Current time: 14.185 | Loss difference: 8.769e-07 | Loss: 7.826e-06\n",
      "Number no loss change 8: | Current time: 15.632 | Loss difference: 5.753e-07 | Loss: 4.782e-06\n",
      "Number no loss change 9: | Current time: 16.126 | Loss difference: 7.349e-07 | Loss: 5.517e-06\n",
      "Number no loss change 10: | Current time: 16.655 | Loss difference: 9.315e-07 | Loss: 6.448e-06\n",
      "Number no loss change 11: | Current time: 17.640 | Loss difference: 8.078e-07 | Loss: 4.962e-06\n",
      "Number no loss change 12: | Current time: 18.140 | Loss difference: 5.087e-07 | Loss: 4.453e-06\n",
      "Number no loss change 13: | Current time: 19.130 | Loss difference: 8.157e-07 | Loss: 2.344e-06\n",
      "Number no loss change 14: | Current time: 19.606 | Loss difference: 2.878e-07 | Loss: 2.632e-06\n",
      "Number no loss change 15: | Current time: 24.495 | Loss difference: 7.692e-07 | Loss: 3.102e-06\n",
      "Number no loss change 16: | Current time: 24.979 | Loss difference: 1.285e-08 | Loss: 3.115e-06\n",
      "Number no loss change 17: | Current time: 26.993 | Loss difference: 4.579e-07 | Loss: 9.565e-07\n",
      "Number no loss change 18: | Current time: 31.467 | Loss difference: 6.312e-07 | Loss: 2.36e-06\n",
      "Number no loss change 19: | Current time: 32.406 | Loss difference: 4.83e-07 | Loss: 1.877e-06\n",
      "Number no loss change 20: | Current time: 32.935 | Loss difference: 9.502e-07 | Loss: 9.268e-07\n",
      "Number no loss change 21: | Current time: 34.405 | Loss difference: 1.858e-07 | Loss: 1.864e-06\n",
      "Number no loss change 22: | Current time: 34.884 | Loss difference: 8.811e-07 | Loss: 9.826e-07\n",
      "Number no loss change 23: | Current time: 35.410 | Loss difference: 4.225e-07 | Loss: 1.405e-06\n",
      "Number no loss change 24: | Current time: 36.287 | Loss difference: 1.447e-07 | Loss: 1.26e-06\n",
      "Number no loss change 25: | Current time: 37.266 | Loss difference: 2.246e-07 | Loss: 1.485e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  2\n",
      "Number no loss change 6: | Current time: 12.267 | Loss difference: 1.977e-07 | Loss: 2.832e-06\n",
      "Number no loss change 7: | Current time: 12.740 | Loss difference: 6.497e-07 | Loss: 3.481e-06\n",
      "Number no loss change 8: | Current time: 13.252 | Loss difference: 1.33e-07 | Loss: 3.348e-06\n",
      "Number no loss change 9: | Current time: 14.741 | Loss difference: 2.869e-07 | Loss: 3.653e-06\n",
      "Number no loss change 10: | Current time: 15.257 | Loss difference: 1.835e-07 | Loss: 3.47e-06\n",
      "Number no loss change 11: | Current time: 16.233 | Loss difference: 4.466e-07 | Loss: 1.975e-06\n",
      "Number no loss change 12: | Current time: 16.726 | Loss difference: 6.071e-07 | Loss: 2.582e-06\n",
      "Number no loss change 13: | Current time: 17.223 | Loss difference: 2.075e-07 | Loss: 2.79e-06\n",
      "Number no loss change 14: | Current time: 17.716 | Loss difference: 5.439e-07 | Loss: 2.246e-06\n",
      "Number no loss change 15: | Current time: 18.204 | Loss difference: 2.807e-07 | Loss: 2.527e-06\n",
      "Number no loss change 16: | Current time: 19.669 | Loss difference: 4.011e-07 | Loss: 2.871e-06\n",
      "Number no loss change 17: | Current time: 20.156 | Loss difference: 6.196e-07 | Loss: 2.251e-06\n",
      "Number no loss change 18: | Current time: 20.654 | Loss difference: 2.163e-07 | Loss: 2.467e-06\n",
      "Number no loss change 19: | Current time: 21.140 | Loss difference: 9.894e-08 | Loss: 2.566e-06\n",
      "Number no loss change 20: | Current time: 22.123 | Loss difference: 7.288e-07 | Loss: 4.919e-06\n",
      "Number no loss change 21: | Current time: 23.089 | Loss difference: 1.777e-07 | Loss: 1.855e-06\n",
      "Number no loss change 22: | Current time: 26.007 | Loss difference: 3.931e-07 | Loss: 1.238e-06\n",
      "Number no loss change 23: | Current time: 26.495 | Loss difference: 5.931e-08 | Loss: 1.298e-06\n",
      "Number no loss change 24: | Current time: 27.969 | Loss difference: 2.339e-07 | Loss: 2.101e-06\n",
      "Number no loss change 25: | Current time: 28.924 | Loss difference: 9.372e-07 | Loss: 1.833e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  3\n",
      "Number no loss change 6: | Current time: 20.183 | Loss difference: 7.648e-07 | Loss: 8.184e-06\n",
      "Number no loss change 7: | Current time: 24.602 | Loss difference: 7.794e-07 | Loss: 4.646e-06\n",
      "Number no loss change 8: | Current time: 25.131 | Loss difference: 9.731e-07 | Loss: 3.672e-06\n",
      "Number no loss change 9: | Current time: 25.628 | Loss difference: 9.197e-07 | Loss: 2.753e-06\n",
      "Number no loss change 10: | Current time: 27.156 | Loss difference: 1.015e-07 | Loss: 2.09e-06\n",
      "Number no loss change 11: | Current time: 28.772 | Loss difference: 7.299e-07 | Loss: 1.815e-06\n",
      "Number no loss change 12: | Current time: 29.305 | Loss difference: 1.789e-07 | Loss: 1.994e-06\n",
      "Number no loss change 13: | Current time: 30.919 | Loss difference: 1.493e-07 | Loss: 1.891e-06\n",
      "Number no loss change 14: | Current time: 31.917 | Loss difference: 4.884e-07 | Loss: 3.228e-06\n",
      "Number no loss change 15: | Current time: 33.873 | Loss difference: 5.827e-08 | Loss: 1.398e-06\n",
      "Number no loss change 16: | Current time: 34.368 | Loss difference: 9.399e-07 | Loss: 2.338e-06\n",
      "Number no loss change 17: | Current time: 35.356 | Loss difference: 9.181e-07 | Loss: 3.064e-06\n",
      "Number no loss change 18: | Current time: 37.303 | Loss difference: 7.173e-07 | Loss: 1.891e-06\n",
      "Number no loss change 19: | Current time: 37.799 | Loss difference: 8.578e-07 | Loss: 1.033e-06\n",
      "Number no loss change 20: | Current time: 38.306 | Loss difference: 4.736e-07 | Loss: 1.506e-06\n",
      "Number no loss change 21: | Current time: 40.287 | Loss difference: 4.748e-07 | Loss: 1.856e-06\n",
      "Number no loss change 22: | Current time: 40.768 | Loss difference: 9.176e-07 | Loss: 9.388e-07\n",
      "Number no loss change 23: | Current time: 41.742 | Loss difference: 8.183e-07 | Loss: 2.751e-06\n",
      "Number no loss change 24: | Current time: 42.725 | Loss difference: 2.683e-07 | Loss: 1.442e-06\n",
      "Number no loss change 25: | Current time: 43.214 | Loss difference: 6.729e-07 | Loss: 7.687e-07\n",
      "Test model beaten. Total beaten by prospective ground truth:  4\n",
      "Number no loss change 6: | Current time: 9.099 | Loss difference: 7.511e-07 | Loss: 7.369e-06\n",
      "Number no loss change 7: | Current time: 10.145 | Loss difference: 2.203e-07 | Loss: 6.298e-06\n",
      "Number no loss change 8: | Current time: 10.640 | Loss difference: 6.509e-07 | Loss: 5.647e-06\n",
      "Number no loss change 9: | Current time: 12.658 | Loss difference: 7.909e-07 | Loss: 5.826e-06\n",
      "Number no loss change 10: | Current time: 13.637 | Loss difference: 6.226e-07 | Loss: 4.113e-06\n",
      "Number no loss change 11: | Current time: 14.623 | Loss difference: 9.762e-07 | Loss: 5.231e-06\n",
      "Number no loss change 12: | Current time: 18.624 | Loss difference: 1.62e-07 | Loss: 3.329e-06\n",
      "Number no loss change 13: | Current time: 19.113 | Loss difference: 2.605e-07 | Loss: 3.069e-06\n",
      "Number no loss change 14: | Current time: 21.086 | Loss difference: 3.451e-07 | Loss: 2.718e-06\n",
      "Number no loss change 15: | Current time: 24.104 | Loss difference: 5.665e-07 | Loss: 2.707e-06\n",
      "Number no loss change 16: | Current time: 24.600 | Loss difference: 3.001e-08 | Loss: 2.677e-06\n",
      "Number no loss change 17: | Current time: 25.094 | Loss difference: 9.527e-07 | Loss: 1.724e-06\n",
      "Number no loss change 18: | Current time: 26.084 | Loss difference: 6.545e-07 | Loss: 2.652e-06\n",
      "Number no loss change 19: | Current time: 26.602 | Loss difference: 7.454e-07 | Loss: 1.907e-06\n",
      "Number no loss change 20: | Current time: 27.153 | Loss difference: 9.507e-07 | Loss: 2.858e-06\n",
      "Number no loss change 21: | Current time: 27.647 | Loss difference: 2.308e-07 | Loss: 3.088e-06\n",
      "Number no loss change 22: | Current time: 29.734 | Loss difference: 5.18e-07 | Loss: 2.186e-06\n",
      "Number no loss change 23: | Current time: 30.221 | Loss difference: 6.733e-07 | Loss: 2.859e-06\n",
      "Number no loss change 24: | Current time: 31.244 | Loss difference: 8.982e-08 | Loss: 4.552e-06\n",
      "Number no loss change 25: | Current time: 32.352 | Loss difference: 7.005e-09 | Loss: 1.523e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  5\n",
      "Number no loss change 6: | Current time: 13.176 | Loss difference: 5.493e-07 | Loss: 4.79e-06\n",
      "Number no loss change 7: | Current time: 15.558 | Loss difference: 1.785e-07 | Loss: 6.346e-06\n",
      "Number no loss change 8: | Current time: 18.003 | Loss difference: 6.889e-07 | Loss: 3.114e-06\n",
      "Number no loss change 9: | Current time: 19.970 | Loss difference: 2.226e-07 | Loss: 4.15e-06\n",
      "Number no loss change 10: | Current time: 21.405 | Loss difference: 8.32e-08 | Loss: 4.006e-06\n",
      "Number no loss change 11: | Current time: 23.367 | Loss difference: 9.078e-07 | Loss: 1.898e-06\n",
      "Number no loss change 12: | Current time: 23.854 | Loss difference: 3.58e-07 | Loss: 2.257e-06\n",
      "Number no loss change 13: | Current time: 24.346 | Loss difference: 2.34e-07 | Loss: 2.49e-06\n",
      "Number no loss change 14: | Current time: 25.332 | Loss difference: 3.579e-07 | Loss: 4.849e-06\n",
      "Number no loss change 15: | Current time: 27.287 | Loss difference: 5.126e-07 | Loss: 6.309e-06\n",
      "Number no loss change 16: | Current time: 27.772 | Loss difference: 9.402e-07 | Loss: 7.249e-06\n",
      "Number no loss change 17: | Current time: 29.690 | Loss difference: 7.209e-07 | Loss: 3.625e-06\n",
      "Number no loss change 18: | Current time: 30.661 | Loss difference: 5.135e-07 | Loss: 1.576e-06\n",
      "Number no loss change 19: | Current time: 32.183 | Loss difference: 8.738e-08 | Loss: 2.86e-06\n",
      "Number no loss change 20: | Current time: 32.675 | Loss difference: 7.432e-07 | Loss: 2.117e-06\n",
      "Number no loss change 21: | Current time: 34.204 | Loss difference: 1.083e-07 | Loss: 2.07e-06\n",
      "Number no loss change 22: | Current time: 34.692 | Loss difference: 6.59e-07 | Loss: 1.411e-06\n",
      "Number no loss change 23: | Current time: 36.121 | Loss difference: 3.323e-08 | Loss: 1.076e-06\n",
      "Number no loss change 24: | Current time: 37.567 | Loss difference: 2.805e-08 | Loss: 4.944e-06\n",
      "Number no loss change 25: | Current time: 39.000 | Loss difference: 2.118e-07 | Loss: 5.301e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  6\n",
      "Number no loss change 6: | Current time: 9.228 | Loss difference: 8.48e-07 | Loss: 9.619e-06\n",
      "Number no loss change 7: | Current time: 13.084 | Loss difference: 9.371e-08 | Loss: 5.603e-06\n",
      "Number no loss change 8: | Current time: 15.754 | Loss difference: 3.858e-07 | Loss: 5.495e-06\n",
      "Number no loss change 9: | Current time: 18.630 | Loss difference: 3.941e-07 | Loss: 5.599e-06\n",
      "Number no loss change 10: | Current time: 21.538 | Loss difference: 1.492e-07 | Loss: 2.575e-06\n",
      "Number no loss change 11: | Current time: 22.015 | Loss difference: 3.623e-07 | Loss: 2.213e-06\n",
      "Number no loss change 12: | Current time: 23.450 | Loss difference: 6.882e-08 | Loss: 1.281e-06\n",
      "Number no loss change 13: | Current time: 23.943 | Loss difference: 2.429e-07 | Loss: 1.039e-06\n",
      "Number no loss change 14: | Current time: 24.454 | Loss difference: 7.61e-07 | Loss: 1.799e-06\n",
      "Number no loss change 15: | Current time: 24.947 | Loss difference: 1.615e-07 | Loss: 1.638e-06\n",
      "Number no loss change 16: | Current time: 25.430 | Loss difference: 3.506e-07 | Loss: 1.287e-06\n",
      "Number no loss change 17: | Current time: 25.915 | Loss difference: 1.276e-07 | Loss: 1.415e-06\n",
      "Number no loss change 18: | Current time: 27.836 | Loss difference: 5.521e-07 | Loss: 1.852e-06\n",
      "Number no loss change 6: | Current time: 9.195 | Loss difference: 6.757e-07 | Loss: 1.091e-05\n",
      "Number no loss change 7: | Current time: 9.697 | Loss difference: 1.889e-07 | Loss: 1.072e-05\n",
      "Number no loss change 8: | Current time: 11.663 | Loss difference: 3.063e-08 | Loss: 8.594e-06\n",
      "Number no loss change 9: | Current time: 12.145 | Loss difference: 4.968e-07 | Loss: 9.091e-06\n",
      "Number no loss change 10: | Current time: 15.020 | Loss difference: 9.656e-07 | Loss: 7.155e-06\n",
      "Number no loss change 11: | Current time: 15.515 | Loss difference: 3.129e-07 | Loss: 6.842e-06\n",
      "Number no loss change 12: | Current time: 17.454 | Loss difference: 4.114e-07 | Loss: 5.417e-06\n",
      "Number no loss change 13: | Current time: 18.400 | Loss difference: 2.645e-07 | Loss: 3.484e-06\n",
      "Number no loss change 14: | Current time: 19.859 | Loss difference: 2.99e-07 | Loss: 3.928e-06\n",
      "Number no loss change 15: | Current time: 22.269 | Loss difference: 9.386e-07 | Loss: 5.14e-06\n",
      "Number no loss change 16: | Current time: 24.180 | Loss difference: 8.006e-07 | Loss: 3.424e-06\n",
      "Number no loss change 17: | Current time: 25.151 | Loss difference: 6.228e-07 | Loss: 2.125e-06\n",
      "Number no loss change 18: | Current time: 25.628 | Loss difference: 8.799e-07 | Loss: 1.245e-06\n",
      "Number no loss change 19: | Current time: 26.590 | Loss difference: 1.465e-07 | Loss: 2.705e-06\n",
      "Number no loss change 20: | Current time: 28.536 | Loss difference: 3.775e-07 | Loss: 1.567e-06\n",
      "Number no loss change 21: | Current time: 29.020 | Loss difference: 3.396e-07 | Loss: 1.227e-06\n",
      "Number no loss change 22: | Current time: 34.331 | Loss difference: 5.542e-07 | Loss: 3.469e-06\n",
      "Number no loss change 23: | Current time: 36.279 | Loss difference: 4.806e-07 | Loss: 1.235e-06\n",
      "Number no loss change 24: | Current time: 38.716 | Loss difference: 1.689e-07 | Loss: 1.309e-06\n",
      "Number no loss change 25: | Current time: 39.686 | Loss difference: 9.832e-07 | Loss: 4.435e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  7\n",
      "Number no loss change 6: | Current time: 10.632 | Loss difference: 6.849e-07 | Loss: 5.738e-06\n",
      "Number no loss change 7: | Current time: 12.558 | Loss difference: 6.412e-07 | Loss: 4.247e-06\n",
      "Number no loss change 8: | Current time: 13.999 | Loss difference: 6.46e-07 | Loss: 2.509e-06\n",
      "Number no loss change 9: | Current time: 14.494 | Loss difference: 9.019e-07 | Loss: 3.411e-06\n",
      "Number no loss change 10: | Current time: 14.980 | Loss difference: 8.071e-07 | Loss: 4.218e-06\n",
      "Number no loss change 11: | Current time: 15.451 | Loss difference: 3.931e-07 | Loss: 3.825e-06\n",
      "Number no loss change 12: | Current time: 18.361 | Loss difference: 9.844e-07 | Loss: 2.222e-06\n",
      "Number no loss change 13: | Current time: 19.326 | Loss difference: 8.221e-07 | Loss: 3.079e-06\n",
      "Number no loss change 14: | Current time: 19.807 | Loss difference: 3.298e-07 | Loss: 2.75e-06\n",
      "Number no loss change 15: | Current time: 20.278 | Loss difference: 4.905e-07 | Loss: 3.24e-06\n",
      "Number no loss change 16: | Current time: 20.758 | Loss difference: 4.238e-07 | Loss: 2.816e-06\n",
      "Number no loss change 17: | Current time: 21.243 | Loss difference: 2.119e-07 | Loss: 2.605e-06\n",
      "Number no loss change 18: | Current time: 21.719 | Loss difference: 3.458e-07 | Loss: 2.95e-06\n",
      "Number no loss change 19: | Current time: 22.186 | Loss difference: 9.552e-07 | Loss: 1.995e-06\n",
      "Number no loss change 20: | Current time: 22.675 | Loss difference: 5.625e-07 | Loss: 2.558e-06\n",
      "Number no loss change 21: | Current time: 23.174 | Loss difference: 1.381e-07 | Loss: 2.42e-06\n",
      "Number no loss change 22: | Current time: 23.671 | Loss difference: 4.844e-07 | Loss: 1.935e-06\n",
      "Number no loss change 23: | Current time: 24.160 | Loss difference: 8.498e-07 | Loss: 2.785e-06\n",
      "Number no loss change 24: | Current time: 26.098 | Loss difference: 8.791e-07 | Loss: 2.588e-06\n",
      "Number no loss change 25: | Current time: 26.596 | Loss difference: 4.864e-07 | Loss: 2.101e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  8\n",
      "Number no loss change 6: | Current time: 9.600 | Loss difference: 2.231e-07 | Loss: 4.81e-06\n",
      "Number no loss change 7: | Current time: 11.064 | Loss difference: 4.669e-07 | Loss: 2.975e-06\n",
      "Number no loss change 8: | Current time: 12.045 | Loss difference: 9.518e-07 | Loss: 5.183e-06\n",
      "Number no loss change 9: | Current time: 12.529 | Loss difference: 7.984e-07 | Loss: 4.384e-06\n",
      "Number no loss change 10: | Current time: 13.500 | Loss difference: 6.514e-07 | Loss: 3.587e-06\n",
      "Number no loss change 11: | Current time: 14.457 | Loss difference: 1.979e-07 | Loss: 4.601e-06\n",
      "Number no loss change 12: | Current time: 15.421 | Loss difference: 7.386e-08 | Loss: 2.489e-06\n",
      "Number no loss change 13: | Current time: 15.895 | Loss difference: 7.799e-07 | Loss: 3.269e-06\n",
      "Number no loss change 14: | Current time: 16.388 | Loss difference: 8.562e-07 | Loss: 2.413e-06\n",
      "Number no loss change 15: | Current time: 17.967 | Loss difference: 4.033e-07 | Loss: 2.196e-06\n",
      "Number no loss change 16: | Current time: 19.896 | Loss difference: 1.304e-07 | Loss: 3.742e-06\n",
      "Number no loss change 17: | Current time: 21.571 | Loss difference: 8.936e-07 | Loss: 1.661e-06\n",
      "Number no loss change 18: | Current time: 22.259 | Loss difference: 7.569e-07 | Loss: 2.418e-06\n",
      "Number no loss change 19: | Current time: 23.014 | Loss difference: 7.986e-07 | Loss: 3.217e-06\n",
      "Number no loss change 20: | Current time: 23.707 | Loss difference: 2.112e-07 | Loss: 3.428e-06\n",
      "Number no loss change 21: | Current time: 24.748 | Loss difference: 3.566e-07 | Loss: 1.452e-06\n",
      "Number no loss change 22: | Current time: 27.487 | Loss difference: 1.995e-07 | Loss: 2.652e-06\n",
      "Number no loss change 23: | Current time: 28.415 | Loss difference: 8.22e-07 | Loss: 3.474e-06\n",
      "Number no loss change 24: | Current time: 28.887 | Loss difference: 9.525e-07 | Loss: 2.521e-06\n",
      "Number no loss change 25: | Current time: 29.362 | Loss difference: 7.072e-07 | Loss: 3.228e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  9\n",
      "Iteration:  1  | Ground truth number:  1\n",
      "Iteration:  1  | Ground truth number:  2\n",
      "Iteration:  1  | Ground truth number:  3\n",
      "Number no loss change 6: | Current time: 15.556 | Loss difference: 1.928e-08 | Loss: 6.851e-06\n",
      "Number no loss change 7: | Current time: 20.721 | Loss difference: 9.197e-07 | Loss: 5.791e-06\n",
      "Number no loss change 8: | Current time: 21.225 | Loss difference: 2.429e-07 | Loss: 6.034e-06\n",
      "Number no loss change 9: | Current time: 21.719 | Loss difference: 5.749e-07 | Loss: 5.459e-06\n",
      "Number no loss change 10: | Current time: 22.697 | Loss difference: 5.278e-07 | Loss: 1.243e-05\n",
      "Number no loss change 11: | Current time: 34.802 | Loss difference: 4.387e-07 | Loss: 3.402e-06\n",
      "Number no loss change 12: | Current time: 35.780 | Loss difference: 3.138e-07 | Loss: 5.929e-06\n",
      "Number no loss change 13: | Current time: 36.247 | Loss difference: 5.472e-07 | Loss: 6.476e-06\n",
      "Number no loss change 14: | Current time: 37.218 | Loss difference: 9.056e-07 | Loss: 8.185e-06\n",
      "Number no loss change 15: | Current time: 42.506 | Loss difference: 2.196e-07 | Loss: 4.093e-06\n",
      "Number no loss change 16: | Current time: 44.466 | Loss difference: 5.643e-07 | Loss: 2.041e-06\n",
      "Number no loss change 17: | Current time: 50.254 | Loss difference: 8.266e-07 | Loss: 2.608e-06\n",
      "Number no loss change 18: | Current time: 52.707 | Loss difference: 5.312e-07 | Loss: 5.143e-06\n",
      "Number no loss change 19: | Current time: 54.183 | Loss difference: 1.524e-07 | Loss: 3.582e-06\n",
      "Number no loss change 20: | Current time: 55.664 | Loss difference: 4.101e-07 | Loss: 4.099e-06\n",
      "Number no loss change 21: | Current time: 60.461 | Loss difference: 2.428e-07 | Loss: 3.982e-06\n",
      "Number no loss change 22: | Current time: 61.063 | Loss difference: 6.227e-07 | Loss: 4.604e-06\n",
      "Number no loss change 23: | Current time: 63.977 | Loss difference: 2.046e-07 | Loss: 4.86e-06\n",
      "Number no loss change 24: | Current time: 64.525 | Loss difference: 2.022e-07 | Loss: 4.658e-06\n",
      "Number no loss change 25: | Current time: 68.895 | Loss difference: 9.69e-08 | Loss: 4.964e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  1\n",
      "Number no loss change 6: | Current time: 24.003 | Loss difference: 7.293e-07 | Loss: 4.496e-06\n",
      "Number no loss change 7: | Current time: 24.544 | Loss difference: 1.962e-07 | Loss: 4.3e-06\n",
      "Number no loss change 8: | Current time: 38.542 | Loss difference: 5.951e-07 | Loss: 7.72e-06\n",
      "Number no loss change 9: | Current time: 39.030 | Loss difference: 9.643e-08 | Loss: 7.623e-06\n",
      "Number no loss change 10: | Current time: 43.407 | Loss difference: 3.179e-07 | Loss: 6.854e-06\n",
      "Number no loss change 11: | Current time: 43.890 | Loss difference: 5.62e-07 | Loss: 6.292e-06\n",
      "Number no loss change 12: | Current time: 46.779 | Loss difference: 3.878e-07 | Loss: 5.989e-06\n",
      "Number no loss change 13: | Current time: 47.257 | Loss difference: 4.605e-07 | Loss: 5.529e-06\n",
      "Number no loss change 14: | Current time: 47.732 | Loss difference: 5.829e-07 | Loss: 4.946e-06\n",
      "Number no loss change 15: | Current time: 52.948 | Loss difference: 9.423e-07 | Loss: 4.175e-06\n",
      "Number no loss change 16: | Current time: 64.560 | Loss difference: 6.848e-07 | Loss: 6.45e-06\n",
      "Number no loss change 17: | Current time: 65.048 | Loss difference: 8.645e-07 | Loss: 7.315e-06\n",
      "Number no loss change 18: | Current time: 65.538 | Loss difference: 2.496e-07 | Loss: 7.065e-06\n",
      "Number no loss change 19: | Current time: 67.930 | Loss difference: 6.109e-07 | Loss: 3.823e-06\n",
      "Number no loss change 20: | Current time: 73.846 | Loss difference: 2.294e-07 | Loss: 1.264e-05\n",
      "Number no loss change 21: | Current time: 75.313 | Loss difference: 1.184e-07 | Loss: 3.091e-06\n",
      "Number no loss change 22: | Current time: 75.788 | Loss difference: 2.599e-07 | Loss: 3.351e-06\n",
      "Number no loss change 23: | Current time: 83.963 | Loss difference: 1.497e-07 | Loss: 3.018e-06\n",
      "Number no loss change 24: | Current time: 86.354 | Loss difference: 4.057e-07 | Loss: 4.164e-06\n",
      "Number no loss change 25: | Current time: 103.319 | Loss difference: 5.494e-07 | Loss: 1.007e-05\n",
      "Test model beaten. Total beaten by prospective ground truth:  2\n",
      "Number no loss change 6: | Current time: 14.507 | Loss difference: 7.575e-07 | Loss: 4.359e-06\n",
      "Number no loss change 7: | Current time: 14.986 | Loss difference: 6.885e-10 | Loss: 4.359e-06\n",
      "Number no loss change 8: | Current time: 15.939 | Loss difference: 8.784e-07 | Loss: 8.247e-06\n",
      "Number no loss change 9: | Current time: 16.403 | Loss difference: 1.154e-07 | Loss: 8.132e-06\n",
      "Number no loss change 10: | Current time: 16.911 | Loss difference: 5.895e-07 | Loss: 8.721e-06\n",
      "Number no loss change 11: | Current time: 18.849 | Loss difference: 8.646e-07 | Loss: 4.279e-06\n",
      "Number no loss change 12: | Current time: 21.746 | Loss difference: 8.788e-07 | Loss: 4.467e-06\n",
      "Number no loss change 13: | Current time: 24.193 | Loss difference: 8.451e-07 | Loss: 4.805e-06\n",
      "Number no loss change 14: | Current time: 25.399 | Loss difference: 3.581e-07 | Loss: 6.217e-06\n",
      "Number no loss change 15: | Current time: 29.181 | Loss difference: 5.85e-07 | Loss: 4.293e-06\n",
      "Number no loss change 16: | Current time: 31.601 | Loss difference: 4.996e-07 | Loss: 3.519e-06\n",
      "Number no loss change 17: | Current time: 32.601 | Loss difference: 2.481e-07 | Loss: 6.087e-06\n",
      "Number no loss change 18: | Current time: 33.102 | Loss difference: 9.917e-07 | Loss: 5.095e-06\n",
      "Number no loss change 19: | Current time: 35.558 | Loss difference: 4.502e-08 | Loss: 1.876e-06\n",
      "Number no loss change 20: | Current time: 37.049 | Loss difference: 7.158e-07 | Loss: 5.268e-06\n",
      "Number no loss change 21: | Current time: 38.032 | Loss difference: 2.503e-07 | Loss: 3.784e-06\n",
      "Number no loss change 22: | Current time: 38.527 | Loss difference: 4.724e-07 | Loss: 3.311e-06\n",
      "Number no loss change 23: | Current time: 40.938 | Loss difference: 6.027e-07 | Loss: 3.905e-06\n",
      "Number no loss change 24: | Current time: 50.623 | Loss difference: 1.609e-07 | Loss: 2.911e-06\n",
      "Number no loss change 25: | Current time: 53.544 | Loss difference: 2.116e-07 | Loss: 5.825e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  3\n",
      "Number no loss change 6: | Current time: 17.479 | Loss difference: 4.15e-07 | Loss: 1.329e-05\n",
      "Number no loss change 7: | Current time: 19.398 | Loss difference: 5.511e-07 | Loss: 7.095e-06\n",
      "Number no loss change 8: | Current time: 23.279 | Loss difference: 3.614e-07 | Loss: 6.021e-06\n",
      "Number no loss change 9: | Current time: 24.701 | Loss difference: 6.727e-07 | Loss: 6.843e-06\n",
      "Number no loss change 10: | Current time: 28.121 | Loss difference: 1.539e-07 | Loss: 5.308e-06\n",
      "Number no loss change 11: | Current time: 34.443 | Loss difference: 1.413e-07 | Loss: 3.351e-06\n",
      "Number no loss change 12: | Current time: 34.931 | Loss difference: 1.512e-07 | Loss: 3.502e-06\n",
      "Number no loss change 13: | Current time: 37.381 | Loss difference: 6.476e-07 | Loss: 3.248e-06\n",
      "Number no loss change 14: | Current time: 39.322 | Loss difference: 8.18e-07 | Loss: 4.79e-06\n",
      "Number no loss change 15: | Current time: 46.292 | Loss difference: 7.648e-07 | Loss: 1.664e-06\n",
      "Number no loss change 16: | Current time: 47.278 | Loss difference: 2.969e-07 | Loss: 5.908e-06\n",
      "Number no loss change 17: | Current time: 49.726 | Loss difference: 2.525e-07 | Loss: 2.827e-06\n",
      "Number no loss change 18: | Current time: 56.993 | Loss difference: 1.676e-07 | Loss: 4.543e-06\n",
      "Number no loss change 19: | Current time: 58.418 | Loss difference: 4.639e-07 | Loss: 2.842e-06\n",
      "Number no loss change 20: | Current time: 60.844 | Loss difference: 6.079e-07 | Loss: 4.797e-06\n",
      "Number no loss change 21: | Current time: 63.749 | Loss difference: 5.783e-07 | Loss: 7.569e-06\n",
      "Number no loss change 22: | Current time: 64.730 | Loss difference: 7.978e-08 | Loss: 3.25e-06\n",
      "Number no loss change 23: | Current time: 71.459 | Loss difference: 1.375e-08 | Loss: 2.416e-06\n",
      "Number no loss change 24: | Current time: 76.797 | Loss difference: 4.035e-07 | Loss: 6.283e-06\n",
      "Number no loss change 25: | Current time: 77.760 | Loss difference: 7.456e-07 | Loss: 5.367e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  4\n",
      "Number no loss change 6: | Current time: 16.605 | Loss difference: 6.505e-07 | Loss: 2.777e-06\n",
      "Number no loss change 7: | Current time: 24.807 | Loss difference: 5.703e-08 | Loss: 4.001e-06\n",
      "Number no loss change 8: | Current time: 26.260 | Loss difference: 7.898e-07 | Loss: 4.792e-06\n",
      "Number no loss change 9: | Current time: 27.719 | Loss difference: 8.887e-07 | Loss: 5.809e-06\n",
      "Number no loss change 10: | Current time: 34.013 | Loss difference: 5.794e-08 | Loss: 3.701e-06\n",
      "Number no loss change 11: | Current time: 41.312 | Loss difference: 4.703e-07 | Loss: 6.709e-06\n",
      "Number no loss change 12: | Current time: 41.840 | Loss difference: 2.419e-08 | Loss: 6.733e-06\n",
      "Number no loss change 13: | Current time: 44.395 | Loss difference: 9.792e-07 | Loss: 5.863e-06\n",
      "Number no loss change 14: | Current time: 48.753 | Loss difference: 4.539e-07 | Loss: 3.106e-06\n",
      "Number no loss change 15: | Current time: 51.203 | Loss difference: 8.622e-08 | Loss: 1.04e-05\n",
      "Number no loss change 16: | Current time: 54.170 | Loss difference: 6.869e-07 | Loss: 9.313e-06\n",
      "Number no loss change 17: | Current time: 56.563 | Loss difference: 8.488e-07 | Loss: 3.402e-06\n",
      "Number no loss change 18: | Current time: 60.961 | Loss difference: 9.088e-07 | Loss: 4.187e-06\n",
      "Number no loss change 19: | Current time: 61.952 | Loss difference: 4.208e-07 | Loss: 1.715e-06\n",
      "Number no loss change 20: | Current time: 62.941 | Loss difference: 9.902e-07 | Loss: 3.287e-06\n",
      "Number no loss change 21: | Current time: 63.913 | Loss difference: 8.761e-07 | Loss: 2.719e-06\n",
      "Number no loss change 22: | Current time: 64.388 | Loss difference: 9.582e-07 | Loss: 3.678e-06\n",
      "Number no loss change 23: | Current time: 67.763 | Loss difference: 8.817e-07 | Loss: 5.154e-06\n",
      "Number no loss change 24: | Current time: 70.176 | Loss difference: 2.819e-07 | Loss: 1.477e-06\n",
      "Number no loss change 25: | Current time: 70.654 | Loss difference: 2.37e-07 | Loss: 1.714e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  5\n",
      "Number no loss change 6: | Current time: 22.579 | Loss difference: 8.258e-07 | Loss: 9.511e-06\n",
      "Number no loss change 7: | Current time: 23.554 | Loss difference: 6.095e-07 | Loss: 7.754e-06\n",
      "Number no loss change 8: | Current time: 24.531 | Loss difference: 9.753e-07 | Loss: 1.223e-05\n",
      "Number no loss change 9: | Current time: 27.460 | Loss difference: 7.297e-07 | Loss: 5.394e-06\n",
      "Number no loss change 10: | Current time: 32.837 | Loss difference: 4.874e-07 | Loss: 4.112e-06\n",
      "Number no loss change 11: | Current time: 40.608 | Loss difference: 6.498e-07 | Loss: 4.169e-06\n",
      "Number no loss change 12: | Current time: 41.095 | Loss difference: 8.874e-07 | Loss: 5.056e-06\n",
      "Number no loss change 13: | Current time: 46.242 | Loss difference: 6.288e-07 | Loss: 2.05e-06\n",
      "Number no loss change 14: | Current time: 48.696 | Loss difference: 8.384e-07 | Loss: 6.519e-06\n",
      "Number no loss change 15: | Current time: 52.583 | Loss difference: 8.563e-07 | Loss: 3.509e-06\n",
      "Number no loss change 16: | Current time: 54.063 | Loss difference: 3.534e-07 | Loss: 3.747e-06\n",
      "Number no loss change 17: | Current time: 55.046 | Loss difference: 7.123e-07 | Loss: 1.124e-05\n",
      "Number no loss change 18: | Current time: 57.496 | Loss difference: 2.892e-07 | Loss: 6.905e-06\n",
      "Number no loss change 19: | Current time: 59.528 | Loss difference: 3.632e-07 | Loss: 2.124e-06\n",
      "Number no loss change 20: | Current time: 63.029 | Loss difference: 4.127e-07 | Loss: 5.195e-06\n",
      "Number no loss change 21: | Current time: 63.547 | Loss difference: 7.676e-08 | Loss: 5.118e-06\n",
      "Number no loss change 22: | Current time: 65.519 | Loss difference: 9.765e-08 | Loss: 2.769e-06\n",
      "Number no loss change 23: | Current time: 67.917 | Loss difference: 4.783e-07 | Loss: 7.021e-06\n",
      "Number no loss change 24: | Current time: 70.323 | Loss difference: 7.426e-07 | Loss: 7.664e-06\n",
      "Number no loss change 25: | Current time: 72.248 | Loss difference: 9.489e-07 | Loss: 5.626e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  6\n",
      "Number no loss change 6: | Current time: 19.292 | Loss difference: 3.681e-07 | Loss: 4.339e-06\n",
      "Number no loss change 7: | Current time: 20.746 | Loss difference: 9.592e-07 | Loss: 4.553e-06\n",
      "Number no loss change 8: | Current time: 26.277 | Loss difference: 8.578e-07 | Loss: 5.485e-06\n",
      "Number no loss change 9: | Current time: 27.251 | Loss difference: 5.482e-07 | Loss: 3.942e-06\n",
      "Number no loss change 10: | Current time: 32.066 | Loss difference: 5.881e-07 | Loss: 4.106e-06\n",
      "Number no loss change 11: | Current time: 34.823 | Loss difference: 1.301e-07 | Loss: 3.97e-06\n",
      "Number no loss change 12: | Current time: 36.330 | Loss difference: 8.683e-07 | Loss: 7.629e-06\n",
      "Number no loss change 13: | Current time: 39.787 | Loss difference: 3.909e-07 | Loss: 4.726e-06\n",
      "Number no loss change 14: | Current time: 40.811 | Loss difference: 7.33e-07 | Loss: 1.594e-06\n",
      "Number no loss change 15: | Current time: 41.834 | Loss difference: 6.842e-07 | Loss: 2.453e-06\n",
      "Number no loss change 16: | Current time: 42.353 | Loss difference: 2.328e-07 | Loss: 2.22e-06\n",
      "Number no loss change 17: | Current time: 44.410 | Loss difference: 3.168e-07 | Loss: 5.626e-06\n",
      "Number no loss change 18: | Current time: 45.932 | Loss difference: 7.623e-08 | Loss: 4.845e-06\n",
      "Number no loss change 19: | Current time: 50.829 | Loss difference: 9.55e-07 | Loss: 1.15e-05\n",
      "Number no loss change 20: | Current time: 51.823 | Loss difference: 2.904e-07 | Loss: 2.686e-06\n",
      "Number no loss change 21: | Current time: 53.287 | Loss difference: 9.006e-08 | Loss: 3.72e-06\n",
      "Number no loss change 22: | Current time: 61.659 | Loss difference: 8.582e-08 | Loss: 2.585e-06\n",
      "Number no loss change 23: | Current time: 62.144 | Loss difference: 4.587e-08 | Loss: 2.631e-06\n",
      "Number no loss change 24: | Current time: 66.215 | Loss difference: 3.27e-07 | Loss: 7.732e-06\n",
      "Number no loss change 25: | Current time: 67.697 | Loss difference: 5.064e-07 | Loss: 3.827e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  7\n",
      "Number no loss change 6: | Current time: 24.060 | Loss difference: 2.538e-07 | Loss: 1.247e-05\n",
      "Number no loss change 7: | Current time: 29.364 | Loss difference: 3.552e-07 | Loss: 9.353e-06\n",
      "Number no loss change 8: | Current time: 29.917 | Loss difference: 7.736e-07 | Loss: 1.013e-05\n",
      "Number no loss change 9: | Current time: 39.285 | Loss difference: 4.515e-07 | Loss: 9.294e-06\n",
      "Number no loss change 10: | Current time: 45.649 | Loss difference: 4.19e-07 | Loss: 3.581e-06\n",
      "Number no loss change 11: | Current time: 46.125 | Loss difference: 5.691e-07 | Loss: 4.15e-06\n",
      "Number no loss change 12: | Current time: 55.082 | Loss difference: 1.866e-08 | Loss: 2.003e-06\n",
      "Number no loss change 13: | Current time: 64.401 | Loss difference: 3.453e-07 | Loss: 4.392e-06\n",
      "Number no loss change 14: | Current time: 69.269 | Loss difference: 7.65e-07 | Loss: 7.54e-06\n",
      "Number no loss change 15: | Current time: 70.443 | Loss difference: 8.511e-07 | Loss: 3.608e-06\n",
      "Number no loss change 16: | Current time: 71.891 | Loss difference: 3.984e-07 | Loss: 1.892e-06\n",
      "Number no loss change 17: | Current time: 72.871 | Loss difference: 3.687e-07 | Loss: 5.862e-06\n",
      "Number no loss change 18: | Current time: 73.372 | Loss difference: 8.054e-07 | Loss: 6.667e-06\n",
      "Number no loss change 19: | Current time: 74.363 | Loss difference: 2.099e-07 | Loss: 1.989e-05\n",
      "Number no loss change 20: | Current time: 83.877 | Loss difference: 1.059e-07 | Loss: 1.762e-06\n",
      "Number no loss change 21: | Current time: 86.142 | Loss difference: 7.31e-07 | Loss: 6.323e-06\n",
      "Number no loss change 22: | Current time: 86.637 | Loss difference: 4.216e-07 | Loss: 6.745e-06\n",
      "Number no loss change 23: | Current time: 88.593 | Loss difference: 4.288e-08 | Loss: 4.219e-06\n",
      "Number no loss change 24: | Current time: 89.581 | Loss difference: 4.612e-07 | Loss: 3.182e-06\n",
      "Number no loss change 25: | Current time: 90.549 | Loss difference: 6.893e-07 | Loss: 7.737e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  8\n",
      "Number no loss change 6: | Current time: 17.937 | Loss difference: 4.456e-07 | Loss: 5.298e-06\n",
      "Number no loss change 7: | Current time: 18.440 | Loss difference: 8.87e-07 | Loss: 4.411e-06\n",
      "Number no loss change 8: | Current time: 18.935 | Loss difference: 7.948e-07 | Loss: 3.617e-06\n",
      "Number no loss change 9: | Current time: 19.436 | Loss difference: 3.727e-07 | Loss: 3.244e-06\n",
      "Number no loss change 10: | Current time: 26.147 | Loss difference: 8.338e-07 | Loss: 4.175e-06\n",
      "Number no loss change 11: | Current time: 31.692 | Loss difference: 1.688e-07 | Loss: 4.917e-06\n",
      "Number no loss change 12: | Current time: 41.919 | Loss difference: 9.309e-07 | Loss: 2.104e-06\n",
      "Number no loss change 13: | Current time: 43.370 | Loss difference: 9.345e-07 | Loss: 2.962e-06\n",
      "Number no loss change 14: | Current time: 52.266 | Loss difference: 1.622e-07 | Loss: 4.935e-06\n",
      "Number no loss change 15: | Current time: 52.752 | Loss difference: 8.194e-07 | Loss: 4.116e-06\n",
      "Number no loss change 16: | Current time: 53.293 | Loss difference: 9.697e-07 | Loss: 3.146e-06\n",
      "Number no loss change 17: | Current time: 55.549 | Loss difference: 8.123e-07 | Loss: 6.464e-06\n",
      "Number no loss change 18: | Current time: 61.011 | Loss difference: 7.52e-09 | Loss: 6.338e-06\n",
      "Number no loss change 19: | Current time: 64.478 | Loss difference: 7.567e-07 | Loss: 5.692e-06\n",
      "Number no loss change 20: | Current time: 68.424 | Loss difference: 2.15e-07 | Loss: 2.242e-06\n",
      "Number no loss change 21: | Current time: 70.381 | Loss difference: 8.415e-07 | Loss: 4.923e-06\n",
      "Number no loss change 22: | Current time: 83.600 | Loss difference: 8.335e-07 | Loss: 4.503e-06\n",
      "Number no loss change 23: | Current time: 86.078 | Loss difference: 8.383e-07 | Loss: 3.604e-06\n",
      "Number no loss change 24: | Current time: 86.584 | Loss difference: 1.509e-07 | Loss: 3.755e-06\n",
      "Number no loss change 25: | Current time: 89.023 | Loss difference: 3.272e-07 | Loss: 2.888e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  9\n",
      "Number no loss change 6: | Current time: 19.231 | Loss difference: 6.383e-07 | Loss: 7.872e-06\n",
      "Number no loss change 7: | Current time: 23.652 | Loss difference: 8e-07 | Loss: 4.745e-06\n",
      "Number no loss change 8: | Current time: 24.130 | Loss difference: 5.564e-07 | Loss: 4.189e-06\n",
      "Number no loss change 9: | Current time: 25.590 | Loss difference: 4.997e-07 | Loss: 9.645e-06\n",
      "Number no loss change 10: | Current time: 26.552 | Loss difference: 8.783e-07 | Loss: 5.668e-06\n",
      "Number no loss change 11: | Current time: 27.056 | Loss difference: 7.555e-07 | Loss: 4.912e-06\n",
      "Number no loss change 12: | Current time: 35.859 | Loss difference: 7.86e-07 | Loss: 2.525e-06\n",
      "Number no loss change 13: | Current time: 45.626 | Loss difference: 4.027e-07 | Loss: 1.151e-05\n",
      "Number no loss change 14: | Current time: 48.556 | Loss difference: 4.261e-07 | Loss: 3.926e-06\n",
      "Number no loss change 15: | Current time: 54.894 | Loss difference: 9.478e-07 | Loss: 6.386e-06\n",
      "Number no loss change 16: | Current time: 55.374 | Loss difference: 9.418e-07 | Loss: 5.444e-06\n",
      "Number no loss change 17: | Current time: 57.826 | Loss difference: 7.738e-07 | Loss: 7.795e-06\n",
      "Number no loss change 18: | Current time: 59.266 | Loss difference: 1.652e-07 | Loss: 2.975e-06\n",
      "Number no loss change 19: | Current time: 60.706 | Loss difference: 1.613e-07 | Loss: 4.165e-06\n",
      "Number no loss change 20: | Current time: 61.706 | Loss difference: 2.003e-07 | Loss: 8.577e-06\n",
      "Number no loss change 21: | Current time: 63.180 | Loss difference: 6.094e-07 | Loss: 3.588e-06\n",
      "Number no loss change 22: | Current time: 64.625 | Loss difference: 6.14e-07 | Loss: 7.43e-06\n",
      "Number no loss change 23: | Current time: 65.579 | Loss difference: 6.824e-08 | Loss: 6.086e-06\n",
      "Number no loss change 24: | Current time: 69.515 | Loss difference: 9.549e-07 | Loss: 3.153e-06\n",
      "Number no loss change 25: | Current time: 69.996 | Loss difference: 5.005e-07 | Loss: 2.652e-06\n",
      "Test model beaten. Total beaten by prospective ground truth:  10\n",
      "Iteration:  1  | Ground truth number:  4\n",
      "Potential unbreakable found\n"
     ]
    }
   ],
   "source": [
    "#linear  combo 5d guassian weight*5\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "firstmodeltrained=binaryClassification()\n",
    "test_model_optimizer = optim.Adam(firstmodeltrained.parameters(), lr=LEARNING_RATE)\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader,test_model_optimizer)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    \n",
    "    test_model_list=[binaryClassification() for i in range(10)]\n",
    "    for i in range(0, 10):\n",
    "        total_time=0\n",
    "        infinite_time_counter=0\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "\n",
    "        for j, test_model in enumerate(test_model_list):\n",
    "            current_loss=0\n",
    "            previous_loss=0\n",
    "            train_testmodel=test_model.get_copy()\n",
    "            test_model_optimizer = optim.Adam(train_testmodel.parameters(), lr=LEARNING_RATE)\n",
    "            data_counter=0\n",
    "            test_time=0\n",
    "            inital_data_length=len(data_list)\n",
    "            accepted=False\n",
    "            loss_difference_counter=0\n",
    "            Model_beaten=False\n",
    "\n",
    "            while(not accepted): \n",
    "                #use previously generated data\n",
    "                if data_counter<inital_data_length:\n",
    "                    X=data_list[data_counter]\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    previous_loss=current_loss\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "                    data_counter=data_counter+1\n",
    "                #generate new data if needed\n",
    "                else:                          \n",
    "                    X=get_Xvals()\n",
    "                    data_list.append(X)\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                    previous_loss=current_loss\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "\n",
    "\n",
    "                #print(current_loss)\n",
    "\n",
    "                #checks if loss difference is small\n",
    "                if abs(loss_diff)<(1e-6):\n",
    "                    loss_difference_counter=loss_difference_counter+1\n",
    "                    if loss_difference_counter>25:\n",
    "                        infinite_time_counter=infinite_time_counter+1\n",
    "                        print(\"Test model beaten. Total beaten by prospective ground truth: \", infinite_time_counter)\n",
    "                        Model_beaten=True\n",
    "                    elif loss_difference_counter>5:\n",
    "                        print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    " \n",
    "\n",
    "                \n",
    "                if Model_beaten:\n",
    "                    break\n",
    "\n",
    "\n",
    "            total_time=total_time+test_time\n",
    "            #print(\"Iteration: \", interationcounter, \" | Ground truth number: \", i+1,\" | Test model number: \", j+1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        print(\"Iteration: \", interationcounter, \" | Ground truth number: \", i+1)\n",
    "\n",
    "        if infinite_time_counter==10:\n",
    "            print(\"Potential unbreakable found\")\n",
    "            possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "            break\n",
    "        time_list.append(total_time/(10))\n",
    "\n",
    "        \n",
    "           \n",
    "    \n",
    "    if infinite_time_counter==10:\n",
    "        break\n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    time_increase=max_new_time-current_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==10:\n",
    "        print(\"No increase for 10 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "      \n",
    "                                \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da379",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Linear combo [1]*5\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_modellinear(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==25:\n",
    "        print(\"No increase for 25 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6d956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
