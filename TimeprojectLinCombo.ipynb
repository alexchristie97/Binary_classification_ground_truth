{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0,
     44,
     63,
     82,
     94,
     106,
     115,
     158,
     214,
     244,
     262,
     486,
     525,
     552,
     578,
     604,
     650
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "    \n",
    "THRESH_HOLD=1e-3            #MSE value when we consider the second model to have \"cracked\" the first\n",
    "EPOCHS = 25                 #number of passes of whole data\n",
    "BATCH_SIZE = 64             #size of data going through at once\n",
    "LEARNING_RATE = 0.001       #how much we shift parameters during back prop\n",
    "NEURONS=5                   #number of nodes in each layer\n",
    "XSIZE=1056                  #size of each data set generated\n",
    "BADLOSSPASSES=1000          #number of times we have small loss until we stop code\n",
    "TESTMODULE_LAYERS=10        #number of layers in cracking module\n",
    "GROUND_TRUTH_LAYERS=5       #number of layers in ground thruth models\n",
    "\n",
    "    \n",
    "def get_Xvals():\n",
    "    return (np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getdata_XY():\n",
    "    X=(np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def trainnetwork(network, train_loader,Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #X_batch = X_batch.astype(np.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = torch.sigmoid(network(X_batch))\n",
    "            #y_pred = network(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')\n",
    "        #rint(\"Ave Loss: \", epoch_loss)\n",
    "        #rint(\"size \", len(train_loader))\n",
    "        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "\n",
    "\n",
    "def get_new_GroundTruth(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    \n",
    "    layer1_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer1_weight=layer1_weight+i.layer_1.weight/(len(better_model_list))\n",
    "        \n",
    "    layer1_weight.requires_grad_()\n",
    "    newGroundTruth.layer_1.weight=torch.nn.Parameter(layer1_weight)\n",
    "\n",
    "    layer2_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer2_weight=layer2_weight+i.layer_2.weight/(len(better_model_list))\n",
    "        \n",
    "    layer2_weight.requires_grad_()\n",
    "    newGroundTruth.layer_2.weight=torch.nn.Parameter(layer2_weight)\n",
    "    \n",
    "    \n",
    "    layer3_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer3_weight=layer3_weight+i.layer_3.weight/(len(better_model_list))\n",
    "        \n",
    "    layer3_weight.requires_grad_()\n",
    "    newGroundTruth.layer_3.weight=torch.nn.Parameter(layer3_weight)\n",
    "    \n",
    "    layer4_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer4_weight=layer4_weight+i.layer_4.weight/(len(better_model_list))\n",
    "        \n",
    "    layer4_weight.requires_grad_()\n",
    "    newGroundTruth.layer_4.weight=torch.nn.Parameter(layer4_weight)\n",
    "    \n",
    "    layer5_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer5_weight=layer5_weight+i.layer_5.weight/(len(better_model_list))\n",
    "        \n",
    "    layer5_weight.requires_grad_()\n",
    "    newGroundTruth.layer_5.weight=torch.nn.Parameter(layer5_weight)\n",
    "    \n",
    "                \n",
    "    layeroutput_weight=torch.tensor([[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layeroutput_weight=layeroutput_weight+i.layer_out.weight/(len(better_model_list))\n",
    "        \n",
    "    layeroutput_weight.requires_grad_()\n",
    "    newGroundTruth.layer_out.weight=torch.nn.Parameter(layeroutput_weight)\n",
    "    \n",
    "    return newGroundTruth\n",
    "        \n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    total_lossconfirm=0\n",
    "    #criterion = nn.MSELoss()\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            #loss = criterion(y_pred_tag, torch.tensor([y]))\n",
    "\n",
    "            \n",
    "            #print(\"y \", y)\n",
    "            #print(\"pred \", y_pred_tag.cpu().numpy())\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "            #total_lossconfirm=total_lossconfirm+loss.item()\n",
    "    \n",
    "    #total_loss=np.sqrt(total_loss)/len(truth)\n",
    "    total_loss=total_loss/len(truth)\n",
    "    total_lossconfirm=total_lossconfirm/len(truth)\n",
    "    #print(\"current loss: \", total_loss)\n",
    "    #print(\"current confirm loss: \", total_lossconfirm)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True, total_loss[0][0]\n",
    "    else:\n",
    "        return False, total_loss[0][0]\n",
    "        \n",
    "        \n",
    "def evalnetwork(network, test_loader, stats=True):\n",
    "    y_pred_list =[]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            y_test_pred = network(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            #y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    if(stats):\n",
    "        statistics(y_pred_list)\n",
    "    return y_pred_list\n",
    "\n",
    "def statistics(y_pred_list):\n",
    "    correctcounter=0\n",
    "    for i in range(len(y_pred_list)):\n",
    "        if y_pred_list[i]==y_test[i]:\n",
    "            correctcounter=correctcounter+1       \n",
    "\n",
    "    print(\"# correct: \",correctcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Model statistics\")\n",
    "    print(classification_report(y_test, y_pred_list))    \n",
    "    \n",
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, NEURONS) \n",
    "        self.layer_2 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_3 = nn.Linear(NEURONS, NEURONS)\n",
    "        self.layer_4 = nn.Linear(NEURONS,NEURONS)\n",
    "        self.layer_5 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_out = nn.Linear(NEURONS, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "     \n",
    "    def get_copy(self):\n",
    "        copied_model=binaryClassification()\n",
    "        copied_model.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        copied_model.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        copied_model.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        copied_model.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        copied_model.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        copied_model.layer_out = copy.deepcopy(self.layer_out)\n",
    "        copied_model.batchnorm1=copy.deepcopy(self.batchnorm1)\n",
    "        copied_model.batchnorm2=copy.deepcopy(self.batchnorm2)\n",
    "        copied_model.batchnorm3=copy.deepcopy(self.batchnorm3)\n",
    "        copied_model.batchnorm4=copy.deepcopy(self.batchnorm4)\n",
    "        copied_model.batchnorm5=copy.deepcopy(self.batchnorm5)\n",
    "\n",
    "        \n",
    "          \n",
    "        return copied_model\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    def change_node_modellinear(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=[1.0]*5\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=np.random.normal(0, 1, size=5)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "def select_node():\n",
    "    layer=randrange(5)\n",
    "    if layer!=6:\n",
    "        node=randrange(5)\n",
    "    else:\n",
    "        node=randrange(2)\n",
    "    return [layer, node]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class arbitraryLayerModel(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(arbitraryLayerModel, self).__init__()\n",
    "        self.layer_input=nn.Linear(5, NEURONS)\n",
    "        self.layers=nn.ModuleList([nn.Linear(NEURONS, NEURONS) for i in range(num_layers)])\n",
    "        self.batchnorms=nn.ModuleList([nn.BatchNorm1d(NEURONS) for i in range(num_layers)])\n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def get_copy(self):\n",
    "        copied_model=arbitraryLayerModel()\n",
    "        copied_model.layers=nn.ModuleList()\n",
    "        for i in self.layers:\n",
    "            copied_model.layers.append(copy.deepcopy(i))\n",
    "            \n",
    "        copied_model.batchnorms=nn.ModuleList()\n",
    "        for i in self.batchnorms:\n",
    "            copied_model.batchnorms.append(copy.deepcopy(i))\n",
    "        copied_model.layer_input=copy.deepcopy(self.layer_input)\n",
    "        copied_model.layer_output=copy.deepcopy(self.layer_output)\n",
    "\n",
    "        return copied_model\n",
    "            \n",
    "     \n",
    "    def forward(self, inputs):\n",
    "        x=self.relu(self.layer_input(inputs))\n",
    "        for (layer, batchnorm) in zip(self.layers, self.batchnorms):\n",
    "            x=batchnorm(x)\n",
    "            x=self.relu(layer(x))\n",
    "            x=self.dropout(x)\n",
    "        x=self.layer_output(x)\n",
    "        return(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=self.get_copy()\n",
    "        \n",
    "        weightchange=np.random.normal(0,1)\n",
    "        weightchange=[weightchange.item()]\n",
    "        zeros=[[0]]*(NEURONS-1)\n",
    "        if node[0]==0:\n",
    "            zeros.insert(weightchange, node[1])\n",
    "            newweight=self.layer_input.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_input.weight=torch.nn.Parameter(newweight)    \n",
    "            return changed_node\n",
    "            \n",
    "            \n",
    "        weightchange=np.random.normal(0, 1, size=NEURONS)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "        zeros = [[0.0]*NEURONS]*(NEURONS-1)\n",
    "        \n",
    "        if node[0]==TESTMODULE_LAYERS+1:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight) \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            for layer, i in enumerate(changed_node.layers):\n",
    "                if i==node[0]+1:\n",
    "                    zeros.insert(weightchange,node[1])\n",
    "                    newweight=layer.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "                    newweight.requires_grad_()\n",
    "                    layer.weight=torch.nn.Parameter(newweight)\n",
    "                    \n",
    "        \n",
    "\n",
    "        return changed_node\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2419aa",
   "metadata": {
    "code_folding": [
     17
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time:  1.2305994033813477\n",
      "Iteration 1: | Previous time: 1.231 | Best new time: 1.291 | Difference: 0.060\n",
      "Iteration 2: | Previous time: 1.291 | Best new time: 1.356 | Difference: 0.065\n",
      "Iteration 3: | Previous time: 1.356 | Best new time: 1.268 | Difference: -0.088\n",
      "Iteration 4: | Previous time: 1.356 | Best new time: 1.284 | Difference: -0.072\n",
      "Iteration 5: | Previous time: 1.356 | Best new time: 1.283 | Difference: -0.073\n",
      "Iteration 6: | Previous time: 1.356 | Best new time: 1.290 | Difference: -0.066\n",
      "Iteration 7: | Previous time: 1.356 | Best new time: 1.247 | Difference: -0.109\n",
      "Iteration 8: | Previous time: 1.356 | Best new time: 1.248 | Difference: -0.108\n",
      "Iteration 9: | Previous time: 1.356 | Best new time: 1.213 | Difference: -0.143\n",
      "Iteration 10: | Previous time: 1.356 | Best new time: 1.296 | Difference: -0.059\n",
      "Iteration 11: | Previous time: 1.356 | Best new time: 1.265 | Difference: -0.091\n",
      "Iteration 12: | Previous time: 1.356 | Best new time: 1.233 | Difference: -0.123\n",
      "Iteration 13: | Previous time: 1.356 | Best new time: 1.233 | Difference: -0.123\n",
      "Iteration 14: | Previous time: 1.356 | Best new time: 1.852 | Difference: 0.497\n",
      "Iteration 15: | Previous time: 1.852 | Best new time: 1.239 | Difference: -0.613\n",
      "Iteration 16: | Previous time: 1.852 | Best new time: 1.252 | Difference: -0.600\n",
      "Iteration 17: | Previous time: 1.852 | Best new time: 1.220 | Difference: -0.632\n",
      "Iteration 18: | Previous time: 1.852 | Best new time: 1.228 | Difference: -0.624\n",
      "Iteration 19: | Previous time: 1.852 | Best new time: 1.273 | Difference: -0.579\n",
      "Iteration 20: | Previous time: 1.852 | Best new time: 1.267 | Difference: -0.585\n",
      "Iteration 21: | Previous time: 1.852 | Best new time: 1.221 | Difference: -0.632\n",
      "Iteration 22: | Previous time: 1.852 | Best new time: 1.216 | Difference: -0.637\n",
      "Iteration 23: | Previous time: 1.852 | Best new time: 1.246 | Difference: -0.606\n",
      "Iteration 24: | Previous time: 1.852 | Best new time: 1.226 | Difference: -0.627\n",
      "Iteration 25: | Previous time: 1.852 | Best new time: 1.259 | Difference: -0.593\n",
      "Iteration 26: | Previous time: 1.852 | Best new time: 1.246 | Difference: -0.606\n",
      "Iteration 27: | Previous time: 1.852 | Best new time: 1.707 | Difference: -0.145\n",
      "Iteration 28: | Previous time: 1.852 | Best new time: 1.233 | Difference: -0.619\n",
      "Iteration 29: | Previous time: 1.852 | Best new time: 1.377 | Difference: -0.475\n",
      "Iteration 30: | Previous time: 1.852 | Best new time: 1.258 | Difference: -0.594\n",
      "Iteration 31: | Previous time: 1.852 | Best new time: 1.257 | Difference: -0.595\n",
      "Iteration 32: | Previous time: 1.852 | Best new time: 1.254 | Difference: -0.598\n",
      "Iteration 33: | Previous time: 1.852 | Best new time: 1.258 | Difference: -0.594\n",
      "Iteration 34: | Previous time: 1.852 | Best new time: 1.227 | Difference: -0.625\n",
      "Iteration 35: | Previous time: 1.852 | Best new time: 1.221 | Difference: -0.631\n",
      "Iteration 36: | Previous time: 1.852 | Best new time: 1.214 | Difference: -0.638\n",
      "Iteration 37: | Previous time: 1.852 | Best new time: 1.336 | Difference: -0.516\n",
      "Iteration 38: | Previous time: 1.852 | Best new time: 1.231 | Difference: -0.621\n",
      "Iteration 39: | Previous time: 1.852 | Best new time: 1.266 | Difference: -0.586\n",
      "No increase for 25 iterations\n"
     ]
    }
   ],
   "source": [
    "#Linear combo 5d guassian weight \n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==25:\n",
    "        print(\"No increase for 25 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "        \n",
    "                          \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a24e46",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time:  0.9680702686309814\n",
      "Iteration 1: | Previous time: 0.968 | Best new time: 0.978 | Difference: 0.010\n",
      "Iteration 2: | Previous time: 0.978 | Best new time: 1.920 | Difference: 0.942\n",
      "Iteration 3: | Previous time: 1.920 | Best new time: 2.111 | Difference: 0.192\n",
      "Iteration 4: | Previous time: 2.111 | Best new time: 1.951 | Difference: -0.161\n",
      "Iteration 5: | Previous time: 2.111 | Best new time: 1.938 | Difference: -0.173\n",
      "Iteration 6: | Previous time: 2.111 | Best new time: 1.943 | Difference: -0.168\n",
      "Iteration 7: | Previous time: 2.111 | Best new time: 1.940 | Difference: -0.171\n",
      "Iteration 8: | Previous time: 2.111 | Best new time: 2.396 | Difference: 0.285\n",
      "Iteration 9: | Previous time: 2.396 | Best new time: 5.757 | Difference: 3.360\n",
      "Iteration 10: | Previous time: 5.757 | Best new time: 4.850 | Difference: -0.906\n",
      "Iteration 11: | Previous time: 5.757 | Best new time: 4.504 | Difference: -1.252\n",
      "Iteration 12: | Previous time: 5.757 | Best new time: 2.346 | Difference: -3.411\n",
      "Iteration 13: | Previous time: 5.757 | Best new time: 4.226 | Difference: -1.531\n",
      "Iteration 14: | Previous time: 5.757 | Best new time: 6.528 | Difference: 0.772\n",
      "Iteration 15: | Previous time: 6.528 | Best new time: 12.494 | Difference: 5.965\n",
      "Iteration 16: | Previous time: 12.494 | Best new time: 9.531 | Difference: -2.963\n",
      "Iteration 17: | Previous time: 12.494 | Best new time: 2.217 | Difference: -10.277\n",
      "Iteration 18: | Previous time: 12.494 | Best new time: 4.111 | Difference: -8.383\n",
      "Iteration 19: | Previous time: 12.494 | Best new time: 4.258 | Difference: -8.236\n",
      "Iteration 20: | Previous time: 12.494 | Best new time: 6.330 | Difference: -6.164\n",
      "Iteration 21: | Previous time: 12.494 | Best new time: 5.238 | Difference: -7.256\n",
      "Iteration 22: | Previous time: 12.494 | Best new time: 4.238 | Difference: -8.256\n",
      "Number no losss change 6: | Current time: 439.126 | Loss difference: 4.547e-07 | Loss: 0.00018766344874165952\n",
      "Number no losss change 7: | Current time: 462.084 | Loss difference: 1.861e-07 | Loss: 0.00011171129153808579\n",
      "Number no losss change 8: | Current time: 503.905 | Loss difference: 3.975e-07 | Loss: 0.00018646445823833346\n",
      "Number no losss change 9: | Current time: 545.867 | Loss difference: 9.544e-08 | Loss: 0.00010716650285758078\n"
     ]
    }
   ],
   "source": [
    "#Coordinate descent, add 5d gaussian \n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    time_increase=max_new_time-current_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        max_index=time_list.index(max_new_time)\n",
    "        GroundTruth=model_list[i].get_copy()\n",
    "        time_increase=True\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==10:\n",
    "        print(\"No increase for 10 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1f88b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time:  1.2061059474945068\n",
      "Iteration 1: | Previous time: 1.206 | Best new time: 1.325 | Difference: 0.119\n",
      "Iteration 2: | Previous time: 1.325 | Best new time: 1.299 | Difference: -0.026\n",
      "Iteration 3: | Previous time: 1.325 | Best new time: 1.310 | Difference: -0.015\n",
      "Iteration 4: | Previous time: 1.325 | Best new time: 2.368 | Difference: 1.043\n",
      "Iteration 5: | Previous time: 2.368 | Best new time: 4.807 | Difference: 2.439\n",
      "Iteration 6: | Previous time: 4.807 | Best new time: 7.254 | Difference: 2.446\n",
      "Iteration 7: | Previous time: 7.254 | Best new time: 20.876 | Difference: 13.623\n",
      "Iteration 8: | Previous time: 20.876 | Best new time: 17.925 | Difference: -2.951\n",
      "Number no loss change 6: | Current time: 23.875 | Loss difference: 0.0002548 | Loss: 0.0015785606810823083\n",
      "Number no loss change 7: | Current time: 25.055 | Loss difference: 0.0003635 | Loss: 0.0019420890603214502\n",
      "Number no loss change 8: | Current time: 27.432 | Loss difference: 7.055e-05 | Loss: 0.0014148685149848461\n",
      "Number no loss change 9: | Current time: 29.847 | Loss difference: 0.0001615 | Loss: 0.001380488625727594\n",
      "Number no loss change 10: | Current time: 32.201 | Loss difference: 3.871e-05 | Loss: 0.0012680930085480213\n",
      "Number no loss change 11: | Current time: 33.366 | Loss difference: 0.0003825 | Loss: 0.0016505812527611852\n",
      "Number no loss change 12: | Current time: 36.887 | Loss difference: 1.1e-05 | Loss: 0.0012849076883867383\n",
      "Number no loss change 13: | Current time: 38.050 | Loss difference: 7.757e-05 | Loss: 0.0013624825514853\n",
      "Number no loss change 14: | Current time: 40.542 | Loss difference: 1.476e-05 | Loss: 0.001297821756452322\n",
      "Number no loss change 15: | Current time: 41.770 | Loss difference: 0.0001269 | Loss: 0.0014246812788769603\n",
      "Number no loss change 16: | Current time: 45.266 | Loss difference: 2.733e-05 | Loss: 0.0013588510919362307\n",
      "Number no loss change 17: | Current time: 47.638 | Loss difference: 0.0001556 | Loss: 0.0015037604607641697\n",
      "Number no loss change 18: | Current time: 50.021 | Loss difference: 0.0003505 | Loss: 0.0015728077851235867\n",
      "Number no loss change 19: | Current time: 54.798 | Loss difference: 6.954e-05 | Loss: 0.0013549060095101595\n",
      "Number no loss change 20: | Current time: 58.520 | Loss difference: 0.0001027 | Loss: 0.0012206864776089787\n",
      "Number no loss change 21: | Current time: 60.881 | Loss difference: 0.0002478 | Loss: 0.0013475494924932718\n",
      "Number no loss change 22: | Current time: 63.235 | Loss difference: 4.664e-05 | Loss: 0.0011627518106251955\n",
      "Number no loss change 23: | Current time: 64.473 | Loss difference: 0.0001823 | Loss: 0.0013450438855215907\n",
      "Number no loss change 24: | Current time: 66.806 | Loss difference: 2.522e-06 | Loss: 0.0012620346387848258\n",
      "Number no loss change 6: | Current time: 24.831 | Loss difference: 0.0001911 | Loss: 0.0023642508313059807\n",
      "Number no loss change 7: | Current time: 28.314 | Loss difference: 0.0001988 | Loss: 0.001990978140383959\n",
      "Number no loss change 8: | Current time: 30.616 | Loss difference: 0.0005162 | Loss: 0.0023240498267114162\n",
      "Number no loss change 9: | Current time: 33.104 | Loss difference: 0.0002196 | Loss: 0.0019040959887206554\n",
      "Number no loss change 10: | Current time: 34.347 | Loss difference: 0.0005739 | Loss: 0.0024779564701020718\n",
      "Number no loss change 11: | Current time: 37.938 | Loss difference: 2.256e-05 | Loss: 0.0013698104303330183\n",
      "Iteration 9: | Previous time: 20.876 | Best new time: 69.211 | Difference: 48.334\n",
      "Number no loss change 6: | Current time: 19.053 | Loss difference: 0.001065 | Loss: 0.0022100505884736776\n",
      "Number no loss change 6: | Current time: 20.293 | Loss difference: 0.0003037 | Loss: 0.001802780432626605\n",
      "Number no loss change 6: | Current time: 24.154 | Loss difference: 0.0005077 | Loss: 0.0020740872714668512\n",
      "Iteration 10: | Previous time: 69.211 | Best new time: 25.351 | Difference: -43.860\n",
      "Iteration 11: | Previous time: 69.211 | Best new time: 20.875 | Difference: -48.336\n",
      "Number no loss change 6: | Current time: 16.237 | Loss difference: 0.0005512 | Loss: 0.0016197044169530272\n",
      "Number no loss change 6: | Current time: 23.686 | Loss difference: 0.0001034 | Loss: 0.0013341602170839906\n",
      "Number no loss change 7: | Current time: 26.072 | Loss difference: 0.0002542 | Loss: 0.0014293703716248274\n",
      "Number no loss change 8: | Current time: 29.713 | Loss difference: 0.0001217 | Loss: 0.001241834368556738\n",
      "Iteration 12: | Previous time: 69.211 | Best new time: 30.916 | Difference: -38.295\n",
      "Number no loss change 6: | Current time: 19.589 | Loss difference: 0.000348 | Loss: 0.0014423809479922056\n",
      "Iteration 13: | Previous time: 69.211 | Best new time: 25.428 | Difference: -43.782\n",
      "Number no loss change 6: | Current time: 23.208 | Loss difference: 0.0002828 | Loss: 0.0014580891001969576\n",
      "Number no loss change 7: | Current time: 25.645 | Loss difference: 1.19e-05 | Loss: 0.0012749688467010856\n",
      "Number no loss change 6: | Current time: 19.697 | Loss difference: 0.0005487 | Loss: 0.0018260650103911757\n",
      "Number no loss change 7: | Current time: 22.104 | Loss difference: 0.001093 | Loss: 0.002398202195763588\n",
      "Number no loss change 8: | Current time: 23.425 | Loss difference: 0.0007003 | Loss: 0.003098456421867013\n",
      "Number no loss change 9: | Current time: 25.867 | Loss difference: 0.0002931 | Loss: 0.0018473489908501506\n",
      "Number no loss change 10: | Current time: 28.401 | Loss difference: 0.0002211 | Loss: 0.00164946005679667\n",
      "Number no loss change 11: | Current time: 29.668 | Loss difference: 0.0002603 | Loss: 0.0019097572658210993\n",
      "Number no loss change 12: | Current time: 30.895 | Loss difference: 0.0001954 | Loss: 0.0021051312796771526\n",
      "Iteration 14: | Previous time: 69.211 | Best new time: 32.184 | Difference: -37.026\n",
      "Number no loss change 6: | Current time: 21.268 | Loss difference: 0.0007672 | Loss: 0.0018163922941312194\n",
      "Number no loss change 7: | Current time: 24.835 | Loss difference: 0.0001821 | Loss: 0.0012441768776625395\n",
      "Number no loss change 6: | Current time: 20.398 | Loss difference: 0.0001938 | Loss: 0.0015282820677384734\n",
      "Iteration 15: | Previous time: 69.211 | Best new time: 28.528 | Difference: -40.683\n",
      "Iteration 16: | Previous time: 69.211 | Best new time: 25.028 | Difference: -44.182\n",
      "Number no loss change 6: | Current time: 18.723 | Loss difference: 0.0005346 | Loss: 0.0026966731529682875\n",
      "Iteration 17: | Previous time: 69.211 | Best new time: 22.355 | Difference: -46.856\n",
      "Number no loss change 6: | Current time: 27.687 | Loss difference: 8.409e-05 | Loss: 0.001603035838343203\n",
      "Number no loss change 6: | Current time: 26.460 | Loss difference: 8.9e-05 | Loss: 0.0013746442273259163\n",
      "Number no loss change 7: | Current time: 30.002 | Loss difference: 7.63e-05 | Loss: 0.0013838164741173387\n",
      "Iteration 18: | Previous time: 69.211 | Best new time: 31.165 | Difference: -38.046\n",
      "Number no loss change 6: | Current time: 21.132 | Loss difference: 0.0004588 | Loss: 0.0017268691444769502\n",
      "Number no loss change 7: | Current time: 23.482 | Loss difference: 0.0003017 | Loss: 0.0016474624862894416\n",
      "Number no loss change 8: | Current time: 24.614 | Loss difference: 0.0002454 | Loss: 0.0018928420031443238\n",
      "Number no loss change 9: | Current time: 29.347 | Loss difference: 0.0002075 | Loss: 0.0014278085436671972\n",
      "Number no loss change 10: | Current time: 30.469 | Loss difference: 5.845e-05 | Loss: 0.0014862538082525134\n",
      "Number no loss change 11: | Current time: 32.795 | Loss difference: 0.0006043 | Loss: 0.001795782009139657\n",
      "Number no loss change 12: | Current time: 38.644 | Loss difference: 8.045e-05 | Loss: 0.0014490324538201094\n",
      "Number no loss change 13: | Current time: 39.773 | Loss difference: 0.0002576 | Loss: 0.0017066571163013577\n",
      "Number no loss change 14: | Current time: 42.096 | Loss difference: 0.0007992 | Loss: 0.002046516863629222\n",
      "Number no loss change 15: | Current time: 45.576 | Loss difference: 0.0003841 | Loss: 0.001617205562070012\n",
      "Number no loss change 16: | Current time: 47.908 | Loss difference: 1.644e-05 | Loss: 0.0015284923138096929\n",
      "Number no loss change 17: | Current time: 49.073 | Loss difference: 0.0002278 | Loss: 0.0017562743742018938\n",
      "Number no loss change 18: | Current time: 51.373 | Loss difference: 0.0003968 | Loss: 0.0014362788060680032\n",
      "Number no loss change 19: | Current time: 52.534 | Loss difference: 0.0002537 | Loss: 0.0016900122864171863\n",
      "Number no loss change 20: | Current time: 54.867 | Loss difference: 0.0004218 | Loss: 0.0016547651030123234\n",
      "Number no loss change 21: | Current time: 57.183 | Loss difference: 0.0002748 | Loss: 0.001650057965889573\n",
      "Number no loss change 22: | Current time: 61.743 | Loss difference: 0.0004649 | Loss: 0.0017674850532785058\n",
      "Number no loss change 23: | Current time: 64.157 | Loss difference: 4.909e-05 | Loss: 0.0015603965148329735\n",
      "Number no loss change 24: | Current time: 65.310 | Loss difference: 0.0001001 | Loss: 0.0016604670090600848\n",
      "Number no loss change 25: | Current time: 66.479 | Loss difference: 8.256e-06 | Loss: 0.001668723183684051\n",
      "Number no loss change 26: | Current time: 68.791 | Loss difference: 0.0001967 | Loss: 0.0016128813149407506\n",
      "Number no loss change 27: | Current time: 71.102 | Loss difference: 0.0003532 | Loss: 0.0016329832142218947\n",
      "Number no loss change 28: | Current time: 75.789 | Loss difference: 0.0001609 | Loss: 0.001541644218377769\n",
      "Number no loss change 29: | Current time: 78.108 | Loss difference: 0.000354 | Loss: 0.0015993674751371145\n",
      "Number no loss change 30: | Current time: 80.375 | Loss difference: 0.000325 | Loss: 0.001666972297243774\n",
      "Number no loss change 31: | Current time: 82.751 | Loss difference: 0.0002793 | Loss: 0.0014918403467163444\n",
      "Number no loss change 6: | Current time: 24.215 | Loss difference: 0.0006628 | Loss: 0.0017168163321912289\n",
      "Iteration 19: | Previous time: 69.211 | Best new time: 85.071 | Difference: 15.860\n",
      "Number no loss change 6: | Current time: 28.858 | Loss difference: 0.0002444 | Loss: 0.001452691270969808\n",
      "Number no loss change 7: | Current time: 32.608 | Loss difference: 9.953e-06 | Loss: 0.0012778312666341662\n",
      "Number no loss change 8: | Current time: 33.815 | Loss difference: 0.0001128 | Loss: 0.001390643767081201\n",
      "Number no loss change 9: | Current time: 35.141 | Loss difference: 0.0001811 | Loss: 0.0015717935748398304\n",
      "Number no loss change 10: | Current time: 38.939 | Loss difference: 0.0004443 | Loss: 0.0016321215080097318\n",
      "Number no loss change 11: | Current time: 40.340 | Loss difference: 0.002819 | Loss: 0.004450878594070673\n",
      "Number no loss change 12: | Current time: 44.433 | Loss difference: 0.0001323 | Loss: 0.0013789423974230886\n",
      "Number no loss change 13: | Current time: 45.592 | Loss difference: 4.86e-05 | Loss: 0.001427540904842317\n",
      "Number no loss change 14: | Current time: 46.837 | Loss difference: 8.552e-05 | Loss: 0.0015130647225305438\n",
      "Number no loss change 15: | Current time: 49.256 | Loss difference: 0.0004655 | Loss: 0.0015324711566790938\n",
      "Number no loss change 16: | Current time: 50.496 | Loss difference: 4.732e-05 | Loss: 0.0015797895612195134\n",
      "Number no loss change 17: | Current time: 52.946 | Loss difference: 0.0007599 | Loss: 0.0019770232029259205\n",
      "Number no loss change 18: | Current time: 55.480 | Loss difference: 0.0003365 | Loss: 0.0016178737860172987\n",
      "Number no loss change 19: | Current time: 58.050 | Loss difference: 7.274e-05 | Loss: 0.0015142709016799927\n",
      "Number no loss change 20: | Current time: 63.530 | Loss difference: 0.0001066 | Loss: 0.001507461885921657\n",
      "Number no loss change 21: | Current time: 64.915 | Loss difference: 6.872e-05 | Loss: 0.001576183014549315\n",
      "Number no loss change 22: | Current time: 67.408 | Loss difference: 0.0002533 | Loss: 0.0013299848651513457\n",
      "Number no loss change 23: | Current time: 68.682 | Loss difference: 4.954e-05 | Loss: 0.0013795216800644994\n",
      "Number no loss change 24: | Current time: 69.916 | Loss difference: 3.713e-05 | Loss: 0.0014166489709168673\n",
      "Number no loss change 25: | Current time: 71.082 | Loss difference: 6.251e-05 | Loss: 0.0014791606226935983\n",
      "Number no loss change 26: | Current time: 73.538 | Loss difference: 0.0002336 | Loss: 0.0015821814304217696\n",
      "Number no loss change 27: | Current time: 75.977 | Loss difference: 0.0001701 | Loss: 0.001341218245215714\n",
      "Number no loss change 28: | Current time: 77.226 | Loss difference: 2.322e-06 | Loss: 0.001343540265224874\n",
      "Number no loss change 6: | Current time: 17.715 | Loss difference: 0.0001489 | Loss: 0.0015683030942454934\n",
      "Number no loss change 7: | Current time: 20.042 | Loss difference: 3.428e-05 | Loss: 0.0015378294046968222\n",
      "Number no loss change 6: | Current time: 19.634 | Loss difference: 0.0007512 | Loss: 0.002070334739983082\n",
      "Iteration 20: | Previous time: 85.071 | Best new time: 78.430 | Difference: -6.641\n",
      "Number no loss change 6: | Current time: 18.720 | Loss difference: 0.000108 | Loss: 0.0016351236263290048\n",
      "Number no loss change 7: | Current time: 19.860 | Loss difference: 0.0004284 | Loss: 0.002063566818833351\n",
      "Number no loss change 8: | Current time: 23.272 | Loss difference: 0.0002038 | Loss: 0.0014269421808421612\n",
      "Number no loss change 9: | Current time: 25.625 | Loss difference: 7.19e-05 | Loss: 0.0013917854521423578\n",
      "Number no loss change 10: | Current time: 28.001 | Loss difference: 0.0002294 | Loss: 0.0014461950631812215\n",
      "Number no loss change 11: | Current time: 30.281 | Loss difference: 0.0005477 | Loss: 0.0016601404640823603\n",
      "Number no loss change 12: | Current time: 31.441 | Loss difference: 0.0001249 | Loss: 0.0017850259318947792\n",
      "Number no loss change 13: | Current time: 33.794 | Loss difference: 0.0006311 | Loss: 0.001949273981153965\n",
      "Number no loss change 6: | Current time: 18.674 | Loss difference: 0.0008711 | Loss: 0.0019920323975384235\n",
      "Number no loss change 7: | Current time: 22.156 | Loss difference: 5.989e-05 | Loss: 0.0011128621408715844\n",
      "Number no loss change 8: | Current time: 23.272 | Loss difference: 8.108e-05 | Loss: 0.0011939407559111714\n",
      "Number no loss change 9: | Current time: 24.456 | Loss difference: 2.019e-05 | Loss: 0.0012141349725425243\n",
      "Iteration 21: | Previous time: 85.071 | Best new time: 36.052 | Difference: -49.019\n",
      "Number no loss change 6: | Current time: 19.642 | Loss difference: 0.0001041 | Loss: 0.001485526212491095\n",
      "Number no loss change 7: | Current time: 23.120 | Loss difference: 1.173e-05 | Loss: 0.0010574680054560304\n",
      "Number no loss change 8: | Current time: 24.301 | Loss difference: 9.481e-05 | Loss: 0.001152273267507553\n",
      "Iteration 22: | Previous time: 85.071 | Best new time: 25.421 | Difference: -59.651\n",
      "Number no loss change 6: | Current time: 24.595 | Loss difference: 0.0003756 | Loss: 0.0017939785029739141\n",
      "Number no loss change 6: | Current time: 16.923 | Loss difference: 5.948e-06 | Loss: 0.0011239483719691634\n",
      "Iteration 23: | Previous time: 85.071 | Best new time: 29.831 | Difference: -55.240\n",
      "Number no loss change 6: | Current time: 24.561 | Loss difference: 0.0006447 | Loss: 0.0019843222107738256\n",
      "Number no loss change 7: | Current time: 28.022 | Loss difference: 0.0005482 | Loss: 0.0015990855172276497\n",
      "Number no loss change 6: | Current time: 19.317 | Loss difference: 0.0009524 | Loss: 0.002138687763363123\n",
      "Number no loss change 7: | Current time: 22.915 | Loss difference: 0.0001846 | Loss: 0.0014934387290850282\n",
      "Number no loss change 8: | Current time: 24.202 | Loss difference: 4.896e-05 | Loss: 0.0015423991717398167\n",
      "Number no loss change 9: | Current time: 25.498 | Loss difference: 0.0005516 | Loss: 0.00209396262653172\n",
      "Number no loss change 10: | Current time: 28.009 | Loss difference: 0.0001614 | Loss: 0.0013639156240969896\n",
      "Number no loss change 11: | Current time: 29.643 | Loss difference: 6.477e-05 | Loss: 0.0014286863151937723\n",
      "Number no loss change 12: | Current time: 30.961 | Loss difference: 0.0002595 | Loss: 0.001688153832219541\n",
      "Number no loss change 13: | Current time: 33.675 | Loss difference: 0.0002857 | Loss: 0.0014719300670549273\n",
      "Number no loss change 14: | Current time: 34.916 | Loss difference: 5.293e-05 | Loss: 0.0015248648123815656\n",
      "Iteration 24: | Previous time: 85.071 | Best new time: 37.587 | Difference: -47.484\n"
     ]
    }
   ],
   "source": [
    "#Linear combo [1]*5\n",
    "       \n",
    "#groundtruth model  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=binaryClassification()\n",
    "possible_infinite_time=binaryClassification()\n",
    "\n",
    "\n",
    "\n",
    "test_model=binaryClassification()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_modellinear(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==25:\n",
    "        print(\"No increase for 25 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f5d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
