{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=np.random.normal(0, 1, size=(3000, 5))\n",
    "\n",
    "\n",
    "y=[]\n",
    "for i in range(3000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, 5) \n",
    "        self.layer_2 = nn.Linear(5, 5) \n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4 = nn.Linear(5, 5)\n",
    "        self.layer_5 = nn.Linear(5, 5) \n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196afae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#parallel model (two 5 layer models, with output going into new output layer)\n",
    "class parallelmodel(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(parallelmodel, self).__init__()\n",
    "        self.layer1_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer1_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer1_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer1_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer1_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer1_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu1 = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout1 = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1_1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm1_2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm1_3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm1_4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm1_5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        #self.batchnorm1_out=nn.BatchNorm1d(1)\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        #self.batchnorm2_out=nn.BatchNorm1d()\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1, bias=False)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu1(self.layer1_1(inputs))\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu1(self.layer1_2(x))\n",
    "        x = self.batchnorm1_2(x)\n",
    "        x = self.relu1(self.layer1_3(x))\n",
    "        x = self.batchnorm1_3(x)\n",
    "        x = self.relu1(self.layer1_4(x))\n",
    "        x = self.batchnorm1_4(x)\n",
    "        x = self.relu1(self.layer1_5(x))\n",
    "        x = self.batchnorm1_5(x) \n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer1_out(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(inputs))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18de1eec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model that only does partial backprop\n",
    "class partialparralelmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(partialparralelmodel, self).__init__()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        y=inputs[:, :5]\n",
    "        x=inputs[:, 5:]\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(y))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 100 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "\n",
    "\n",
    "baddata=True\n",
    "while(baddata):\n",
    "\n",
    "    \n",
    "\n",
    "    GroundTruth.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in Truthloadertrain:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            truthoptimizer.zero_grad()\n",
    "\n",
    "            y_pred = GroundTruth(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            truthoptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "    Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_allscaled, y, test_size=0.33, random_state=69)\n",
    "    truthcounter=0\n",
    "    for i in y:\n",
    "        if i==1:\n",
    "            truthcounter=truthcounter+1\n",
    "    \n",
    "    \n",
    "    #print(truthcounter)\n",
    "    if truthcounter/len(y)<.8 and truthcounter/len(y)>.2:\n",
    "        baddata=False\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  895  out of  990\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.80      0.85       329\n",
      "         1.0       0.91      0.95      0.93       661\n",
      "\n",
      "    accuracy                           0.90       990\n",
      "   macro avg       0.90      0.88      0.89       990\n",
      "weighted avg       0.90      0.90      0.90       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "newinputvar=[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truthloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = trained(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = y_truth\n",
    "        newinputvar.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "newinputvar = [[a.squeeze().tolist() for a in newinputvar]]\n",
    "\n",
    "#print(newinputvar)\n",
    "X_allscaledextra=np.append(X_allscaled, np.array(newinputvar).reshape(len(y),1), axis=1)   \n",
    "\n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "    \n",
    "#format new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_allscaledextra, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####ORIGINAL LOADERS\n",
    "\n",
    "\n",
    "X_trainorig=X_train[:,:5]\n",
    "X_testorig=X_test[:,:5]\n",
    "test_dataorig = testData(torch.FloatTensor(X_testorig))\n",
    "\n",
    "test_loaderorig=DataLoader(dataset=test_dataorig)\n",
    "\n",
    "\n",
    "testifworks =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        testifworks.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "testifworks = [a.squeeze().tolist() for a in testifworks]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  919  out of  990\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.88      0.89       329\n",
      "         1.0       0.94      0.95      0.95       661\n",
      "\n",
      "    accuracy                           0.93       990\n",
      "   macro avg       0.92      0.92      0.92       990\n",
      "weighted avg       0.93      0.93      0.93       990\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[ 8.3994, -4.9226]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#train partial parralel model\n",
    "parralel = partialparralelmodel()\n",
    "parralel.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "parralel.outputlayer.weight=torch.nn.Parameter(data=torch.tensor([[.9,0.05]]), requires_grad=True)\n",
    "parralel.alpha.append(.9)\n",
    "parralel.beta.append(0.05)\n",
    "epochlist=[]\n",
    "losslist=[]\n",
    "\n",
    "paroptimizer = optim.Adam(parralel.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "#EPOCHS = 300 #number of passes of whole data\n",
    "#BATCH_SIZE = 16 #size of data going through at once\n",
    "\n",
    "\n",
    "\n",
    "#train trained model\n",
    "parralel.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        paroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = parralel(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        paroptimizer.step()\n",
    "        \n",
    "        parralel.alpha.append(parralel.outputlayer.weight[0][0].detach().numpy().item())\n",
    "        parralel.beta.append(parralel.outputlayer.weight[0][1].detach().numpy().item())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    epochlist.append(e)   \n",
    "    losslist.append(epoch_loss/len(train_loader))\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "    \n",
    "passlist=list(range(0,len(parralel.alpha)))\n",
    "    \n",
    "#losslist.insert(0, losslist[0])\n",
    "\n",
    "      \n",
    "y_parmodelpred_list =[]\n",
    "parralel.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = parralel(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    \n",
    "parmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_parmodelpred_list[i]==y_test[i]:\n",
    "        parmodelcounter=parmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    \n",
    "    \n",
    "print(\"output weight: \", parralel.outputlayer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821e9828",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphs\n",
    "\n",
    "fig, (weights, lossgraph) = plt.subplots(2)\n",
    "weights.plot(passlist,parralel.alpha, label=\"Alpha\")\n",
    "weights.plot(passlist,parralel.beta, label=\"Beta\")\n",
    "weights.legend()\n",
    "\n",
    "weights.set_xlabel('Passes')\n",
    "weights.set_ylabel('Weights')\n",
    "weights.set_title('Alpa and Beta')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(epochlist,losslist, label=\"loss\")\n",
    "\n",
    "lossgraph.set_xlabel('Epochs')\n",
    "lossgraph.set_label('Loss')\n",
    "lossgraph.set_title('Loss')\n",
    "  \n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('e2triningrategraph3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a880e22f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained half stats:\n",
      "untained half model;\n",
      "Number correct full model:  360  out of  990\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.04      0.04      0.04       329\n",
      "         1.0       0.52      0.52      0.52       661\n",
      "\n",
      "    accuracy                           0.36       990\n",
      "   macro avg       0.28      0.28      0.28       990\n",
      "weighted avg       0.36      0.36      0.36       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#half model stats\n",
    "\n",
    "halfmodeltrained=binaryClassification()\n",
    "halfmodellow=binaryClassification()\n",
    "\n",
    "\n",
    "halfmodellow.layer_1 = copy.deepcopy(parralel.layer2_1)\n",
    "halfmodellow.layer_2 = copy.deepcopy(parralel.layer2_2)\n",
    "halfmodellow.layer_3 = copy.deepcopy(parralel.layer2_3)\n",
    "halfmodellow.layer_4 = copy.deepcopy(parralel.layer2_4)\n",
    "halfmodellow.layer_5 = copy.deepcopy(parralel.layer2_5)\n",
    "halfmodellow.layer_out = copy.deepcopy(parralel.layer2_out)\n",
    "\n",
    "\n",
    "\n",
    "halfmodellow.batchnorm1 = copy.deepcopy(parralel.batchnorm2_1)\n",
    "halfmodellow.batchnorm2 = copy.deepcopy(parralel.batchnorm2_2)\n",
    "halfmodellow.batchnorm3 = copy.deepcopy(parralel.batchnorm2_3)\n",
    "halfmodellow.batchnorm4 = copy.deepcopy(parralel.batchnorm2_4)\n",
    "halfmodellow.batchnorm5 = copy.deepcopy(parralel.batchnorm2_5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"untrained half stats:\")\n",
    "y_untrianedlist =[]\n",
    "y_untrained_unrounded=[]\n",
    "halfmodellow.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = halfmodellow(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_untrained_unrounded.append(y_test_pred.cpu().numpy())\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrianedlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_untrianedlist = [a.squeeze().tolist() for a in y_untrianedlist]\n",
    "y_untrained_unrounded = [a.squeeze().tolist() for a in y_untrained_unrounded]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_untrianedlist)):\n",
    "    if y_untrianedlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"untained half model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_untrianedlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        test.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "test = [a.squeeze().tolist() for a in test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8813daa2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histograms\n",
    "xbins=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]\n",
    "fig=plt.figure()\n",
    "#trained_histo=fig.add_subplot(2,1,1)\n",
    "untrained_histo=fig.add_subplot(2,1,2)\n",
    "#n, bins, patches = trained_histo.hist(y_pretrainedunrounded,xbins)\n",
    "n, bins, patches = untrained_histo.hist(y_untrained_unrounded,xbins)\n",
    "untrained_histo.set_title('Partial model predicitons, notpretrained')\n",
    "#trained_histo.set_title(\"Partial model predictions, pretrained\")\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.hist(y_pretrainedunrounded, bins\n",
    "#plt.hist(y_untrained_unrounded, bins=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9])\n",
    "\n",
    "\n",
    "plt.savefig('HIST_TRe1_N5_D10000_PARTIAL_NOBIAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f137a5bc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of training routines:0\n"
     ]
    }
   ],
   "source": [
    "#multiple routines\n",
    "val = input(\"Enter number of training routines:\")\n",
    "for k in range(int(val)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X=random.rand(1000, 5)\n",
    "\n",
    "    np.random.normal(0, 1, size=(1000, 10))\n",
    "\n",
    "\n",
    "    y=[]\n",
    "    for i in range(1000):\n",
    "        y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "    \n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data= trainData(torch.FloatTensor(X_train), \n",
    "                           torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "    #data loader initiation\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #train trained model\n",
    "    parralel.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            paroptimizer.zero_grad()\n",
    "\n",
    "            y_pred = parralel(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            paroptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_parmodelpred_list =[]\n",
    "    parralel.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = parralel(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    #print(y_parmodelpred_list)\n",
    "\n",
    "    parmodelcounter=0\n",
    "    for i in range(len(y_fullmodelpred_list)):\n",
    "        if y_parmodelpred_list[i]==y_test[i]:\n",
    "            parmodelcounter=parmodelcounter+1       \n",
    "    print(\"training routine #: \", k+1)\n",
    "    print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Full model statistics\")\n",
    "    print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    print(\"output weight: \", parralel.outputlayer.weight)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
