{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=random.rand(10000, 5)\n",
    "\n",
    "np.random.normal(0, 1, size=(10000, 10))\n",
    "\n",
    "\n",
    "y=[]\n",
    "for i in range(10000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, 5) \n",
    "        self.layer_2 = nn.Linear(5, 5) \n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4 = nn.Linear(5, 5)\n",
    "        self.layer_5 = nn.Linear(5, 5) \n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196afae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#parallel model (two 5 layer models, with output going into new output layer)\n",
    "class parallelmodel(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(parallelmodel, self).__init__()\n",
    "        self.layer1_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer1_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer1_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer1_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer1_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer1_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu1 = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout1 = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1_1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm1_2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm1_3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm1_4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm1_5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        #self.batchnorm1_out=nn.BatchNorm1d(1)\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        #self.batchnorm2_out=nn.BatchNorm1d()\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu1(self.layer1_1(inputs))\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu1(self.layer1_2(x))\n",
    "        x = self.batchnorm1_2(x)\n",
    "        x = self.relu1(self.layer1_3(x))\n",
    "        x = self.batchnorm1_3(x)\n",
    "        x = self.relu1(self.layer1_4(x))\n",
    "        x = self.batchnorm1_4(x)\n",
    "        x = self.relu1(self.layer1_5(x))\n",
    "        x = self.batchnorm1_5(x) \n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer1_out(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(inputs))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18de1eec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model that only does partial backprop\n",
    "class partialparralelmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(partialparralelmodel, self).__init__()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        y=inputs[:, :5]\n",
    "        x=inputs[:, 5:]\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(y))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd55f044",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 100 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "\n",
    "\n",
    "baddata=True\n",
    "while(baddata):\n",
    "\n",
    "    \n",
    "\n",
    "    GroundTruth.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in Truthloadertrain:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            truthoptimizer.zero_grad()\n",
    "\n",
    "            y_pred = GroundTruth(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            truthoptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "    Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_allscaled, y, test_size=0.33, random_state=69)\n",
    "    truthcounter=0\n",
    "    for i in y:\n",
    "        if i==1:\n",
    "            truthcounter=truthcounter+1\n",
    "    \n",
    "    \n",
    "    #print(truthcounter)\n",
    "    if truthcounter/len(y)<.8 and truthcounter/len(y)>.2:\n",
    "        baddata=False\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  3236  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      1487\n",
      "         1.0       0.98      0.98      0.98      1813\n",
      "\n",
      "    accuracy                           0.98      3300\n",
      "   macro avg       0.98      0.98      0.98      3300\n",
      "weighted avg       0.98      0.98      0.98      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "newinputvar=[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truthloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = trained(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = y_truth\n",
    "        newinputvar.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "newinputvar = [[a.squeeze().tolist() for a in newinputvar]]\n",
    "\n",
    "#print(newinputvar)\n",
    "X_allscaledextra=np.append(X_allscaled, np.array(newinputvar).reshape(len(y),1), axis=1)   \n",
    "\n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "    \n",
    "#format new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_allscaledextra, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####ORIGINAL LOADERS\n",
    "\n",
    "\n",
    "X_trainorig=X_train[:,:5]\n",
    "X_testorig=X_test[:,:5]\n",
    "test_dataorig = testData(torch.FloatTensor(X_testorig))\n",
    "\n",
    "test_loaderorig=DataLoader(dataset=test_dataorig)\n",
    "\n",
    "\n",
    "testifworks =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        testifworks.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "testifworks = [a.squeeze().tolist() for a in testifworks]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  3257  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      1487\n",
      "         1.0       0.99      0.99      0.99      1813\n",
      "\n",
      "    accuracy                           0.99      3300\n",
      "   macro avg       0.99      0.99      0.99      3300\n",
      "weighted avg       0.99      0.99      0.99      3300\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[12.3670,  6.9522]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#train partial parralel model\n",
    "parralel = partialparralelmodel()\n",
    "parralel.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "parralel.outputlayer.weight=torch.nn.Parameter(data=torch.tensor([[.7,0.3]]), requires_grad=True)\n",
    "parralel.alpha.append(.7)\n",
    "parralel.beta.append(.3)\n",
    "epochlist=[]\n",
    "losslist=[]\n",
    "\n",
    "paroptimizer = optim.Adam(parralel.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "#EPOCHS = 300 #number of passes of whole data\n",
    "#BATCH_SIZE = 16 #size of data going through at once\n",
    "\n",
    "\n",
    "\n",
    "#train trained model\n",
    "parralel.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        paroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = parralel(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        paroptimizer.step()\n",
    "        \n",
    "        parralel.alpha.append(parralel.outputlayer.weight[0][0].detach().numpy().item())\n",
    "        parralel.beta.append(parralel.outputlayer.weight[0][1].detach().numpy().item())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    epochlist.append(e)   \n",
    "    losslist.append(epoch_loss/len(train_loader))\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "    \n",
    "passlist=list(range(0,len(parralel.alpha)))\n",
    "    \n",
    "#losslist.insert(0, losslist[0])\n",
    "\n",
    "      \n",
    "y_parmodelpred_list =[]\n",
    "parralel.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = parralel(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    \n",
    "parmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_parmodelpred_list[i]==y_test[i]:\n",
    "        parmodelcounter=parmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    \n",
    "    \n",
    "print(\"output weight: \", parralel.outputlayer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821e9828",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphs\n",
    "\n",
    "fig, (weights, lossgraph) = plt.subplots(2)\n",
    "weights.plot(passlist,parralel.alpha, label=\"Alpha\")\n",
    "weights.plot(passlist,parralel.beta, label=\"Beta\")\n",
    "weights.legend()\n",
    "\n",
    "weights.set_xlabel('Passes')\n",
    "weights.set_ylabel('Weights')\n",
    "weights.set_title('Alpa and Beta')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(epochlist,losslist, label=\"loss\")\n",
    "\n",
    "lossgraph.set_xlabel('Epochs')\n",
    "lossgraph.set_label('Loss')\n",
    "lossgraph.set_title('Loss')\n",
    "  \n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('e2triningrategraph3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a880e22f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained half stats:\n",
      "untained half model;\n",
      "Number correct full model:  1813  out of  3300\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      1487\n",
      "         1.0       0.55      1.00      0.71      1813\n",
      "\n",
      "    accuracy                           0.55      3300\n",
      "   macro avg       0.27      0.50      0.35      3300\n",
      "weighted avg       0.30      0.55      0.39      3300\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#half model stats\n",
    "\n",
    "halfmodeltrained=binaryClassification()\n",
    "halfmodellow=binaryClassification()\n",
    "\n",
    "\n",
    "halfmodellow.layer_1 = copy.deepcopy(parralel.layer2_1)\n",
    "halfmodellow.layer_2 = copy.deepcopy(parralel.layer2_2)\n",
    "halfmodellow.layer_3 = copy.deepcopy(parralel.layer2_3)\n",
    "halfmodellow.layer_4 = copy.deepcopy(parralel.layer2_4)\n",
    "halfmodellow.layer_5 = copy.deepcopy(parralel.layer2_5)\n",
    "halfmodellow.layer_out = copy.deepcopy(parralel.layer2_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"untrained half stats:\")\n",
    "y_untrianedlist =[]\n",
    "halfmodellow.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = halfmodellow(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrianedlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_untrianedlist = [a.squeeze().tolist() for a in y_untrianedlist]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_untrianedlist)):\n",
    "    if y_untrianedlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"untained half model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_untrianedlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        test.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "test = [a.squeeze().tolist() for a in test]\n",
    "\n",
    "print(test==testifworks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f137a5bc",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of training routines:2\n",
      "training routine #:  1\n",
      "# correct:  168  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.31      0.38       157\n",
      "         1.0       0.52      0.69      0.59       173\n",
      "\n",
      "    accuracy                           0.51       330\n",
      "   macro avg       0.50      0.50      0.49       330\n",
      "weighted avg       0.50      0.51      0.49       330\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[0.9721, 0.6614]], requires_grad=True)\n",
      "training routine #:  2\n",
      "# correct:  155  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.27      0.33       157\n",
      "         1.0       0.50      0.65      0.56       173\n",
      "\n",
      "    accuracy                           0.47       330\n",
      "   macro avg       0.45      0.46      0.45       330\n",
      "weighted avg       0.46      0.47      0.45       330\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[0.9296, 0.6703]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#multiple routines\n",
    "val = input(\"Enter number of training routines:\")\n",
    "for k in range(int(val)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X=random.rand(1000, 5)\n",
    "\n",
    "    np.random.normal(0, 1, size=(1000, 10))\n",
    "\n",
    "\n",
    "    y=[]\n",
    "    for i in range(1000):\n",
    "        y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "    \n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data= trainData(torch.FloatTensor(X_train), \n",
    "                           torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "    #data loader initiation\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #train trained model\n",
    "    parralel.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            paroptimizer.zero_grad()\n",
    "\n",
    "            y_pred = parralel(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            paroptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_parmodelpred_list =[]\n",
    "    parralel.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = parralel(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    #print(y_parmodelpred_list)\n",
    "\n",
    "    parmodelcounter=0\n",
    "    for i in range(len(y_fullmodelpred_list)):\n",
    "        if y_parmodelpred_list[i]==y_test[i]:\n",
    "            parmodelcounter=parmodelcounter+1       \n",
    "    print(\"training routine #: \", k+1)\n",
    "    print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Full model statistics\")\n",
    "    print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    print(\"output weight: \", parralel.outputlayer.weight)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
