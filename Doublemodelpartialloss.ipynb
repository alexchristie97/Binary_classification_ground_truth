{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, weight definitions, data classes, rounding function\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=random.rand(10000, 5)\n",
    "\n",
    "np.random.normal(0, 1, size=(10000, 10))\n",
    "\n",
    "\n",
    "y=[]\n",
    "for i in range(10000):\n",
    "    y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554690d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, 5) \n",
    "        self.layer_2 = nn.Linear(5, 5) \n",
    "        self.layer_3 = nn.Linear(5, 5)\n",
    "        self.layer_4 = nn.Linear(5, 5)\n",
    "        self.layer_5 = nn.Linear(5, 5) \n",
    "        self.layer_out = nn.Linear(5, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e196afae",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#parallel model (two 5 layer models, with output going into new output layer)\n",
    "class parallelmodel(nn.Module):\n",
    "    def __init__(self, originalmodel):\n",
    "        super(parallelmodel, self).__init__()\n",
    "        self.layer1_1 = copy.deepcopy(originalmodel.layer_1)\n",
    "        self.layer1_2 = copy.deepcopy(originalmodel.layer_2)\n",
    "        self.layer1_3 = copy.deepcopy(originalmodel.layer_3)\n",
    "        self.layer1_4 = copy.deepcopy(originalmodel.layer_4)\n",
    "        self.layer1_5 = copy.deepcopy(originalmodel.layer_5)\n",
    "        self.layer1_out = copy.deepcopy(originalmodel.layer_out)\n",
    "        \n",
    "        self.relu1 = copy.deepcopy(originalmodel.relu)        \n",
    "        self.dropout1 = copy.deepcopy(originalmodel.dropout)\n",
    "        \n",
    "        self.batchnorm1_1 = copy.deepcopy(originalmodel.batchnorm1)\n",
    "        self.batchnorm1_2 = copy.deepcopy(originalmodel.batchnorm2)\n",
    "        self.batchnorm1_3 = copy.deepcopy(originalmodel.batchnorm3)\n",
    "        self.batchnorm1_4 = copy.deepcopy(originalmodel.batchnorm4)\n",
    "        self.batchnorm1_5 = copy.deepcopy(originalmodel.batchnorm5)\n",
    "        #self.batchnorm1_out=nn.BatchNorm1d(1)\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        #self.batchnorm2_out=nn.BatchNorm1d()\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1, bias=False)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu1(self.layer1_1(inputs))\n",
    "        x = self.batchnorm1_1(x)\n",
    "        x = self.relu1(self.layer1_2(x))\n",
    "        x = self.batchnorm1_2(x)\n",
    "        x = self.relu1(self.layer1_3(x))\n",
    "        x = self.batchnorm1_3(x)\n",
    "        x = self.relu1(self.layer1_4(x))\n",
    "        x = self.batchnorm1_4(x)\n",
    "        x = self.relu1(self.layer1_5(x))\n",
    "        x = self.batchnorm1_5(x) \n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer1_out(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(inputs))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18de1eec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#model that only does partial backprop\n",
    "class partialparralelmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(partialparralelmodel, self).__init__()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        self.batchnorm2_1 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_2 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_3 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_4 = nn.BatchNorm1d(5)\n",
    "        self.batchnorm2_5 = nn.BatchNorm1d(5)\n",
    "        \n",
    "        self.layer2_1 = nn.Linear(5, 5) \n",
    "        self.layer2_2 = nn.Linear(5, 5) \n",
    "        self.layer2_3 = nn.Linear(5, 5)\n",
    "        self.layer2_4 = nn.Linear(5, 5)\n",
    "        self.layer2_5 = nn.Linear(5, 5) \n",
    "        self.layer2_out = nn.Linear(5, 1) \n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.outputlayer= nn.Linear(2, 1)\n",
    "        self.alpha=[]\n",
    "        self.beta=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \n",
    "        y=inputs[:, :5]\n",
    "        x=inputs[:, 5:]\n",
    "        \n",
    "        \n",
    "        y = self.relu2(self.layer2_1(y))\n",
    "        y = self.batchnorm2_1(y)\n",
    "        y = self.relu2(self.layer2_2(y))\n",
    "        y = self.batchnorm2_2(y)\n",
    "        y = self.relu2(self.layer2_3(y))\n",
    "        y = self.batchnorm2_3(y)\n",
    "        y = self.relu2(self.layer2_4(y))\n",
    "        y = self.batchnorm2_4(y)\n",
    "        y = self.relu2(self.layer2_5(y))\n",
    "        y = self.batchnorm2_5(y)        \n",
    "        y = self.dropout2(y)\n",
    "        y = self.layer2_out(y)\n",
    "        y=torch.sigmoid(y)\n",
    "        \n",
    "        z=self.outputlayer(torch.cat([x, y], dim=1))\n",
    "        return z\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd55f044",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#groundtruth model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = StandardScaler()\n",
    "X_allscaled = scaler.fit_transform(X) #scales data\n",
    "X_formatted = testData(torch.FloatTensor(X_allscaled))\n",
    "EPOCHS = 100 #number of passes of whole data\n",
    "BATCH_SIZE = 64 #size of data going through at once\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Truthtrain=trainData(torch.FloatTensor(X_allscaled), \n",
    "                       torch.FloatTensor(y))\n",
    "\n",
    "\n",
    "Truthloadertrain= DataLoader(dataset=Truthtrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "GroundTruth = binaryClassification()\n",
    "\n",
    "\n",
    "GroundTruth.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "truthoptimizer = optim.Adam(GroundTruth.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#print(list(model.parameters())[0])\n",
    "\n",
    "\n",
    "\n",
    "baddata=True\n",
    "while(baddata):\n",
    "\n",
    "    \n",
    "\n",
    "    GroundTruth.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in Truthloadertrain:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            truthoptimizer.zero_grad()\n",
    "\n",
    "            y_pred = GroundTruth(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            truthoptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Truthtest = testData(torch.FloatTensor(X_allscaled))\n",
    "    Truthloader = DataLoader(dataset=Truthtest, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_allscaled, y, test_size=0.33, random_state=69)\n",
    "    truthcounter=0\n",
    "    for i in y:\n",
    "        if i==1:\n",
    "            truthcounter=truthcounter+1\n",
    "    \n",
    "    \n",
    "    #print(truthcounter)\n",
    "    if truthcounter/len(y)<.8 and truthcounter/len(y)>.2:\n",
    "        baddata=False\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data= trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b14074",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  3104  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.96      0.93      1392\n",
      "         1.0       0.97      0.92      0.95      1908\n",
      "\n",
      "    accuracy                           0.94      3300\n",
      "   macro avg       0.94      0.94      0.94      3300\n",
      "weighted avg       0.94      0.94      0.94      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train first model\n",
    "trained = binaryClassification()\n",
    "trained.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(trained.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "trained.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = trained(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "y_fullmodelpred_list =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_fullmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_fullmodelpred_list = [a.squeeze().tolist() for a in y_fullmodelpred_list]\n",
    "\n",
    "\n",
    "newinputvar=[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in Truthloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_truth = trained(X_batch)\n",
    "        y_truth = torch.sigmoid(y_truth)\n",
    "        y_truthtag = y_truth\n",
    "        newinputvar.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "newinputvar = [[a.squeeze().tolist() for a in newinputvar]]\n",
    "\n",
    "#print(newinputvar)\n",
    "X_allscaledextra=np.append(X_allscaled, np.array(newinputvar).reshape(len(y),1), axis=1)   \n",
    "\n",
    "fullmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_fullmodelpred_list[i]==y_test[i]:\n",
    "        fullmodelcounter=fullmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",fullmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_fullmodelpred_list))    \n",
    "    \n",
    "    \n",
    "    \n",
    "#format new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_allscaledextra, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "#data loader initiation\n",
    "train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####ORIGINAL LOADERS\n",
    "\n",
    "\n",
    "X_trainorig=X_train[:,:5]\n",
    "X_testorig=X_test[:,:5]\n",
    "test_dataorig = testData(torch.FloatTensor(X_testorig))\n",
    "\n",
    "test_loaderorig=DataLoader(dataset=test_dataorig)\n",
    "\n",
    "\n",
    "testifworks =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        testifworks.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "testifworks = [a.squeeze().tolist() for a in testifworks]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a742d7a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# correct:  3205  out of  3300\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      1392\n",
      "         1.0       0.98      0.97      0.98      1908\n",
      "\n",
      "    accuracy                           0.97      3300\n",
      "   macro avg       0.97      0.97      0.97      3300\n",
      "weighted avg       0.97      0.97      0.97      3300\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[11.0876, -7.2322]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#train partial parralel model\n",
    "parralel = partialparralelmodel()\n",
    "parralel.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "parralel.outputlayer.weight=torch.nn.Parameter(data=torch.tensor([[.9,0.05]]), requires_grad=True)\n",
    "parralel.alpha.append(.9)\n",
    "parralel.beta.append(0.05)\n",
    "epochlist=[]\n",
    "losslist=[]\n",
    "\n",
    "paroptimizer = optim.Adam(parralel.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n",
    "#EPOCHS = 300 #number of passes of whole data\n",
    "#BATCH_SIZE = 16 #size of data going through at once\n",
    "\n",
    "\n",
    "\n",
    "#train trained model\n",
    "parralel.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        paroptimizer.zero_grad()\n",
    "        \n",
    "        y_pred = parralel(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        paroptimizer.step()\n",
    "        \n",
    "        parralel.alpha.append(parralel.outputlayer.weight[0][0].detach().numpy().item())\n",
    "        parralel.beta.append(parralel.outputlayer.weight[0][1].detach().numpy().item())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    epochlist.append(e)   \n",
    "    losslist.append(epoch_loss/len(train_loader))\n",
    "    #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "    \n",
    "passlist=list(range(0,len(parralel.alpha)))\n",
    "    \n",
    "#losslist.insert(0, losslist[0])\n",
    "\n",
    "      \n",
    "y_parmodelpred_list =[]\n",
    "parralel.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = parralel(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    \n",
    "parmodelcounter=0\n",
    "for i in range(len(y_fullmodelpred_list)):\n",
    "    if y_parmodelpred_list[i]==y_test[i]:\n",
    "        parmodelcounter=parmodelcounter+1       \n",
    "\n",
    "print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "        \n",
    "print(\"Full model statistics\")\n",
    "print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    \n",
    "    \n",
    "print(\"output weight: \", parralel.outputlayer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821e9828",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphs\n",
    "\n",
    "fig, (weights, lossgraph) = plt.subplots(2)\n",
    "weights.plot(passlist,parralel.alpha, label=\"Alpha\")\n",
    "weights.plot(passlist,parralel.beta, label=\"Beta\")\n",
    "weights.legend()\n",
    "\n",
    "weights.set_xlabel('Passes')\n",
    "weights.set_ylabel('Weights')\n",
    "weights.set_title('Alpa and Beta')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(epochlist,losslist, label=\"loss\")\n",
    "\n",
    "lossgraph.set_xlabel('Epochs')\n",
    "lossgraph.set_label('Loss')\n",
    "lossgraph.set_title('Loss')\n",
    "  \n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('e2triningrategraph3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a880e22f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrained half stats:\n",
      "untained half model;\n",
      "Number correct full model:  1392  out of  3300\n",
      "precision=(# of correct)/(# of guessed)\n",
      "recall=(# of correct)/(total)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      1.00      0.59      1392\n",
      "         1.0       0.00      0.00      0.00      1908\n",
      "\n",
      "    accuracy                           0.42      3300\n",
      "   macro avg       0.21      0.50      0.30      3300\n",
      "weighted avg       0.18      0.42      0.25      3300\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#half model stats\n",
    "\n",
    "halfmodeltrained=binaryClassification()\n",
    "halfmodellow=binaryClassification()\n",
    "\n",
    "\n",
    "halfmodellow.layer_1 = copy.deepcopy(parralel.layer2_1)\n",
    "halfmodellow.layer_2 = copy.deepcopy(parralel.layer2_2)\n",
    "halfmodellow.layer_3 = copy.deepcopy(parralel.layer2_3)\n",
    "halfmodellow.layer_4 = copy.deepcopy(parralel.layer2_4)\n",
    "halfmodellow.layer_5 = copy.deepcopy(parralel.layer2_5)\n",
    "halfmodellow.layer_out = copy.deepcopy(parralel.layer2_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"untrained half stats:\")\n",
    "y_untrianedlist =[]\n",
    "y_untrained_unrounded=[]\n",
    "halfmodellow.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = halfmodellow(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_untrained_unrounded.append(y_test_pred.cpu().numpy())\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_untrianedlist.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "y_untrianedlist = [a.squeeze().tolist() for a in y_untrianedlist]\n",
    "y_untrained_unrounded = [a.squeeze().tolist() for a in y_untrained_unrounded]\n",
    "\n",
    "\n",
    "\n",
    "correctcounter=0\n",
    "for i in range(len(y_untrianedlist)):\n",
    "    if y_untrianedlist[i]==y_test[i]:\n",
    "        correctcounter=correctcounter+1 \n",
    "        \n",
    "        \n",
    "print(\"untained half model;\")\n",
    "print(\"Number correct full model: \", correctcounter, \" out of \", len(y_test))\n",
    "print(\"precision=(# of correct)/(# of guessed)\")\n",
    "print(\"recall=(# of correct)/(total)\")\n",
    "print(classification_report(y_test, y_untrianedlist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test =[]\n",
    "trained.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loaderorig:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = trained(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        test.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "test = [a.squeeze().tolist() for a in test]\n",
    "\n",
    "print(test==testifworks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec2dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histograms\n",
    "xbins=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]\n",
    "fig=plt.figure()\n",
    "#trained_histo=fig.add_subplot(2,1,1)\n",
    "untrained_histo=fig.add_subplot(2,1,2)\n",
    "#n, bins, patches = trained_histo.hist(y_pretrainedunrounded,xbins)\n",
    "n, bins, patches = untrained_histo.hist(y_untrained_unrounded,xbins)\n",
    "untrained_histo.set_title('Partial model predicitons, notpretrained')\n",
    "#trained_histo.set_title(\"Partial model predictions, pretrained\")\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.hist(y_pretrainedunrounded, bins\n",
    "#plt.hist(y_untrained_unrounded, bins=[0,.1,.2,.3,.4,.5,.6,.7,.8,.9])\n",
    "\n",
    "\n",
    "plt.savefig('HIST_TRe1_N5_D10000_PARTIAL_NOBIAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f137a5bc",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of training routines:2\n",
      "training routine #:  1\n",
      "# correct:  168  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.31      0.38       157\n",
      "         1.0       0.52      0.69      0.59       173\n",
      "\n",
      "    accuracy                           0.51       330\n",
      "   macro avg       0.50      0.50      0.49       330\n",
      "weighted avg       0.50      0.51      0.49       330\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[0.9721, 0.6614]], requires_grad=True)\n",
      "training routine #:  2\n",
      "# correct:  155  out of  330\n",
      "Full model statistics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.27      0.33       157\n",
      "         1.0       0.50      0.65      0.56       173\n",
      "\n",
      "    accuracy                           0.47       330\n",
      "   macro avg       0.45      0.46      0.45       330\n",
      "weighted avg       0.46      0.47      0.45       330\n",
      "\n",
      "output weight:  Parameter containing:\n",
      "tensor([[0.9296, 0.6703]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#multiple routines\n",
    "val = input(\"Enter number of training routines:\")\n",
    "for k in range(int(val)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X=random.rand(1000, 5)\n",
    "\n",
    "    np.random.normal(0, 1, size=(1000, 10))\n",
    "\n",
    "\n",
    "    y=[]\n",
    "    for i in range(1000):\n",
    "        y.append(random.binomial(1, 0.5, size=None))\n",
    "\n",
    "    \n",
    "    truth_list = []\n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in Truthloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_truth = GroundTruth(X_batch)\n",
    "            y_truth = torch.sigmoid(y_truth)\n",
    "            y_truthtag = torch.round(y_truth)\n",
    "            truth_list.append(y_truthtag.cpu().numpy())\n",
    "\n",
    "    y = [a.squeeze().tolist() for a in truth_list] #new truth values\n",
    "    #split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data= trainData(torch.FloatTensor(X_train), \n",
    "                           torch.FloatTensor(y_train))\n",
    "\n",
    "\n",
    "\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "\n",
    "    #data loader initiation\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #train trained model\n",
    "    parralel.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            paroptimizer.zero_grad()\n",
    "\n",
    "            y_pred = parralel(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            paroptimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_parmodelpred_list =[]\n",
    "    parralel.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = parralel(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_parmodelpred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_parmodelpred_list = [a.squeeze().tolist() for a in y_parmodelpred_list]\n",
    "\n",
    "\n",
    "    #print(y_parmodelpred_list)\n",
    "\n",
    "    parmodelcounter=0\n",
    "    for i in range(len(y_fullmodelpred_list)):\n",
    "        if y_parmodelpred_list[i]==y_test[i]:\n",
    "            parmodelcounter=parmodelcounter+1       \n",
    "    print(\"training routine #: \", k+1)\n",
    "    print(\"# correct: \",parmodelcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Full model statistics\")\n",
    "    print(classification_report(y_test, y_parmodelpred_list))    \n",
    "    print(\"output weight: \", parralel.outputlayer.weight)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
