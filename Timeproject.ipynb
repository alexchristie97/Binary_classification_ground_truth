{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0,
     45,
     64,
     83,
     95,
     107,
     116,
     159,
     215,
     245,
     310,
     329,
     341,
     368,
     395,
     529,
     597
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "    \n",
    "THRESH_HOLD=5e-6            #MSE value when we consider the second model to have \"cracked\" the first\n",
    "EPOCHS = 25                 #number of passes of whole data\n",
    "BATCH_SIZE = 64             #size of data going through at once\n",
    "LEARNING_RATE = 0.01       #how much we shift parameters during back prop\n",
    "NEURONS=5                   #number of nodes in each layer\n",
    "XSIZE=1056                  #size of each data set generated\n",
    "BADLOSSPASSES=1000          #number of times we have small loss until we stop code\n",
    "TESTMODULE_LAYERS=10        #number of layers in cracking module\n",
    "GROUND_TRUTH_LAYERS=5       #number of layers in ground thruth models\n",
    "\n",
    "    \n",
    "    \n",
    "def get_Xvals():\n",
    "    return (np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def getdata_XY():\n",
    "    X=(np.random.uniform( size=(XSIZE, 5))-0.5)*np.sqrt(12)\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "def binary_acc(y_pred, y_test): \n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def trainnetwork(network, train_loader,Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #X_batch = X_batch.astype(np.float32)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            y_pred = torch.sigmoid(network(X_batch))\n",
    "            #y_pred = network(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            #print(\"batch loss: \", loss.item()) \n",
    "\n",
    "        #print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')\n",
    "        #rint(\"Ave Loss: \", epoch_loss)\n",
    "        #rint(\"size \", len(train_loader))\n",
    "        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "\n",
    "\n",
    "def get_new_GroundTruth(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    \n",
    "    layer1_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer1_weight=layer1_weight+i.layer_1.weight/(len(better_model_list))\n",
    "        \n",
    "    layer1_weight.requires_grad_()\n",
    "    newGroundTruth.layer_1.weight=torch.nn.Parameter(layer1_weight)\n",
    "\n",
    "    layer2_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer2_weight=layer2_weight+i.layer_2.weight/(len(better_model_list))\n",
    "        \n",
    "    layer2_weight.requires_grad_()\n",
    "    newGroundTruth.layer_2.weight=torch.nn.Parameter(layer2_weight)\n",
    "    \n",
    "    \n",
    "    layer3_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer3_weight=layer3_weight+i.layer_3.weight/(len(better_model_list))\n",
    "        \n",
    "    layer3_weight.requires_grad_()\n",
    "    newGroundTruth.layer_3.weight=torch.nn.Parameter(layer3_weight)\n",
    "    \n",
    "    layer4_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer4_weight=layer4_weight+i.layer_4.weight/(len(better_model_list))\n",
    "        \n",
    "    layer4_weight.requires_grad_()\n",
    "    newGroundTruth.layer_4.weight=torch.nn.Parameter(layer4_weight)\n",
    "    \n",
    "    layer5_weight=torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer5_weight=layer5_weight+i.layer_5.weight/(len(better_model_list))\n",
    "        \n",
    "    layer5_weight.requires_grad_()\n",
    "    newGroundTruth.layer_5.weight=torch.nn.Parameter(layer5_weight)\n",
    "    \n",
    "                \n",
    "    layeroutput_weight=torch.tensor([[0,0,0,0,0]],requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layeroutput_weight=layeroutput_weight+i.layer_out.weight/(len(better_model_list))\n",
    "        \n",
    "    layeroutput_weight.requires_grad_()\n",
    "    newGroundTruth.layer_out.weight=torch.nn.Parameter(layeroutput_weight)\n",
    "    \n",
    "    return newGroundTruth\n",
    "        \n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    total_lossconfirm=0\n",
    "    #criterion = nn.MSELoss()\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            #loss = criterion(y_pred_tag, torch.tensor([y]))\n",
    "\n",
    "            \n",
    "            #print(\"y \", y)\n",
    "            #print(\"pred \", y_pred_tag.cpu().numpy())\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "            #total_lossconfirm=total_lossconfirm+loss.item()\n",
    "    \n",
    "    #total_loss=np.sqrt(total_loss)/len(truth)\n",
    "    total_loss=total_loss/len(truth)\n",
    "    total_lossconfirm=total_lossconfirm/len(truth)\n",
    "    #print(\"current loss: \", total_loss)\n",
    "    #print(\"current confirm loss: \", total_lossconfirm)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True, total_loss[0][0]\n",
    "    else:\n",
    "        return False, total_loss[0][0]\n",
    "        \n",
    "        \n",
    "def evalnetwork(network, test_loader, stats=True):\n",
    "    y_pred_list =[]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            y_test_pred = network(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            #y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    if(stats):\n",
    "        statistics(y_pred_list)\n",
    "    return y_pred_list\n",
    "\n",
    "def statistics(y_pred_list):\n",
    "    correctcounter=0\n",
    "    for i in range(len(y_pred_list)):\n",
    "        if y_pred_list[i]==y_test[i]:\n",
    "            correctcounter=correctcounter+1       \n",
    "\n",
    "    print(\"# correct: \",correctcounter, \" out of \", len(y_test))\n",
    "\n",
    "    print(\"Model statistics\")\n",
    "    print(classification_report(y_test, y_pred_list))    \n",
    "    \n",
    "#model class 5 layers, then an output layer\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(5, NEURONS) \n",
    "        self.layer_2 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_3 = nn.Linear(NEURONS, NEURONS)\n",
    "        self.layer_4 = nn.Linear(NEURONS,NEURONS)\n",
    "        self.layer_5 = nn.Linear(NEURONS, NEURONS) \n",
    "        self.layer_out = nn.Linear(NEURONS, 1) #output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(NEURONS)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.layer_4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.layer_5(x))\n",
    "        x = self.batchnorm5(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "     \n",
    "    def get_copy(self):\n",
    "        copied_model=binaryClassification()\n",
    "        copied_model.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        copied_model.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        copied_model.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        copied_model.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        copied_model.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        copied_model.layer_out = copy.deepcopy(self.layer_out)\n",
    "        copied_model.batchnorm1=copy.deepcopy(self.batchnorm1)\n",
    "        copied_model.batchnorm2=copy.deepcopy(self.batchnorm2)\n",
    "        copied_model.batchnorm3=copy.deepcopy(self.batchnorm3)\n",
    "        copied_model.batchnorm4=copy.deepcopy(self.batchnorm4)\n",
    "        copied_model.batchnorm5=copy.deepcopy(self.batchnorm5)\n",
    "\n",
    "        \n",
    "          \n",
    "        return copied_model\n",
    "  \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=np.random.normal(0, 1, size=5)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_out.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_out.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class arbitraryLayerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(arbitraryLayerModel, self).__init__()\n",
    "        self.layer_input=nn.Linear(5, NEURONS)\n",
    "        self.layers=nn.ModuleList([nn.Linear(NEURONS, NEURONS) for i in range(TESTMODULE_LAYERS)])\n",
    "        self.batchnorms=nn.ModuleList([nn.BatchNorm1d(NEURONS) for i in range(TESTMODULE_LAYERS)])\n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def get_copy(self):\n",
    "        copied_model=arbitraryLayerModel()\n",
    "        copied_model.layers=nn.ModuleList()\n",
    "        for i in self.layers:\n",
    "            copied_model.layers.append(copy.deepcopy(i))\n",
    "            \n",
    "        copied_model.batchnorms=nn.ModuleList()\n",
    "        for i in self.batchnorms:\n",
    "            copied_model.batchnorms.append(copy.deepcopy(i))\n",
    "        copied_model.layer_input=copy.deepcopy(self.layer_input)\n",
    "        copied_model.layer_output=copy.deepcopy(self.layer_output)\n",
    "\n",
    "        return copied_model\n",
    "            \n",
    "     \n",
    "    def forward(self, inputs):\n",
    "        x=self.relu(self.layer_input(inputs))\n",
    "        for (layer, batchnorm) in zip(self.layers, self.batchnorms):\n",
    "            x=batchnorm(x)\n",
    "            x=self.relu(layer(x))\n",
    "            x=self.dropout(x)\n",
    "        x=self.layer_output(x)\n",
    "        return(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=self.get_copy()\n",
    "        \n",
    "        weightchange=np.random.normal(0,1)\n",
    "        weightchange=[weightchange.item()]\n",
    "        zeros=[[0]]*(NEURONS-1)\n",
    "        if node[0]==0:\n",
    "            zeros.insert(weightchange, node[1])\n",
    "            newweight=self.layer_input.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_input.weight=torch.nn.Parameter(newweight)    \n",
    "            return changed_node\n",
    "            \n",
    "            \n",
    "        weightchange=np.random.normal(0, 1, size=NEURONS)\n",
    "        weightchange=[i.item() for i in weightchange]\n",
    "        zeros = [[0.0]*NEURONS]*(NEURONS-1)\n",
    "        \n",
    "        if node[0]==TESTMODULE_LAYERS+1:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight) \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            for layer, i in enumerate(changed_node.layers):\n",
    "                if i==node[0]+1:\n",
    "                    zeros.insert(weightchange,node[1])\n",
    "                    newweight=layer.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "                    newweight.requires_grad_()\n",
    "                    layer.weight=torch.nn.Parameter(newweight)\n",
    "                    \n",
    "        \n",
    "\n",
    "        return changed_node\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def select_node():\n",
    "    layer=randrange(5)\n",
    "    if layer!=6:\n",
    "        node=randrange(5)\n",
    "    else:\n",
    "        node=randrange(2)\n",
    "    return [layer, node]\n",
    "    \n",
    "def change_node_modellinear(self, node):\n",
    "        changed_node=binaryClassification()\n",
    "        changed_node.layer_1 = copy.deepcopy(self.layer_1)\n",
    "        changed_node.layer_2 = copy.deepcopy(self.layer_2) \n",
    "        changed_node.layer_3 = copy.deepcopy(self.layer_3)\n",
    "        changed_node.layer_4 = copy.deepcopy(self.layer_4)\n",
    "        changed_node.layer_5 = copy.deepcopy(self.layer_5)\n",
    "        changed_node.layer_out = copy.deepcopy(self.layer_out) \n",
    "        \n",
    "        weightchange=[1.0]*5\n",
    "\n",
    "        if node[0]==0:\n",
    "            self.layer_1.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_1.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_1.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_1.weight=torch.nn.Parameter(newweight)\n",
    "\n",
    "        elif node[0]==1:\n",
    "            self.layer_2.weight.requires_grad_(False)\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_2.weight+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_2.weight+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_2.weight=torch.nn.Parameter(newweight)\n",
    "   \n",
    "        elif node[0]==2:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_3.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_3.weight=torch.nn.Parameter(newweight)\n",
    "                               \n",
    "        elif node[0]==3:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_4.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_4.weight=torch.nn.Parameter(newweight)\n",
    "             \n",
    "        elif node[0]==4:\n",
    "            if node[1]==0:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)\n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==1:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)  \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==2:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0],[0,0,0,0,0]],requires_grad=False)          \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==3:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange,[0,0,0,0,0]],requires_grad=False)       \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "            if node[1]==4:\n",
    "                newweight=self.layer_5.weight.requires_grad_(False)+torch.tensor([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],weightchange],requires_grad=False)           \n",
    "                newweight.requires_grad_()\n",
    "                changed_node.layer_5.weight=torch.nn.Parameter(newweight)\n",
    "     \n",
    "        else:\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor([weightchange],requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight)\n",
    "                \n",
    "                \n",
    "        return changed_node\n",
    "                   \n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e346b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time:  2.2322065830230713\n",
      "Iteration 1: | Previous time: 2.232 | Best new time: 2.386 | Difference: 0.154\n",
      "Iteration 2: | Previous time: 2.386 | Best new time: 2.238 | Difference: -0.148\n",
      "Number no loss change 6: | Current time: 59.735 | Loss difference: 2.473e-07 | Loss: 2.3701577447354794e-05\n",
      "Number no loss change 7: | Current time: 68.482 | Loss difference: 6.398e-07 | Loss: 2.1978705262881704e-05\n",
      "Number no loss change 8: | Current time: 81.668 | Loss difference: 1.84e-07 | Loss: 2.1847841708222404e-05\n",
      "Number no loss change 9: | Current time: 121.256 | Loss difference: 2.37e-07 | Loss: 2.527827200538013e-05\n",
      "Number no loss change 10: | Current time: 127.863 | Loss difference: 6.16e-07 | Loss: 2.4285931431222707e-05\n",
      "Number no loss change 11: | Current time: 148.083 | Loss difference: 1.496e-07 | Loss: 2.52058725891402e-05\n",
      "Number no loss change 12: | Current time: 150.276 | Loss difference: 1.375e-07 | Loss: 2.534334453230258e-05\n",
      "Number no loss change 13: | Current time: 156.946 | Loss difference: 2.276e-07 | Loss: 2.295511876582168e-05\n",
      "Number no loss change 14: | Current time: 159.083 | Loss difference: 2.081e-07 | Loss: 2.274698272231035e-05\n",
      "Number no loss change 15: | Current time: 161.278 | Loss difference: 8.184e-07 | Loss: 2.3565426090499386e-05\n",
      "Number no loss change 16: | Current time: 172.759 | Loss difference: 4.278e-07 | Loss: 2.8198624931974337e-05\n",
      "Number no loss change 17: | Current time: 183.927 | Loss difference: 5.51e-07 | Loss: 2.4411423510173336e-05\n",
      "Number no loss change 18: | Current time: 186.145 | Loss difference: 1.121e-07 | Loss: 2.4523558749933727e-05\n",
      "Number no loss change 19: | Current time: 195.000 | Loss difference: 8.301e-07 | Loss: 2.237106855318416e-05\n",
      "Number no loss change 20: | Current time: 219.176 | Loss difference: 9.314e-07 | Loss: 1.9452296328381635e-05\n",
      "Number no loss change 21: | Current time: 250.320 | Loss difference: 7.247e-07 | Loss: 2.7126479835715145e-05\n",
      "Number no loss change 22: | Current time: 263.631 | Loss difference: 9.872e-07 | Loss: 2.3529217287432402e-05\n",
      "Number no loss change 23: | Current time: 279.139 | Loss difference: 6.359e-07 | Loss: 2.161113116017077e-05\n",
      "Number no loss change 24: | Current time: 283.544 | Loss difference: 7.655e-07 | Loss: 2.4549017325625755e-05\n",
      "Number no loss change 25: | Current time: 287.963 | Loss difference: 6.437e-07 | Loss: 2.564455098763574e-05\n",
      "Number no loss change 26: | Current time: 294.607 | Loss difference: 8.939e-07 | Loss: 2.4722870875848457e-05\n",
      "Number no loss change 27: | Current time: 296.798 | Loss difference: 2.943e-07 | Loss: 2.4428591132164e-05\n",
      "Number no loss change 28: | Current time: 314.490 | Loss difference: 8.005e-08 | Loss: 2.217150540673174e-05\n",
      "Number no loss change 29: | Current time: 316.655 | Loss difference: 3.793e-07 | Loss: 2.179220609832555e-05\n",
      "Number no loss change 30: | Current time: 321.085 | Loss difference: 8.692e-07 | Loss: 2.443120138195809e-05\n",
      "Number no loss change 31: | Current time: 349.603 | Loss difference: 4.681e-07 | Loss: 2.164424404327292e-05\n",
      "Number no loss change 32: | Current time: 376.085 | Loss difference: 8.241e-07 | Loss: 2.1881711290916428e-05\n",
      "Number no loss change 33: | Current time: 382.651 | Loss difference: 8.231e-07 | Loss: 2.428341940685641e-05\n",
      "Number no loss change 34: | Current time: 402.507 | Loss difference: 3.436e-07 | Loss: 2.3749536921968684e-05\n",
      "Number no loss change 35: | Current time: 404.745 | Loss difference: 8.031e-07 | Loss: 2.2946473109186627e-05\n",
      "Number no loss change 36: | Current time: 411.368 | Loss difference: 2.077e-07 | Loss: 2.2822692699264735e-05\n",
      "Number no loss change 37: | Current time: 417.985 | Loss difference: 2.113e-07 | Loss: 2.4378632588195615e-05\n",
      "Number no loss change 38: | Current time: 442.234 | Loss difference: 9.009e-07 | Loss: 2.7102287276647985e-05\n",
      "Number no loss change 39: | Current time: 473.994 | Loss difference: 3.76e-07 | Loss: 2.4879202101146802e-05\n",
      "Number no loss change 40: | Current time: 489.982 | Loss difference: 3.483e-07 | Loss: 3.129784090560861e-05\n",
      "Number no loss change 41: | Current time: 494.819 | Loss difference: 6.788e-07 | Loss: 2.3487287762691267e-05\n",
      "Number no loss change 42: | Current time: 506.946 | Loss difference: 6.57e-07 | Loss: 2.5407343855476938e-05\n",
      "Number no loss change 43: | Current time: 526.313 | Loss difference: 3.51e-07 | Loss: 2.20463662117254e-05\n",
      "Number no loss change 44: | Current time: 541.035 | Loss difference: 2.423e-07 | Loss: 2.4772238248260692e-05\n",
      "Number no loss change 45: | Current time: 552.557 | Loss difference: 3.792e-07 | Loss: 2.4307821149704978e-05\n",
      "Number no loss change 46: | Current time: 611.151 | Loss difference: 7.053e-07 | Loss: 1.9631090253824368e-05\n",
      "Number no loss change 47: | Current time: 651.139 | Loss difference: 4.822e-07 | Loss: 2.4918130293372087e-05\n",
      "Number no loss change 48: | Current time: 659.932 | Loss difference: 3.278e-07 | Loss: 2.3322221750277095e-05\n",
      "Number no loss change 49: | Current time: 662.145 | Loss difference: 4.437e-07 | Loss: 2.2878510208101943e-05\n",
      "Number no loss change 50: | Current time: 724.070 | Loss difference: 2.495e-07 | Loss: 2.2486185116576962e-05\n",
      "Number no loss change 51: | Current time: 735.122 | Loss difference: 7.346e-07 | Loss: 2.284791844431311e-05\n",
      "Number no loss change 52: | Current time: 743.893 | Loss difference: 7.738e-07 | Loss: 2.3361621060757898e-05\n",
      "Number no loss change 53: | Current time: 746.116 | Loss difference: 2.769e-07 | Loss: 2.363850398978684e-05\n",
      "Number no loss change 54: | Current time: 748.279 | Loss difference: 9.065e-07 | Loss: 2.2731954231858253e-05\n",
      "Number no loss change 55: | Current time: 779.395 | Loss difference: 8.808e-07 | Loss: 2.4169436073862016e-05\n",
      "Number no loss change 56: | Current time: 790.802 | Loss difference: 2.408e-07 | Loss: 2.569388561823871e-05\n",
      "Number no loss change 57: | Current time: 792.983 | Loss difference: 6.189e-08 | Loss: 2.5631996322772466e-05\n",
      "Number no loss change 58: | Current time: 806.282 | Loss difference: 6.287e-07 | Loss: 2.430099993944168e-05\n",
      "Number no loss change 59: | Current time: 821.780 | Loss difference: 3.019e-07 | Loss: 2.4312816094607115e-05\n",
      "Number no loss change 60: | Current time: 830.612 | Loss difference: 5.578e-08 | Loss: 2.334385135327466e-05\n",
      "Number no loss change 61: | Current time: 859.682 | Loss difference: 3.584e-07 | Loss: 2.5807095880736597e-05\n",
      "Number no loss change 62: | Current time: 894.995 | Loss difference: 8.577e-07 | Loss: 2.243170456495136e-05\n",
      "Number no loss change 63: | Current time: 917.103 | Loss difference: 7.689e-07 | Loss: 2.679874887689948e-05\n",
      "Number no loss change 64: | Current time: 956.555 | Loss difference: 7.579e-07 | Loss: 2.2611375243286602e-05\n",
      "Number no loss change 65: | Current time: 958.802 | Loss difference: 8.594e-07 | Loss: 2.17520137084648e-05\n",
      "Number no loss change 66: | Current time: 971.984 | Loss difference: 5.772e-07 | Loss: 2.0078574380022474e-05\n",
      "Number no loss change 67: | Current time: 978.535 | Loss difference: 9.501e-07 | Loss: 2.0601870346581563e-05\n",
      "Number no loss change 68: | Current time: 998.374 | Loss difference: 2.732e-07 | Loss: 2.9841950890840963e-05\n",
      "Number no loss change 69: | Current time: 1007.158 | Loss difference: 5.402e-07 | Loss: 2.371868868067395e-05\n",
      "Number no loss change 70: | Current time: 1054.448 | Loss difference: 4.174e-07 | Loss: 2.319061240996234e-05\n",
      "Number no loss change 71: | Current time: 1068.396 | Loss difference: 7.118e-07 | Loss: 2.422808756818995e-05\n",
      "Number no loss change 72: | Current time: 1074.963 | Loss difference: 2.619e-08 | Loss: 2.3608208721270785e-05\n",
      "Number no loss change 73: | Current time: 1088.185 | Loss difference: 3.287e-07 | Loss: 2.190936174883973e-05\n",
      "Number no loss change 74: | Current time: 1094.803 | Loss difference: 1.356e-07 | Loss: 2.3648217393201776e-05\n",
      "Number no loss change 75: | Current time: 1108.116 | Loss difference: 7.759e-07 | Loss: 2.4179435058613308e-05\n",
      "Number no loss change 76: | Current time: 1110.341 | Loss difference: 5.589e-07 | Loss: 2.362056875426788e-05\n",
      "Number no loss change 77: | Current time: 1130.880 | Loss difference: 3.692e-07 | Loss: 2.401261735940352e-05\n",
      "Number no loss change 78: | Current time: 1133.164 | Loss difference: 1.304e-07 | Loss: 2.3882190362201072e-05\n",
      "Number no loss change 79: | Current time: 1137.642 | Loss difference: 6.71e-07 | Loss: 2.6470308512216434e-05\n",
      "Number no loss change 80: | Current time: 1142.238 | Loss difference: 8.845e-07 | Loss: 2.3935734134283848e-05\n",
      "Number no loss change 81: | Current time: 1146.782 | Loss difference: 6.726e-07 | Loss: 2.1898824343224987e-05\n",
      "Number no loss change 82: | Current time: 1149.056 | Loss difference: 8.864e-07 | Loss: 2.278524698340334e-05\n",
      "Number no loss change 83: | Current time: 1151.446 | Loss difference: 3.671e-07 | Loss: 2.3152359062805772e-05\n",
      "Number no loss change 84: | Current time: 1153.712 | Loss difference: 9.406e-07 | Loss: 2.22118069359567e-05\n",
      "Number no loss change 85: | Current time: 1165.225 | Loss difference: 2.082e-07 | Loss: 2.1291423763614148e-05\n",
      "Number no loss change 86: | Current time: 1247.473 | Loss difference: 7.93e-07 | Loss: 2.4355067580472678e-05\n",
      "Number no loss change 87: | Current time: 1254.599 | Loss difference: 2.341e-07 | Loss: 2.1312782337190583e-05\n",
      "Number no loss change 88: | Current time: 1264.589 | Loss difference: 5.117e-07 | Loss: 2.4805845896480605e-05\n",
      "Number no loss change 89: | Current time: 1266.944 | Loss difference: 4.607e-07 | Loss: 2.4345170459127985e-05\n",
      "Number no loss change 90: | Current time: 1276.609 | Loss difference: 9.105e-07 | Loss: 2.2103306037024595e-05\n",
      "Number no loss change 91: | Current time: 1279.188 | Loss difference: 9.106e-07 | Loss: 2.301386120961979e-05\n",
      "Number no loss change 92: | Current time: 1303.725 | Loss difference: 3.296e-07 | Loss: 2.4570117602706887e-05\n",
      "Number no loss change 93: | Current time: 1318.317 | Loss difference: 9.046e-07 | Loss: 2.614948789414484e-05\n",
      "Number no loss change 94: | Current time: 1323.548 | Loss difference: 9.585e-07 | Loss: 2.1720496079069562e-05\n",
      "Number no loss change 95: | Current time: 1340.324 | Loss difference: 3.937e-07 | Loss: 2.508158104319591e-05\n",
      "Number no loss change 96: | Current time: 1350.487 | Loss difference: 8.718e-07 | Loss: 2.895848774642218e-05\n",
      "Number no loss change 97: | Current time: 1372.909 | Loss difference: 5.186e-07 | Loss: 2.675554969755467e-05\n",
      "Number no loss change 98: | Current time: 1416.607 | Loss difference: 5.747e-07 | Loss: 2.7797997972811572e-05\n",
      "Number no loss change 99: | Current time: 1437.690 | Loss difference: 8.071e-07 | Loss: 2.6159599656239152e-05\n",
      "Number no loss change 100: | Current time: 1439.966 | Loss difference: 3.953e-07 | Loss: 2.6554931537248194e-05\n",
      "Number no loss change 101: | Current time: 1446.722 | Loss difference: 8.814e-08 | Loss: 2.44517268583877e-05\n",
      "Number no loss change 102: | Current time: 1453.586 | Loss difference: 6.898e-07 | Loss: 2.5808370992308483e-05\n",
      "Number no loss change 103: | Current time: 1458.071 | Loss difference: 3.067e-07 | Loss: 2.7333013349561952e-05\n",
      "Number no loss change 104: | Current time: 1466.845 | Loss difference: 7.195e-07 | Loss: 2.4339362425962463e-05\n",
      "Number no loss change 105: | Current time: 1469.240 | Loss difference: 8.504e-07 | Loss: 2.5189772713929415e-05\n",
      "Number no loss change 106: | Current time: 1473.711 | Loss difference: 8.287e-07 | Loss: 2.694108843570575e-05\n",
      "Number no loss change 107: | Current time: 1480.369 | Loss difference: 6.164e-07 | Loss: 1.9897643142030574e-05\n",
      "Number no loss change 108: | Current time: 1487.336 | Loss difference: 7.91e-07 | Loss: 2.5592114980099723e-05\n",
      "Number no loss change 109: | Current time: 1489.735 | Loss difference: 4.847e-08 | Loss: 2.5640583771746606e-05\n",
      "Number no loss change 110: | Current time: 1499.215 | Loss difference: 1.597e-07 | Loss: 2.360070720897056e-05\n",
      "Number no loss change 111: | Current time: 1504.446 | Loss difference: 2.248e-07 | Loss: 2.521907299524173e-05\n",
      "Number no loss change 112: | Current time: 1512.632 | Loss difference: 1.984e-07 | Loss: 2.463589953549672e-05\n",
      "Number no loss change 113: | Current time: 1517.261 | Loss difference: 1.089e-07 | Loss: 2.0030276573379524e-05\n",
      "Number no loss change 114: | Current time: 1522.018 | Loss difference: 2.581e-07 | Loss: 2.541258254495915e-05\n",
      "Number no loss change 115: | Current time: 1536.944 | Loss difference: 8.323e-07 | Loss: 2.280843909829855e-05\n",
      "Number no loss change 116: | Current time: 1548.775 | Loss difference: 2.154e-07 | Loss: 2.4041772121563554e-05\n",
      "Number no loss change 117: | Current time: 1573.140 | Loss difference: 3.838e-07 | Loss: 2.080211925203912e-05\n"
     ]
    }
   ],
   "source": [
    "#Linear combo 5d guassian weight (cracking model has double layers)\n",
    "       \n",
    "#groundtruth model  \n",
    "GroundTruth = binaryClassification()\n",
    "firstmodel=arbitraryLayerModel()\n",
    "possible_infinite_time=arbitraryLayerModel()\n",
    "\n",
    "\n",
    "\n",
    "test_model=arbitraryLayerModel()\n",
    "firstmodeltrained=test_model.get_copy()\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        current_loss=0\n",
    "        previous_loss=0\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "        loss_difference_counter=0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                previous_loss=current_loss\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "                data_counter=data_counter+1\n",
    "            #generate new data if needed\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                \n",
    "                previous_loss=current_loss\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                loss_diff=previous_loss-current_loss\n",
    "\n",
    "             \n",
    "            \n",
    "            \n",
    "            #checks if loss difference is small\n",
    "            if abs(loss_diff)<(1e-6):\n",
    "                loss_difference_counter=loss_difference_counter+1\n",
    "                if loss_difference_counter>5: \n",
    "                    print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    "                \n",
    "             \n",
    "            \n",
    "            #if to many training routines with small loss, breaks out of code\n",
    "            if loss_difference_counter>=BADLOSSPASSES:\n",
    "                possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "                stop_itterations=True\n",
    "                break\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        time_list.append(test_time)\n",
    "        \n",
    "         \n",
    "        #if to many training routines with small loss, breaks out of code\n",
    "        if stop_itterations:\n",
    "            print(\"No loss decrease for \", BADLOSSPASSES, \" threshhold checks. Prospective global minimum found\")\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max(time_list)>current_time:\n",
    "        GroundTruth=get_new_GroundTruth(model_list, time_list, current_time)\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==10:\n",
    "        print(\"No increase for 10 iterations\")\n",
    "        time_increase=False\n",
    " \n",
    "    #if to many training routines with small loss, breaks out of code\n",
    "    if stop_itterations:\n",
    "        break\n",
    "                                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6983e056",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss:  [[0.00016184]]\n",
      "current loss:  [[0.00111658]]\n",
      "current loss:  [[0.00096108]]\n",
      "current loss:  [[0.00114861]]\n",
      "current loss:  [[0.00110419]]\n",
      "current loss:  [[0.00043214]]\n",
      "current loss:  [[0.00111681]]\n",
      "current loss:  [[0.0010474]]\n",
      "current loss:  [[0.00113417]]\n",
      "current loss:  [[0.00110339]]\n",
      "[12.976532697677612, 12.938209056854248, 14.750714302062988, 12.007935762405396, 11.025629043579102, 10.595731019973755, 12.371632814407349, 11.334189653396606, 13.096515417098999, 12.43299150466919]\n",
      "current loss:  [[5.5408644e-05]]\n",
      "current loss:  [[0.00071849]]\n",
      "current loss:  [[0.00042576]]\n",
      "current loss:  [[0.00038151]]\n",
      "current loss:  [[0.00106397]]\n",
      "current loss:  [[0.00112753]]\n",
      "current loss:  [[0.0007163]]\n",
      "current loss:  [[0.00146907]]\n",
      "current loss:  [[0.00049282]]\n",
      "current loss:  [[0.00100258]]\n",
      "[13.589966773986816, 12.514455795288086, 12.277449607849121, 12.588509798049927, 13.095532655715942, 12.446441650390625, 12.127474069595337, 13.397139310836792, 12.944106101989746, 12.364925622940063]\n"
     ]
    }
   ],
   "source": [
    "#add [1]*5 Not Needed\n",
    "firstpass=True\n",
    "time_increase=1\n",
    "while(time_increase>.01):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    for i in range(0, 10):\n",
    "        train_testmodel=test_model.get_copy()\n",
    "        prospective_GroundTruth=GroundTruth.change_node_modellinear(node_list[i])\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "        data_counter=0\n",
    "        test_time=0\n",
    "        inital_data_length=len(data_list)\n",
    "        accepted=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        while(not accepted): \n",
    "            #use previously generated data\n",
    "            if data_counter<inital_data_length:\n",
    "                X=data_list[data_counter]\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                data_counter=data_counter+1\n",
    "            else:                          \n",
    "                X=get_Xvals()\n",
    "                data_list.append(X)\n",
    "                y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                test_data = testData(torch.FloatTensor(X_test))\n",
    "                train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "                test_time=test_time+trainnetwork(train_testmodel, train_loader)\n",
    "                accepted=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "\n",
    "            #print(test_time)\n",
    "        time_list.append(test_time)\n",
    "    \n",
    "    \n",
    "    print(time_list)\n",
    "    max_new_time=max(time_list)\n",
    "    max_index=time_list.index(max_new_time)\n",
    "    GroundTruth=model_list[i]\n",
    "    time_increase=max_new_time-current_time\n",
    "    current_time=max_new_time\n",
    "\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb699e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
