{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05ff88",
   "metadata": {
    "code_folding": [
     0,
     40,
     43,
     62,
     79,
     91,
     105,
     129,
     162,
     179
    ]
   },
   "outputs": [],
   "source": [
    "#import statements, hyper params, models\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import math\n",
    "import time\n",
    "    \n",
    "THRESH_HOLD=5e-4            #MSE value when we consider the second model to have \"cracked\" the first\n",
    "EPOCHS = 25                 #number of passes of whole data\n",
    "BATCH_SIZE =  64            #size of data going through at once\n",
    "LEARNING_RATE = 0.01        #how much we shift parameters during back prop\n",
    "NEURONS=5                   #number of nodes in each layer\n",
    "INPUTS=5                     #number of input vars\n",
    "XSIZE=  577                 #size of each data set generated\n",
    "BAD_LOSS_PASSES=25          #number of times we have small loss until we stop code\n",
    "NO_TIME_INCREASES_STOP=10        #number of interations with no time increase until we stop code\n",
    "TESTMODULE_LAYERS=2         #number of layers in cracking module\n",
    "GROUND_TRUTH_LAYERS=10       #number of layers in ground thruth models\n",
    "LINCOMBO=True               #wether to take best new time or linear combination\n",
    "activation=nn.Sigmoid()     #activation     \n",
    "def get_Xvals():\n",
    "    return (np.random.uniform( size=(XSIZE, INPUTS))-0.5)*np.sqrt(12)\n",
    "    \n",
    "def getdata_XY():\n",
    "    X=(np.random.uniform( size=(XSIZE, INPUTS))-0.5)*np.sqrt(12)\n",
    "    test_data = testData(torch.FloatTensor(X))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist =[]\n",
    "    \n",
    "    \n",
    "    GroundTruth.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = GroundTruth(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return X, y_truthlist\n",
    "\n",
    "def get_yvals(model, X_data):\n",
    "    model.eval()\n",
    "    test_data = testData(torch.FloatTensor(X_data))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "    y_truthlist=[]\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_truthlist.append(y_test_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "    y_truthlist = [a.squeeze().tolist() for a in y_truthlist]\n",
    "    return y_truthlist\n",
    "\n",
    "#Data class\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "#Data loaders (to look at data) and deal with data (training and testing)\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "#trains a network, returns time spent training \n",
    "def trainnetwork(network, train_loader, optimizer, Time=True):\n",
    "    t0=time.time()\n",
    "    network.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "    network.train()\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = network(X_batch)\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()        \n",
    "            \n",
    "    t1=time.time()\n",
    "    return(t1-t0)\n",
    "\n",
    "#returns next ground truth model\n",
    "#model obtained by taking average of models with better times than previous model \n",
    "def get_new_GroundTruth_lincombo(model_list, time_list, time):\n",
    "    better_model_list=[]\n",
    "    for (i, model) in zip(time_list, model_list):\n",
    "        if i>time:\n",
    "            better_model_list.append(model)\n",
    "    \n",
    "    \n",
    "    newGroundTruth=GroundTruth.get_copy()\n",
    "    \n",
    "    layer_weight=torch.tensor([[0]*INPUTS]*NEURONS, requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer_weight=layer_weight+i.layer_input.weight/(len(better_model_list))\n",
    "        \n",
    "    layer_weight.requires_grad_()    \n",
    "    newGroundTruth.layer_input.weight=torch.nn.Parameter(layer_weight)\n",
    "    \n",
    "    \n",
    "    for i in range(GROUND_TRUTH_LAYERS):\n",
    "        layer_weight=torch.tensor([[0]*NEURONS]*NEURONS, requires_grad=False)\n",
    "        for bettermodel in better_model_list:\n",
    "            layer_weight=layer_weight+bettermodel.layers[i].weight/(len(better_model_list))\n",
    "        layer_weight.requires_grad_()\n",
    "        newGroundTruth.layers[i].weight=torch.nn.Parameter(layer_weight)\n",
    "        \n",
    "    layer_weight=torch.tensor([0]*NEURONS, requires_grad=False)\n",
    "    for i in better_model_list:\n",
    "        layer_weight=layer_weight+i.layer_output.weight/(len(better_model_list))\n",
    "    layer_weight.requires_grad_()   \n",
    "    newGroundTruth.layer_output.weight=torch.nn.Parameter(layer_weight)\n",
    "\n",
    "    return newGroundTruth\n",
    "        \n",
    "#checks accuracy of model\n",
    "def check_threshhold(network, test_loader, truth):\n",
    "    total_loss=0\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_batch, y) in zip(test_loader, truth):\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = network(X_batch)\n",
    "            y_pred_tag = torch.sigmoid(y_test_pred)\n",
    "            total_loss=total_loss+((y_pred_tag.cpu().numpy()-y))**2\n",
    "    \n",
    "    total_loss=total_loss/len(truth)\n",
    "\n",
    "    if total_loss[0][0]<THRESH_HOLD:\n",
    "        return True, total_loss[0][0]\n",
    "    else:\n",
    "        return False, total_loss[0][0]\n",
    "                       \n",
    "def select_node():\n",
    "    layer=randrange(GROUND_TRUTH_LAYERS+2)\n",
    "    if layer==0:\n",
    "        node=[randrange(INPUTS), randrange(NEURONS)]\n",
    "    elif layer==GROUND_TRUTH_LAYERS+1:\n",
    "         node=randrange(NEURONS)\n",
    "    else:\n",
    "        node=[randrange(NEURONS), randrange(NEURONS)]\n",
    "    return [layer, node]\n",
    "       \n",
    "class arbitraryLayerModel(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super(arbitraryLayerModel, self).__init__()\n",
    "        self.layer_input=nn.Linear(INPUTS, NEURONS)\n",
    "        self.layers=nn.ModuleList([nn.Linear(NEURONS, NEURONS) for i in range(num_layers)])\n",
    "        \n",
    "        \n",
    "        self.batchnorms=nn.ModuleList([nn.BatchNorm1d(NEURONS) for i in range(num_layers)])\n",
    "        self.batchnorm_input=nn.BatchNorm1d(NEURONS)\n",
    "        \n",
    "        self.layer_output=nn.Linear(NEURONS,1)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def get_copy(self):\n",
    "        copied_model=arbitraryLayerModel(len(self.layers))\n",
    "        copied_model.layers=nn.ModuleList()\n",
    "        for i in self.layers:\n",
    "            copied_model.layers.append(copy.deepcopy(i))\n",
    "            \n",
    "        copied_model.batchnorms=nn.ModuleList()\n",
    "        for i in self.batchnorms:\n",
    "            copied_model.batchnorms.append(copy.deepcopy(i))\n",
    "        copied_model.layer_input=copy.deepcopy(self.layer_input)\n",
    "        copied_model.layer_output=copy.deepcopy(self.layer_output)\n",
    "        copied_model.batchnorm_input=copy.deepcopy(self.batchnorm_input)\n",
    "\n",
    "        return copied_model\n",
    "            \n",
    "     \n",
    "    def forward(self, inputs):\n",
    "        x=activation(self.batchnorm_input(self.layer_input(inputs)))\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        for (layer, batchnorm) in zip(self.layers, self.batchnorms):\n",
    "            x=activation(batchnorm(layer(inputs)))\n",
    "            x=self.dropout(x)\n",
    "                \n",
    "                \n",
    "        x=self.layer_output(x)\n",
    "        return(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    def change_node_model(self, node):\n",
    "        changed_node=self.get_copy()\n",
    "        \n",
    "        weightchange=np.random.normal(0,1)      \n",
    "        \n",
    "        if node[0]==0:\n",
    "            zeros=[[0]*INPUTS]*NEURONS\n",
    "            zeros[node[1][0]][node[1][1]]=weightchange\n",
    "            newweight=self.layer_input.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_input.weight=torch.nn.Parameter(newweight)    \n",
    "            return changed_node\n",
    "            \n",
    "            \n",
    "        \n",
    "        if node[0]==GROUND_TRUTH_LAYERS+1:\n",
    "            zeros=[0]*(NEURONS-1)\n",
    "            zeros.insert(node[1],weightchange)\n",
    "            newweight=self.layer_output.weight.requires_grad_(False)+torch.tensor(zeros,requires_grad=False)\n",
    "            newweight.requires_grad_()\n",
    "            changed_node.layer_output.weight=torch.nn.Parameter(newweight) \n",
    "            \n",
    "            \n",
    "        \n",
    "        else:\n",
    "            zeros = [[0.0]*NEURONS]*NEURONS\n",
    "            for layer, i in enumerate(changed_node.layers):\n",
    "                if i==node[0]+1:\n",
    "                    zeros[node[1][0]][node[1][1]]=weightchange\n",
    "                    newweight=layer.weight.requires_grad_(False)+torch.tensor(weightchange,requires_grad=False)\n",
    "                    newweight.requires_grad_()\n",
    "                    layer.weight=torch.nn.Parameter(newweight)\n",
    "                    \n",
    "        \n",
    "\n",
    "        return changed_node\n",
    "\n",
    "   \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983e056",
   "metadata": {
    "code_folding": [
     0,
     15,
     36
    ]
   },
   "outputs": [],
   "source": [
    "#linear combo 1 weight guassian weight\n",
    "       \n",
    "#groundtruth model  \n",
    "GroundTruth = arbitraryLayerModel(GROUND_TRUTH_LAYERS)\n",
    "possible_infinite_time=arbitraryLayerModel(GROUND_TRUTH_LAYERS)\n",
    "\n",
    "\n",
    "\n",
    "firstmodeltrained=arbitraryLayerModel(TESTMODULE_LAYERS)\n",
    "test_model_optimizer = optim.Adam(firstmodeltrained.parameters(), lr=LEARNING_RATE)\n",
    "accepted=False\n",
    "current_time=0\n",
    "data_list=[]\n",
    "\n",
    "\n",
    "while((not accepted)):\n",
    "    X, y=getdata_XY()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "    test_data = testData(torch.FloatTensor(X_test))\n",
    "    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=False)                      \n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "    data_list.append(X)\n",
    "    current_time=current_time+trainnetwork(firstmodeltrained, train_loader,test_model_optimizer)\n",
    "    accepted=check_threshhold(firstmodeltrained, test_loader, y_test)\n",
    "    \n",
    "print(\"First time: \", current_time)\n",
    "    \n",
    "#iterates\n",
    "interationcounter=1\n",
    "#number of iterates in a row with no time increase\n",
    "no_increasecounter=0\n",
    "time_increase=True\n",
    "#number of training interations where loss doesnt change\n",
    "loss_difference_counter=0\n",
    "stop_itterations=False\n",
    "while(time_increase):\n",
    "    node_list=[]\n",
    "    time_list=[]\n",
    "    model_list=[]\n",
    "    for i in range(0, 10):\n",
    "        node_list.append(select_node())\n",
    "    \n",
    "    test_model_list=[arbitraryLayerModel(TESTMODULE_LAYERS) for i in range(10)]\n",
    "    for i in range(0, 10):\n",
    "        total_time=0\n",
    "        infinite_time_counter=0\n",
    "        prospective_GroundTruth=GroundTruth.change_node_model(node_list[i])\n",
    "\n",
    "        model_list.append(prospective_GroundTruth)\n",
    "\n",
    "        for j, test_model in enumerate(test_model_list):\n",
    "            current_loss=0\n",
    "            previous_loss=0\n",
    "            train_testmodel=test_model.get_copy()\n",
    "            test_model_optimizer = optim.Adam(train_testmodel.parameters(), lr=LEARNING_RATE)\n",
    "            data_counter=0\n",
    "            test_time=0\n",
    "            inital_data_length=len(data_list)\n",
    "            accepted=False\n",
    "            loss_difference_counter=0\n",
    "            Model_beaten=False\n",
    "\n",
    "            while(not accepted): \n",
    "                #use previously generated data\n",
    "                if data_counter<inital_data_length:\n",
    "                    X=data_list[data_counter]\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    previous_loss=current_loss\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "                    data_counter=data_counter+1\n",
    "                #generate new data if needed\n",
    "                else:                          \n",
    "                    X=get_Xvals()\n",
    "                    data_list.append(X)\n",
    "                    y=get_yvals(prospective_GroundTruth, X)\n",
    "\n",
    "\n",
    "\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "                    train_data= trainData(torch.FloatTensor(X_train),torch.FloatTensor(y_train))\n",
    "                    test_data = testData(torch.FloatTensor(X_test))\n",
    "                    train_loader= DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)                      \n",
    "                    test_loader = DataLoader(dataset=test_data, batch_size=1)\n",
    "\n",
    "                    previous_loss=current_loss\n",
    "                    test_time=test_time+trainnetwork(train_testmodel, train_loader,test_model_optimizer)\n",
    "                    accepted, current_loss=check_threshhold(train_testmodel, test_loader, y_test)\n",
    "                    loss_diff=previous_loss-current_loss\n",
    "\n",
    "\n",
    "                #checks if loss difference is small\n",
    "                \n",
    "                if abs(loss_diff)<(THRESH_HOLD/10):\n",
    "                    loss_difference_counter=loss_difference_counter+1\n",
    "                    if loss_difference_counter>BAD_LOSS_PASSES:\n",
    "                        infinite_time_counter=infinite_time_counter+1\n",
    "                        print(\"Test model beaten. Total beaten by prospective ground truth: \", infinite_time_counter)\n",
    "                        Model_beaten=True\n",
    "                    elif loss_difference_counter>5:\n",
    "                        print(f'Number no loss change {loss_difference_counter}: | Current time: {test_time:.3f} | Loss difference: {abs(loss_diff):.4} | Loss: {current_loss:.4}')\n",
    " \n",
    "            \n",
    "                if Model_beaten:\n",
    "                    break\n",
    "\n",
    "\n",
    "            total_time=total_time+test_time\n",
    "\n",
    "    \n",
    "    \n",
    "        print(f'Iteration: {interationcounter} | Ground truth number: {i+1} | Average time:  {total_time/10:.3}')\n",
    "\n",
    "        if infinite_time_counter==10:\n",
    "            print(\"Potential unbreakable found\")\n",
    "            possible_infinite_time=prospective_GroundTruth.get_copy()\n",
    "            break\n",
    "        time_list.append(total_time/(10))\n",
    "\n",
    "        \n",
    "           \n",
    "    \n",
    "    if infinite_time_counter==10:\n",
    "        break\n",
    "    max_new_time=max(time_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #prints iteration data\n",
    "    print(f'Iteration {interationcounter}: | Previous time: {current_time:.3f} | Best new time: {max_new_time:.3f} | Difference: {max_new_time-current_time:.3f}')\n",
    "    interationcounter=interationcounter+1\n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    time_increase=max_new_time-current_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    #changes ground truth if better time found\n",
    "    if max_new_time>current_time:\n",
    "        if LINCOMBO:\n",
    "            GroundTruth=get_new_GroundTruth_lincombo(model_list, time_list, current_time)\n",
    "        else:\n",
    "            maxindex=time_list.index(max(time_list))\n",
    "            GroundTruth=model_list[maxindex].get_copy()\n",
    "        time_increase=True\n",
    "        previous_time=current_time\n",
    "        current_time=max_new_time\n",
    "        no_increasecounter=0\n",
    "        \n",
    "    else:\n",
    "        no_increasecounter=no_increasecounter+1\n",
    "\n",
    "    #if no better ground truth found for 10 iterations, stops code                 \n",
    "    if no_increasecounter==NO_TIME_INCREASES_STOP:\n",
    "        print(\"No increase for \", NO_TIME_INCREASES_STOP,  \" iterations\")\n",
    "    #    time_increase=False\n",
    " \n",
    "      \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dce23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
